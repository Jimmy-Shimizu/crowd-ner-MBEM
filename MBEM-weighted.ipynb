{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import collections\n",
    "import glob\n",
    "import numpy as np\n",
    "import os\n",
    "import subprocess\n",
    "import torch\n",
    "import torch.autograd as autograd\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import re\n",
    "import random\n",
    "\n",
    "from itertools import groupby\n",
    "torch.manual_seed(1)\n",
    "\n",
    "ans_path = './ner-mturk/answers*'\n",
    "ans_file_list = sorted(glob.glob(ans_path))\n",
    "single_ans_list = sorted(glob.glob('ner-mturk/single_ans*'))\n",
    "truth_file = './ner-mturk/ground_truth.txt'\n",
    "path_w = './MBEM_outputs'\n",
    "alltask_num = 5985\n",
    "train_num = 5385\n",
    "train_num5 = 1077\n",
    "test_num = 600\n",
    "alltype_num = 9859\n",
    "type_train_num = 9089\n",
    "type_test_num = 368\n",
    "k = 9\n",
    "redundancy = 5\n",
    "iteration_times = 5\n",
    "#ans_file = ans_file_list[5]\n",
    "#ans_file = single_ans_list[1]\n",
    "ans_file = '../MBEM/ner-mturk/answers.txt'\n",
    "test_file = '../MBEM/ner-mturk/testset.txt'\n",
    "train_file = '../MBEM/ner-mturk/trainset.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ans(workers, answers):\n",
    "    ans_label = []\n",
    "    for a in workers:\n",
    "        ans_label.append(class_dic[answers[a]])\n",
    "    return ans_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_n_ans(answers, n):\n",
    "    ans = []\n",
    "    for k in range(len(answers)):\n",
    "        ans.append(answers[k][n])\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tupleには対応していないので返り値用に多重配列作り直した方がいいかもしれない\n",
    "def label2num(answers, class_dic, class_dic_r):\n",
    "    ans_return = copy.deepcopy(answers)\n",
    "    if answers[0][0] in class_dic:\n",
    "        for i in range(len(answers)):\n",
    "            for w in range(len(answers[i])):\n",
    "                ans_return[i][w] = class_dic[answers[i][w]]\n",
    "    elif answers[0][0] in class_dic_r:\n",
    "        for i in range(len(answers)):\n",
    "            for w in range(len(answers[i])):\n",
    "                ans_return[i][w] = class_dic_r[int(answers[i][w])]\n",
    "    else: print(\"error\")\n",
    "    return ans_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_output(path, class_dic_r, to_label=False):\n",
    "    f = open(path)\n",
    "    make_xypair = lambda v: list(zip(*[l.strip().split() for l in v]))\n",
    "    is_emptyline = lambda x: x.strip() != '' and not x.startswith('-DOCSTART-')\n",
    "    list_int = lambda t: list([class_dic_r[int(v)] for v in t])\n",
    "    xypairs = [make_xypair(v) for k, v in groupby(f, is_emptyline) if k]\n",
    "    if to_label == True:\n",
    "        return ([p[0] for p in xypairs], [list(list_int(p[1])) for p in xypairs])\n",
    "    if len(xypairs[0]) == 2:\n",
    "        return ([p[0] for p in xypairs], [list(p[1]) for p in xypairs])\n",
    "    else:\n",
    "        return ([p[0] for p in xypairs], [list(p[1:]) for p in xypairs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_crowd_data(ans_file, truth_file, train_num):\n",
    "    #ここからanswersの格納\n",
    "    #answers_list[task_num] = [[words, ...], [回答者], [[answers(one hot ベクトル)]...]]\n",
    "    answers_list = []\n",
    "    sentence = []\n",
    "    answers = []\n",
    "    worker = []\n",
    "    words_dic = {}\n",
    "    get_worker = lambda x: tuple([i for i, l in enumerate(x) if l !='?'])\n",
    "    for l in open(ans_file):\n",
    "        ans = l.split()\n",
    "        if len(l) < 2:\n",
    "            answers_list.append([sentence, worker, answers])\n",
    "            sentence = []\n",
    "            worker = []\n",
    "            answers = []\n",
    "        else:\n",
    "            if len(worker) < 1:\n",
    "                worker = get_worker(ans[1:])\n",
    "            if not ans[0] in words_dic:\n",
    "                words_dic[ans[0]] = len(words_dic)\n",
    "            sentence.append(ans[0])\n",
    "            answers.append(get_ans(worker, ans[1:]))            \n",
    "    #truth_list: [(task_word, answer), ....]\n",
    "    truth_list = [tuple(l.split()) for l in open(truth_file) if l != \"\\n\"]\n",
    "    ans_train = answers_list[0:train_num]\n",
    "#    ans_test = answers_list[train_num:]\n",
    "    return ans_train, words_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ans_matrix(ans_train, redundancy, k):\n",
    "    ans_m = np.zeros((num_words, redundancy,k))\n",
    "    m = 0\n",
    "    for n in range(len(ans_train)):\n",
    "        for i in range(len(ans_train[n][0])):\n",
    "            ans_m[m] = np.eye(k)[ans_train[n][2][i][:5]]\n",
    "            m += 1\n",
    "    return ans_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#deep-learning-modelからのデータの読み込み\n",
    "def get_newest_prediction():\n",
    "    files_list = glob.glob(\"./deep-learning-model/outputs/*\")\n",
    "    latest_file = max(glob.glob(max(files_list, key=os.path.getctime)+\"/*\"), key=os.path.getctime) + \"/best_model_log/pred.txt\"\n",
    "    prediction_list = [list(l.split()) for l in open(latest_file) if l != \"\\n\"]\n",
    "    return prediction_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ワーカのタスクに対する回答の事後確率の初期化\n",
    "#Algorithm 1のInitialixe posterior distribution using weighted mv(論文p6)\n",
    "def init_posdis(redundancy, ans_m, k):\n",
    "    simple_agg = np.zeros((num_words,k))\n",
    "    mv_ans = np.zeros((num_words))\n",
    "    for r in range(redundancy):\n",
    "        simple_agg += (1/redundancy)*ans_m[r]\n",
    "    for i in range(len(simple_agg)):\n",
    "        mv_ans[i] = np.argmax(simple_agg[i])\n",
    "    return mv_ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ワーカのタスクに対する回答の事後確率の初期化\n",
    "#mvしない場合\n",
    "def init_posdis_single(redundancy, ans_m, k):\n",
    "    simple_agg = np.zeros((num_words,k))\n",
    "    mv_ans = np.zeros((num_words))\n",
    "    simple_agg += (1/redundancy)*ans_m[0]\n",
    "    for i in range(len(simple_agg)):\n",
    "        mv_ans[i] = np.argmax(simple_agg[i])\n",
    "    return mv_ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def post_prob_DS(est_labels, ans_train, k, worker_num, num_words):\n",
    "    #学習機とラベルの更新\n",
    "    n = len(ans_train)\n",
    "    m = worker_num\n",
    "    return_labels = []\n",
    "    return_x = []\n",
    "    e_conf = np.zeros((m,k,k))\n",
    "    temp_conf = (1/float(k))*np.ones((m,k,k))\n",
    "    labels_md = np.zeros((k))\n",
    "    worker_acc = np.zeros((m,k)) #ワーカーの信頼度\n",
    "    task_acc = np.zeros((n, k))\n",
    "    #est_labelsを正解ラベルとして混同行列を作成 式(7)\n",
    "    for i in range(n):\n",
    "        for l in range(len(ans_train[i][2])):\n",
    "            #真のラベルの周辺分布を更新\n",
    "            labels_md[int(est_labels[i][l])] += 1\n",
    "            for a, j in enumerate(ans_train[i][1]): #各回答ワーカーについて\n",
    "                temp_conf[j,:,:] = temp_conf[j,:,:] + np.outer(np.eye(k)[int(est_labels[i][l])],np.eye(k)[ans_train[i][2][l][a]]) #外積 混同行列の作成\n",
    "    #temp_confの正規化\n",
    "    for j in range(m):  \n",
    "        for r in range(k):\n",
    "            e_conf[j,:,:] = np.divide(temp_conf[j,:,:],np.outer(np.sum(temp_conf[j,:,:],axis =1),np.ones(k)))\n",
    "    labels_md = np.divide(labels_md, np.sum(labels_md)*np.ones(k))\n",
    "#    print(\"labels_md\", labels_md)\n",
    "    #混同行列を使って真のラベル推定(論文p5の(5)式)\n",
    "    for i in range(n):\n",
    "        temp_list = []\n",
    "        for l in range(len(ans_train[i][2])):\n",
    "            temp_class = 0.0\n",
    "            for r, a in enumerate(ans_train[i][1]):\n",
    "                #混同行列の該当列をとる\n",
    "                temp_acc = np.log(np.dot(e_conf[a,:,:],np.transpose(np.eye(k)[ans_train[i][2][l][r]])))\n",
    "                temp_class = temp_class + temp_acc\n",
    "            temp_class = np.log(labels_md) +temp_class\n",
    "            est_labels[i][l] = np.argmax(temp_class)\n",
    "            temp_list.append(temp_class[np.argmax(temp_class)])\n",
    "        score = sum(temp_list) / len(temp_list)\n",
    "        if score > -0.5:\n",
    "            return_labels.append(est_labels[i])\n",
    "            return_x.append(ans_train[i][0])\n",
    "            return_labels.append(est_labels[i])\n",
    "            return_x.append(ans_train[i][0])\n",
    "            return_labels.append(est_labels[i])\n",
    "            return_x.append(ans_train[i][0])\n",
    "        elif score > -1:\n",
    "            return_labels.append(est_labels[i])\n",
    "            return_x.append(ans_train[i][0])\n",
    "            return_labels.append(est_labels[i])\n",
    "            return_x.append(ans_train[i][0])\n",
    "        else:\n",
    "            return_labels.append(est_labels[i])\n",
    "            return_x.append(ans_train[i][0])\n",
    "    return est_labels, e_conf, return_labels, return_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2  iteration\n",
      "\n",
      "bugggggggggg\n",
      "notanstrain is True\n"
     ]
    }
   ],
   "source": [
    "iter_time = 2\n",
    "print(iter_time, \" iteration\\n\")\n",
    "est_labels = get_newest_prediction()\n",
    "if len(est_labels[0]) == len(ans_train[0][0]) - 1:\n",
    "    print(\"bugggggggggg\")\n",
    "    est_labels[0].insert(0, 'O')\n",
    "est_labels, e_conf, return_labels, return_x = post_prob_DS(label2num(est_labels[0:train_num5], class_dic, class_dic_r), ans_train[:train_num5], k, worker_num, num_words)\n",
    "write_prediction(label2num(return_labels, class_dic, class_dic_r), return_x, iter_time, not_ans_train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_groundX2 = []\n",
    "big_groundy2 = []\n",
    "count = 0\n",
    "for n in range(len(return_x)):\n",
    "    if return_x[n] == list(X_true[count]):\n",
    "        big_groundX2.append(X_true[count])\n",
    "        big_groundy2.append(y_true[count])\n",
    "    else:\n",
    "        count += 1\n",
    "        big_groundX2.append(X_true[count])\n",
    "        big_groundy2.append(y_true[count])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1660\n"
     ]
    }
   ],
   "source": [
    "print(len(big_groundX2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "notanstrain is True\n"
     ]
    }
   ],
   "source": [
    "write_prediction(big_groundy2, big_groundX2, 1234567890, not_ans_train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "#deep-learining-modelに渡すデータの書き込み\n",
    "def write_prediction(est_labels, ans_train, iter_num, not_ans_train=False):\n",
    "    w_list = []\n",
    "    if not_ans_train==True:\n",
    "        print(\"notanstrain is True\")\n",
    "        for n in range(len(ans_train)):\n",
    "            for i in range(len(ans_train[n])):\n",
    "                w_list.append(ans_train[n][i] +\" \"+ str(est_labels[n][i]) + \"\\n\")\n",
    "            w_list.append(\"\\n\")\n",
    "    else:\n",
    "        for n in range(len(ans_train)):\n",
    "            for i in range(len(ans_train[n][0])):\n",
    "                w_list.append(ans_train[n][0][i] +\" \"+ str(est_labels[n][i]) + \"\\n\")\n",
    "            w_list.append(\"\\n\")\n",
    "#    w_file = path_w + \"/prediction.txt\"\n",
    "#    with open(w_file, mode='w') as f:\n",
    "#        f.writelines(w_list)\n",
    "    with open(\"./MBEM_outputs/prediction\"+str(iter_num)+\".txt\", mode='w') as f:\n",
    "        f.writelines(w_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#引数:タスク,混同行列,書き込みファイル\n",
    "#出力:ワーカーの回答(ファイルに書き込む)\n",
    "#ワーカーはランダムにとる\n",
    "def generate_ans(X_true, y_true, labelnum_dic, class_dic_r, conf, repeat):\n",
    "    m, k = conf.shape[0], conf.shape[1]\n",
    "    n = len(X_true)\n",
    "    workers_this_example = np.zeros((n,repeat),dtype=np.int)\n",
    "    ans_list = []\n",
    "    for i in range(n):        #m人のワーカーからrepeat人重複なしで選ぶ\n",
    "        workers_this_example[i] = np.sort(np.random.choice(m,repeat,replace=False))\n",
    "        answers = []\n",
    "        for j in workers_this_example[i]:\n",
    "            answers.append(worker_ans(y_true[i], labelnum_dic, class_dic_r, conf[j]))        \n",
    "        ans_list.append([X_true[i], list(workers_this_example[i]),answers])\n",
    "    return ans_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#正解ラベルと混同行列が与えられた時のワーカーの回答ラベル作成\n",
    "def worker_ans(true_labels, labelnum_dic, class_dic_r, conf):\n",
    "    ans_true = [labelnum_dic[y] for y in true_labels]\n",
    "    res_ans = []\n",
    "    a = 0.0\n",
    "    res_pre = -1\n",
    "    for i in range(len(ans_true)):\n",
    "        if sum(conf[ans_true[i],:][:-1]) > 1.0:\n",
    "            print(ans_true[i], conf)\n",
    "        res = np.argmax(np.random.multinomial(1,conf[ans_true[i],:]))\n",
    "        if res == 4:\n",
    "            res_ans.append(class_dic_r[8])\n",
    "        else:\n",
    "            if res_pre == res:\n",
    "                res_ans.append(class_dic_r[res+4])\n",
    "            else:\n",
    "                res_ans.append(class_dic_r[res])\n",
    "        res_pre = res\n",
    "    return res_ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_ans_list(ans_list, worker_num, w_path):\n",
    "    w_str = \"\"\n",
    "    for n in range(len(ans_list)):\n",
    "        for i in range(len(ans_list[n][0])):\n",
    "            w_str += ans_list[n][0][i] + fillin_ans(ans_list[n][1], ans_list[n][2], i, worker_num) + \"\\n\"\n",
    "        w_str += \"\\n\"\n",
    "    with open(w_path, mode='w') as f:\n",
    "        f.write(w_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fillin_ans(workers, answers, i, worker_num):\n",
    "    w_str = \"\"\n",
    "    for w in range(worker_num):\n",
    "        if w in workers:\n",
    "            ans_index = workers.index(w)\n",
    "            w_str += \" \" + answers[ans_index][i]\n",
    "        else:\n",
    "            w_str += \" ?\"\n",
    "    return w_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#シミュレーションデータのワーカ生成\n",
    "#混同行列の作成\n",
    "#引数:ラベル,ワーカーの人数,ワーカーの正解率\n",
    "#返り値:混同行列\n",
    "def generate_conf(class_label, m, gamma, class_wise=1):\n",
    "    k = len(class_label)\n",
    "    conf = (1/float(k))*np.ones((m,k,k))\n",
    "    if class_wise==1:\n",
    "        for i in range(m):\n",
    "            for j in range(k):\n",
    "            # gammaの確率でそのクラスは正解する\n",
    "                if(np.random.uniform(0,1) < gamma):\n",
    "                    conf[i,j,:] = 0\n",
    "                    conf[i,j,j] = 1 \n",
    "                else:\n",
    "                    conf[i,j,:] = 1\n",
    "                    conf[i,j,j] = 1 + np.random.uniform(0.1,0.11)\n",
    "                    conf[i,j,:] = conf[i,j,:]/np.sum(conf[i,j,:])\n",
    "    if class_wise==0:\n",
    "        for i in range(m):\n",
    "        # gammaの確率でワーカーは正解する\n",
    "            if(np.random.uniform(0,1) < gamma):\n",
    "                for j in range(k):\n",
    "                    conf[i,j,:] = 0\n",
    "                    conf[i,j,j] = 1 \n",
    "            else:\n",
    "                for j in range(k):\n",
    "                    conf[i,j,:] = 1\n",
    "                    conf[i,j,j] = 1 + np.random.uniform(0.1,0.11)\n",
    "                    conf[i,j,:] = conf[i,j,:]/np.sum(conf[i,j,:])\n",
    "    return conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "worker_num 46\n",
      "クラス： {'B-LOC': 0, 'B-MISC': 1, 'B-ORG': 2, 'B-PER': 3, 'I-LOC': 4, 'I-MISC': 5, 'I-ORG': 6, 'I-PER': 7, 'O': 8}\n",
      "タスク数 1077\n",
      "タスク数(単語): 14352\n",
      "語彙数 13364\n"
     ]
    }
   ],
   "source": [
    "class_list = list(set(l.split()[1] for l in open(truth_file) if l != \"\\n\"))\n",
    "class_dic = {k:i for i, k in enumerate(sorted(class_list))}\n",
    "class_dic_r = {class_dic[c]:c for c in class_dic}\n",
    "class_label = {'LOC': 0, 'MISC': 1, 'ORG': 2, 'PER': 3, 'O': 4}\n",
    "labelnum_dic = {'B-LOC': 0, 'B-MISC': 1, 'B-ORG': 2, 'B-PER': 3, 'I-LOC': 0, 'I-MISC': 1, 'I-ORG': 2, 'I-PER': 3, 'O': 4}\n",
    "s1 = {'B-LOC': 'B-MISC', 'B-MISC': 'B-ORG', 'B-ORG': 'B-PER', 'B-PER': 'B-LOC', 'I-LOC': 'I-MISC', 'I-MISC': 'I-ORG', 'I-ORG': 'I-PER', 'I-PER': 'I-LOC', 'O':'O'}\n",
    "s2 = {'B-LOC': 'B-ORG', 'B-MISC': 'B-PER', 'B-ORG': 'B-LOC', 'B-PER':'B-MISC' , 'I-LOC': 'I-ORG', 'I-MISC': 'I-PER', 'I-ORG':  'I-LOC', 'I-PER':'I-MISC', 'O':'O'}\n",
    "class_shuffle = [s1, s2]\n",
    "b_tag = ['B-LOC', 'B-MISC', 'B-ORG', 'B-PER']\n",
    "#データの読み込み\n",
    "ans_train, words_dic = load_crowd_data(ans_file, truth_file, train_num5)\n",
    "X_true, y_true = read_output('../MBEM/ner-mturk/ground_truth.txt', class_dic_r)\n",
    "X_true5, y_true5 = read_output('../MBEM/ner-mturk/testset5.txt', class_dic_r)\n",
    "workers_count = []\n",
    "for i in range(len(ans_train)):\n",
    "    for w in ans_train[i][1]:\n",
    "        workers_count.append(w)\n",
    "worker_num = len(set(workers_count))\n",
    "\n",
    "#多分データを変えるごとにクラス確認したくなるので残しておく\n",
    "num_words = 0\n",
    "for l in ans_train:\n",
    "    num_words += len(l[0])\n",
    "print(\"worker_num\", worker_num)\n",
    "print(\"クラス：\",class_dic)\n",
    "print(\"タスク数\",len(ans_train))\n",
    "print(\"タスク数(単語):\", num_words)\n",
    "print(\"語彙数\", len(words_dic))\n",
    "worker_num = 47"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_file(X, Y, filename):\n",
    "    w_str = \"\"\n",
    "    for n in range(len(X)):\n",
    "        for i in range(len(X[n])):\n",
    "            w_str += str(X[n][i]) + \" \"+ str(Y[n][i]) + \"\\n\"\n",
    "        w_str += \"\\n\"\n",
    "    with open(filename, mode='w') as f:\n",
    "        f.write(w_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (4,9) into shape (5,9)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-189-4c6884c63394>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#ans_mは回答(redundancy)×タスク(単語)×ラベル数\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mans_m\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mans_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mans_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mredundancy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mans_m\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mans_m\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-b920c19bcd90>\u001b[0m in \u001b[0;36mans_matrix\u001b[0;34m(ans_train, redundancy, k)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mans_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mans_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m             \u001b[0mans_m\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meye\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mans_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m             \u001b[0mm\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mans_m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not broadcast input array from shape (4,9) into shape (5,9)"
     ]
    }
   ],
   "source": [
    "#ans_mは回答(redundancy)×タスク(単語)×ラベル数\n",
    "ans_m = ans_matrix(ans_train, redundancy, k)\n",
    "ans_m = ans_m.transpose(1, 0, 2) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mv 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (14352,9) (14119,9) (14352,9) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-188-f74f2d56388e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mw_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0msimple_agg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minit_posdis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mredundancy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mans_m\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtask\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mans_train\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-e73d2ac395c6>\u001b[0m in \u001b[0;36minit_posdis\u001b[0;34m(redundancy, ans_m, k)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mmv_ans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_words\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mredundancy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0msimple_agg\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mredundancy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mans_m\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msimple_agg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mmv_ans\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msimple_agg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (14352,9) (14119,9) (14352,9) "
     ]
    }
   ],
   "source": [
    "#Algorithm 1\n",
    "#deep-learining-modelに渡すデータの書き込み\n",
    "w_list = []\n",
    "i = 0\n",
    "simple_agg = init_posdis(redundancy, ans_m, k)\n",
    "for task in ans_train:\n",
    "    for word in task[0]:\n",
    "        w_list.append(word +\" \"+ str(class_dic_r[int(simple_agg[i])]) + \"\\n\")\n",
    "        i += 1\n",
    "    w_list.append(\"\\n\")\n",
    "w_file = path_w + \"/agg_1_alt.txt\"\n",
    "with open(w_file, mode='w') as f:\n",
    "    f.writelines(w_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subprocess.run(['./deep-learning-models/python', 'main.py', 'dataset_reader=normal_bc5cdr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1  iteration\n",
      "\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-57-71c2c31c98be>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#if len(est_labels[0]) == 22:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#    est_labels[0].insert(0, '3')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mest_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me_conf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpost_prob_DS\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel2num\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mest_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtrain_num\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_dic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_dic_r\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mans_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mworker_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_words\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;31m#write_prediction(label2num(est_labels, class_dic, class_dic_r), ans_train, iter_time)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-f28f448dafba>\u001b[0m in \u001b[0;36mpost_prob_DS\u001b[0;34m(est_labels, ans_train, k, worker_num, num_words)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mans_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0;31m#真のラベルの周辺分布を更新\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m             \u001b[0mlabels_md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mest_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mans_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m#各回答ワーカーについて\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m                 \u001b[0mtemp_conf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtemp_conf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mouter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meye\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mest_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meye\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mans_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#外積 混同行列の作成\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "iter_time = 1\n",
    "print(iter_time, \" iteration\\n\")\n",
    "est_labels = get_newest_prediction()\n",
    "#if len(est_labels[0]) == 22:\n",
    "#    est_labels[0].insert(0, '3')\n",
    "est_labels, e_conf = post_prob_DS(label2num(est_labels[0:train_num], class_dic, class_dic_r), ans_train, k, worker_num, num_words)\n",
    "#write_prediction(label2num(est_labels, class_dic, class_dic_r), ans_train, iter_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "single label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Algorithm 1\n",
    "#deep-learining-modelに渡すデータの書き込み\n",
    "w_list = []\n",
    "i = 0\n",
    "simple_agg = init_posdis_single(redundancy, ans_m, k)\n",
    "for task in ans_train:\n",
    "    for word in task[0]:\n",
    "        w_list.append(word +\" \"+ str(class_dic_r[int(simple_agg[i])]) + \"\\n\")\n",
    "        i += 1\n",
    "    w_list.append(\"\\n\")\n",
    "w_file = path_w + \"/agg_mild_single_test2.txt\"\n",
    "with open(w_file, mode='w') as f:\n",
    "    f.writelines(w_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1  iteration\n",
      "\n",
      "labels_md [0.02856942 0.01611608 0.03659928 0.02496302 0.02411777 0.0101289\n",
      " 0.01381982 0.01914489 0.82654082]\n"
     ]
    }
   ],
   "source": [
    "iter_time = 1\n",
    "print(iter_time, \" iteration\\n\")\n",
    "est_labels = get_newest_prediction()\n",
    "est_labels, e_conf = post_prob_DS(label2num(est_labels[0:train_num], class_dic, class_dic_r), ans_train, k, worker_num, num_words)\n",
    "write_prediction(label2num(est_labels, class_dic, class_dic_r), ans_train, iter_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "確率でやりたい時にはこちら"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4  iteration\n",
      "\n",
      "labels_md [0.03498831 0.0160068  0.04957858 0.04780792 0.         0.\n",
      " 0.         0.         0.85161839]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jimmy/.pyenv/versions/anaconda3-5.2.0/lib/python3.6/site-packages/ipykernel_launcher.py:30: RuntimeWarning: divide by zero encountered in log\n"
     ]
    }
   ],
   "source": [
    "iter_time = 4\n",
    "print(iter_time, \" iteration\\n\")\n",
    "est_labels = get_newest_prediction()\n",
    "est_labels, e_conf = post_prob_DS(label2num(est_labels[0:train_num], class_dic, class_dic_r), ans_train, k, worker_num, num_words)\n",
    "write_prediction(label2num(est_labels, class_dic, class_dic_r), ans_train, iter_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5  iteration\n",
      "\n",
      "labels_md [0.03498831 0.0160068  0.04957858 0.04780792 0.         0.\n",
      " 0.         0.         0.85161839]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jimmy/.pyenv/versions/anaconda3-5.2.0/lib/python3.6/site-packages/ipykernel_launcher.py:30: RuntimeWarning: divide by zero encountered in log\n"
     ]
    }
   ],
   "source": [
    "iter_time = 5\n",
    "print(iter_time, \" iteration\\n\")\n",
    "est_labels = get_newest_prediction()\n",
    "est_labels, e_conf = post_prob_DS(label2num(est_labels[0:train_num], class_dic, class_dic_r), ans_train, k, worker_num, num_words)\n",
    "write_prediction(label2num(est_labels, class_dic, class_dic_r), ans_train, iter_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ワーカのタスクに対する回答の事後確率の初期化\n",
    "#Algorithm 1のInitialixe posterior distribution using weighted mv(論文p6)\n",
    "def init_posdis_p(redundancy, ans_m, k):\n",
    "    simple_agg = np.zeros((num_words,k))\n",
    "    mv_ans = np.zeros((num_words))\n",
    "    for r in range(redundancy):\n",
    "        simple_agg += (1/redundancy)*ans_m[r] #simple_aggをmvせずにそのまま使えるようにしたい\n",
    "    return simple_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Algorithm 1\n",
    "#deep-learining-modelに渡すデータの書き込み\n",
    "w_list = [str(class_dic_r)+\"\\n\\n\"]\n",
    "i = 0\n",
    "simple_agg = init_posdis_p(redundancy, ans_m, k)\n",
    "for task in ans_train:\n",
    "    for word in task[0]:\n",
    "        w_list.append(word +\" \"+ str(simple_agg[i])[1:-1] + \"\\n\")\n",
    "        i += 1\n",
    "    w_list.append(\"\\n\")\n",
    "w_file = path_w + \"/simple_agg_p.txt\"\n",
    "with open(w_file, mode='w') as f:\n",
    "    f.writelines(w_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5  iteration\n",
      "\n",
      "labels_md [0.04041827 0.01312667 0.02640166 0.03396618 0.00496885 0.00904776\n",
      " 0.0120884  0.02921982 0.83076239]\n"
     ]
    }
   ],
   "source": [
    "iter_time = 5\n",
    "print(iter_time, \" iteration\\n\")\n",
    "est_labels = get_newest_prediction()\n",
    "#if len(est_labels[0]) == 22:\n",
    "#    est_labels[0].insert(0, '3')\n",
    "est_labels, e_conf = post_prob_DS(label2num(est_labels[0:train_num5], class_dic, class_dic_r), ans_train, k, worker_num, num_words)\n",
    "write_prediction(label2num(est_labels, class_dic, class_dic_r), ans_train, iter_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'simple_pred' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-f6ae168b7ffd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mest_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0msimple_pred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msimple_pred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miteration_times\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\" iteration\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m#simple_pred(weighed mv)とans_train(回答と回答ワーカ)を使って学習\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m#simple_predを使うのは事前分布のため\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'simple_pred' is not defined"
     ]
    }
   ],
   "source": [
    "est_labels = simple_pred\n",
    "for t in range(iteration_times):\n",
    "    print(t, \" iteration\\n\")\n",
    "    #simple_pred(weighed mv)とans_train(回答と回答ワーカ)を使って学習\n",
    "    #simple_predを使うのは事前分布のため\n",
    "    #学習機のtrainと推定ラベルの更新\n",
    "    model, est_labels = train(words_dic, class_dic, ans_train, est_labels)\n",
    "    #est_labelsで混同行列の更新\n",
    "    est_labels, e_conf = post_prob_DS(est_labels, ans_train, k, worker_num)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
