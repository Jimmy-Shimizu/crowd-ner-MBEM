{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import collections\n",
    "import glob\n",
    "import numpy as np\n",
    "import os\n",
    "import subprocess\n",
    "import torch\n",
    "import torch.autograd as autograd\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import re\n",
    "import random\n",
    "\n",
    "from itertools import groupby\n",
    "torch.manual_seed(1)\n",
    "\n",
    "ans_path = './ner-mturk/answers*'\n",
    "ans_file_list = sorted(glob.glob(ans_path))\n",
    "single_ans_list = sorted(glob.glob('ner-mturk/single_ans*'))\n",
    "truth_file = './ner-mturk/ground_truth.txt'\n",
    "path_w = './MBEM_outputs'\n",
    "alltask_num = 5985\n",
    "train_num = 5385\n",
    "train_num5 = 1077\n",
    "test_num = 600\n",
    "alltype_num = 9859\n",
    "type_train_num = 9089\n",
    "type_test_num = 368\n",
    "k = 9\n",
    "redundancy = 5\n",
    "iteration_times = 5\n",
    "#ans_file = ans_file_list[5]\n",
    "#ans_file = single_ans_list[1]\n",
    "ans_file = '../MBEM/ner-mturk/testK2O_3.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ans(workers, answers):\n",
    "    ans_label = []\n",
    "    for a in workers:\n",
    "        ans_label.append(class_dic[answers[a]])\n",
    "    return ans_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_n_ans(answers, n):\n",
    "    ans = []\n",
    "    for k in range(len(answers)):\n",
    "        ans.append(answers[k][n])\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tupleには対応していないので返り値用に多重配列作り直した方がいいかもしれない\n",
    "def label2num(answers, class_dic, class_dic_r):\n",
    "    ans_return = copy.deepcopy(answers)\n",
    "    if answers[0][0] in class_dic:\n",
    "        for i in range(len(answers)):\n",
    "            for w in range(len(answers[i])):\n",
    "                ans_return[i][w] = class_dic[answers[i][w]]\n",
    "    elif answers[0][0] in class_dic_r:\n",
    "        for i in range(len(answers)):\n",
    "            for w in range(len(answers[i])):\n",
    "                ans_return[i][w] = class_dic_r[int(answers[i][w])]\n",
    "    else: print(\"error\")\n",
    "    return ans_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_output(path, class_dic_r, to_label=False):\n",
    "    f = open(path)\n",
    "    make_xypair = lambda v: list(zip(*[l.strip().split() for l in v]))\n",
    "    is_emptyline = lambda x: x.strip() != '' and not x.startswith('-DOCSTART-')\n",
    "    list_int = lambda t: list([class_dic_r[int(v)] for v in t])\n",
    "    xypairs = [make_xypair(v) for k, v in groupby(f, is_emptyline) if k]\n",
    "    if to_label == True:\n",
    "        return ([p[0] for p in xypairs], [list(list_int(p[1])) for p in xypairs])\n",
    "    if len(xypairs[0]) == 2:\n",
    "        return ([p[0] for p in xypairs], [list(p[1]) for p in xypairs])\n",
    "    else:\n",
    "        return ([p[0] for p in xypairs], [list(p[1:]) for p in xypairs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_crowd_data(ans_file, truth_file, train_num):\n",
    "    #ここからanswersの格納\n",
    "    #answers_list[task_num] = [[words, ...], [回答者], [[answers(one hot ベクトル)]...]]\n",
    "    answers_list = []\n",
    "    sentence = []\n",
    "    answers = []\n",
    "    worker = []\n",
    "    words_dic = {}\n",
    "    get_worker = lambda x: tuple([i for i, l in enumerate(x) if l !='?'])\n",
    "    for l in open(ans_file):\n",
    "        ans = l.split()\n",
    "        if len(l) < 2:\n",
    "            answers_list.append([sentence, worker, answers])\n",
    "            sentence = []\n",
    "            worker = []\n",
    "            answers = []\n",
    "        else:\n",
    "            if len(worker) < 1:\n",
    "                worker = get_worker(ans[1:])\n",
    "            if not ans[0] in words_dic:\n",
    "                words_dic[ans[0]] = len(words_dic)\n",
    "            sentence.append(ans[0])\n",
    "            answers.append(get_ans(worker, ans[1:]))            \n",
    "    #truth_list: [(task_word, answer), ....]\n",
    "    truth_list = [tuple(l.split()) for l in open(truth_file) if l != \"\\n\"]\n",
    "    ans_train = answers_list[0:train_num]\n",
    "#    ans_test = answers_list[train_num:]\n",
    "    return ans_train, words_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ans_matrix(ans_train, redundancy, k):\n",
    "    ans_m = np.zeros((num_words, redundancy,k))\n",
    "    m = 0\n",
    "    for n in range(len(ans_train)):\n",
    "        for i in range(len(ans_train[n][0])):\n",
    "            ans_m[m] = np.eye(k)[ans_train[n][2][i][:5]]\n",
    "            m += 1\n",
    "    return ans_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [],
   "source": [
    "#deep-learning-modelからのデータの読み込み\n",
    "def get_newest_prediction():\n",
    "    files_list = glob.glob(\"./deep-learning-model/outputs/*\")\n",
    "    latest_file = max(glob.glob(max(files_list, key=os.path.getctime)+\"/*\"), key=os.path.getctime) + \"/best_model_log/pred.txt\"\n",
    "    prediction_list = [list(l.split()) for l in open(latest_file) if l != \"\\n\"]\n",
    "    return prediction_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ワーカのタスクに対する回答の事後確率の初期化\n",
    "#Algorithm 1のInitialixe posterior distribution using weighted mv(論文p6)\n",
    "def init_posdis(redundancy, ans_m, k):\n",
    "    simple_agg = np.zeros((num_words,k))\n",
    "    mv_ans = np.zeros((num_words))\n",
    "    for r in range(redundancy):\n",
    "        simple_agg += (1/redundancy)*ans_m[r]\n",
    "    for i in range(len(simple_agg)):\n",
    "        mv_ans[i] = np.argmax(simple_agg[i])\n",
    "    return mv_ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ワーカのタスクに対する回答の事後確率の初期化\n",
    "#mvしない場合\n",
    "def init_posdis_single(redundancy, ans_m, k):\n",
    "    simple_agg = np.zeros((num_words,k))\n",
    "    mv_ans = np.zeros((num_words))\n",
    "    simple_agg += (1/redundancy)*ans_m[0]\n",
    "    for i in range(len(simple_agg)):\n",
    "        mv_ans[i] = np.argmax(simple_agg[i])\n",
    "    return mv_ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [],
   "source": [
    "def post_prob_DS(est_labels, ans_train, k, worker_num, num_words):\n",
    "    #学習機とラベルの更新\n",
    "    n = len(ans_train)\n",
    "    m = worker_num\n",
    "    e_conf = np.zeros((m,k,k))\n",
    "    temp_conf = (1/float(k))*np.ones((m,k,k))\n",
    "    labels_md = np.zeros((k))\n",
    "    worker_acc = np.zeros((m,k)) #ワーカーの信頼度\n",
    "    task_acc = np.zeros((n, k))\n",
    "    #est_labelsを正解ラベルとして混同行列を作成 式(7)\n",
    "    for i in range(n):\n",
    "        for l in range(len(ans_train[i][2])):\n",
    "            #真のラベルの周辺分布を更新\n",
    "            labels_md[int(est_labels[i][l])] += 1\n",
    "            for a, j in enumerate(ans_train[i][1]): #各回答ワーカーについて\n",
    "                temp_conf[j,:,:] = temp_conf[j,:,:] + np.outer(np.eye(k)[int(est_labels[i][l])],np.eye(k)[ans_train[i][2][l][a]]) #外積 混同行列の作成\n",
    "    #temp_confの正規化\n",
    "    for j in range(m):  \n",
    "        for r in range(k):\n",
    "            e_conf[j,:,:] = np.divide(temp_conf[j,:,:],np.outer(np.sum(temp_conf[j,:,:],axis =1),np.ones(k)))\n",
    "    labels_md = np.divide(labels_md, np.sum(labels_md)*np.ones(k))\n",
    "#    print(\"labels_md\", labels_md)\n",
    "    #混同行列を使って真のラベル推定(論文p5の(5)式)\n",
    "    for i in range(n):\n",
    "        for l in range(len(ans_train[i][2])):\n",
    "            temp_class = 0.0\n",
    "            for r, a in enumerate(ans_train[i][1]):\n",
    "                #混同行列の該当列をとる\n",
    "                temp_acc = np.log(np.dot(e_conf[a,:,:],np.transpose(np.eye(k)[ans_train[i][2][l][r]])))\n",
    "                temp_class = temp_class + temp_acc\n",
    "            temp_class = np.log(labels_md) +temp_class\n",
    "            est_labels[i][l] = np.argmax(temp_class)\n",
    "    return est_labels, e_conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "#deep-learining-modelに渡すデータの書き込み\n",
    "def write_prediction(est_labels, ans_train, iter_num):\n",
    "    w_list = []\n",
    "    for n in range(len(ans_train)):\n",
    "        for i in range(len(ans_train[n][0])):\n",
    "            w_list.append(ans_train[n][0][i] +\" \"+ str(est_labels[n][i]) + \"\\n\")\n",
    "        w_list.append(\"\\n\")\n",
    "    w_file = path_w + \"/prediction.txt\"\n",
    "    with open(w_file, mode='w') as f:\n",
    "        f.writelines(w_list)\n",
    "    with open(\"./MBEM_outputs/prediction\"+str(iter_num)+\".txt\", mode='w') as f:\n",
    "        f.writelines(w_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#引数:タスク,混同行列,書き込みファイル\n",
    "#出力:ワーカーの回答(ファイルに書き込む)\n",
    "#ワーカーはランダムにとる\n",
    "def generate_ans(X_true, y_true, labelnum_dic, class_dic_r, conf, repeat):\n",
    "    m, k = conf.shape[0], conf.shape[1]\n",
    "    n = len(X_true)\n",
    "    workers_this_example = np.zeros((n,repeat),dtype=np.int)\n",
    "    ans_list = []\n",
    "    for i in range(n):        #m人のワーカーからrepeat人重複なしで選ぶ\n",
    "        workers_this_example[i] = np.sort(np.random.choice(m,repeat,replace=False))\n",
    "        answers = []\n",
    "        for j in workers_this_example[i]:\n",
    "            answers.append(worker_ans(y_true[i], labelnum_dic, class_dic_r, conf[j]))        \n",
    "        ans_list.append([X_true[i], list(workers_this_example[i]),answers])\n",
    "    return ans_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#正解ラベルと混同行列が与えられた時のワーカーの回答ラベル作成\n",
    "def worker_ans(true_labels, labelnum_dic, class_dic_r, conf):\n",
    "    ans_true = [labelnum_dic[y] for y in true_labels]\n",
    "    res_ans = []\n",
    "    a = 0.0\n",
    "    res_pre = -1\n",
    "    for i in range(len(ans_true)):\n",
    "        if sum(conf[ans_true[i],:][:-1]) > 1.0:\n",
    "            print(ans_true[i], conf)\n",
    "        res = np.argmax(np.random.multinomial(1,conf[ans_true[i],:]))\n",
    "        if res == 4:\n",
    "            res_ans.append(class_dic_r[8])\n",
    "        else:\n",
    "            if res_pre == res:\n",
    "                res_ans.append(class_dic_r[res+4])\n",
    "            else:\n",
    "                res_ans.append(class_dic_r[res])\n",
    "        res_pre = res\n",
    "    return res_ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_ans_list(ans_list, worker_num, w_path):\n",
    "    w_str = \"\"\n",
    "    for n in range(len(ans_list)):\n",
    "        for i in range(len(ans_list[n][0])):\n",
    "            w_str += ans_list[n][0][i] + fillin_ans(ans_list[n][1], ans_list[n][2], i, worker_num) + \"\\n\"\n",
    "        w_str += \"\\n\"\n",
    "    with open(w_path, mode='w') as f:\n",
    "        f.write(w_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fillin_ans(workers, answers, i, worker_num):\n",
    "    w_str = \"\"\n",
    "    for w in range(worker_num):\n",
    "        if w in workers:\n",
    "            ans_index = workers.index(w)\n",
    "            w_str += \" \" + answers[ans_index][i]\n",
    "        else:\n",
    "            w_str += \" ?\"\n",
    "    return w_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#シミュレーションデータのワーカ生成\n",
    "#混同行列の作成\n",
    "#引数:ラベル,ワーカーの人数,ワーカーの正解率\n",
    "#返り値:混同行列\n",
    "def generate_conf(class_label, m, gamma, class_wise=1):\n",
    "    k = len(class_label)\n",
    "    conf = (1/float(k))*np.ones((m,k,k))\n",
    "    if class_wise==1:\n",
    "        for i in range(m):\n",
    "            for j in range(k):\n",
    "            # gammaの確率でそのクラスは正解する\n",
    "                if(np.random.uniform(0,1) < gamma):\n",
    "                    conf[i,j,:] = 0\n",
    "                    conf[i,j,j] = 1 \n",
    "                else:\n",
    "                    conf[i,j,:] = 1\n",
    "                    conf[i,j,j] = 1 + np.random.uniform(0.1,0.11)\n",
    "                    conf[i,j,:] = conf[i,j,:]/np.sum(conf[i,j,:])\n",
    "    if class_wise==0:\n",
    "        for i in range(m):\n",
    "        # gammaの確率でワーカーは正解する\n",
    "            if(np.random.uniform(0,1) < gamma):\n",
    "                for j in range(k):\n",
    "                    conf[i,j,:] = 0\n",
    "                    conf[i,j,j] = 1 \n",
    "            else:\n",
    "                for j in range(k):\n",
    "                    conf[i,j,:] = 1\n",
    "                    conf[i,j,j] = 1 + np.random.uniform(0.1,0.11)\n",
    "                    conf[i,j,:] = conf[i,j,:]/np.sum(conf[i,j,:])\n",
    "    return conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "worker_num 47\n",
      "クラス： {'B-LOC': 0, 'B-MISC': 1, 'B-ORG': 2, 'B-PER': 3, 'I-LOC': 4, 'I-MISC': 5, 'I-ORG': 6, 'I-PER': 7, 'O': 8}\n",
      "タスク数 1077\n",
      "タスク数(単語): 14352\n",
      "語彙数 12378\n"
     ]
    }
   ],
   "source": [
    "class_list = list(set(l.split()[1] for l in open(truth_file) if l != \"\\n\"))\n",
    "class_dic = {k:i for i, k in enumerate(sorted(class_list))}\n",
    "class_dic_r = {class_dic[c]:c for c in class_dic}\n",
    "class_label = {'LOC': 0, 'MISC': 1, 'ORG': 2, 'PER': 3, 'O': 4}\n",
    "labelnum_dic = {'B-LOC': 0, 'B-MISC': 1, 'B-ORG': 2, 'B-PER': 3, 'I-LOC': 0, 'I-MISC': 1, 'I-ORG': 2, 'I-PER': 3, 'O': 4}\n",
    "s1 = {'B-LOC': 'B-MISC', 'B-MISC': 'B-ORG', 'B-ORG': 'B-PER', 'B-PER': 'B-LOC', 'I-LOC': 'I-MISC', 'I-MISC': 'I-ORG', 'I-ORG': 'I-PER', 'I-PER': 'I-LOC', 'O':'O'}\n",
    "s2 = {'B-LOC': 'B-ORG', 'B-MISC': 'B-PER', 'B-ORG': 'B-LOC', 'B-PER':'B-MISC' , 'I-LOC': 'I-ORG', 'I-MISC': 'I-PER', 'I-ORG':  'I-LOC', 'I-PER':'I-MISC', 'O':'O'}\n",
    "class_shuffle = [s1, s2]\n",
    "b_tag = ['B-LOC', 'B-MISC', 'B-ORG', 'B-PER']\n",
    "#データの読み込み\n",
    "ans_train, words_dic = load_crowd_data(ans_file, truth_file, train_num5)\n",
    "X_true, y_true = read_output('../MBEM/ner-mturk/ground_truth.txt', class_dic_r)\n",
    "X_true5, y_true5 = read_output('../MBEM/ner-mturk/testset5.txt', class_dic_r)\n",
    "workers_count = []\n",
    "for i in range(len(ans_train)):\n",
    "    for w in ans_train[i][1]:\n",
    "        workers_count.append(w)\n",
    "worker_num = len(set(workers_count))\n",
    "\n",
    "#多分データを変えるごとにクラス確認したくなるので残しておく\n",
    "num_words = 0\n",
    "for l in ans_train:\n",
    "    num_words += len(l[0])\n",
    "print(\"worker_num\", worker_num)\n",
    "print(\"クラス：\",class_dic)\n",
    "print(\"タスク数\",len(ans_train))\n",
    "print(\"タスク数(単語):\", num_words)\n",
    "print(\"語彙数\", len(words_dic))\n",
    "worker_num = 47"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 721,
   "metadata": {},
   "outputs": [],
   "source": [
    "def div_xy_by_tasks_1gram(X, Y):\n",
    "    y_bool = [[0 if w=='O' else 1 for w in s] for s in Y]\n",
    "    y_entity = []\n",
    "    x_entity = []\n",
    "    for xs, ys in zip(X,Y):\n",
    "        entity_index = [n for n, v in enumerate(ys) if re.match(r\"B-\", v)]\n",
    "        is_entity, entity_xs, entity_ys = False, False, False\n",
    "        for i in range(len(ys)):\n",
    "            if ys[i] == 'O':\n",
    "                is_entity == False\n",
    "            elif i in entity_index:\n",
    "                if entity_ys:\n",
    "                    if i == len(ys)-1:\n",
    "                        entity_ys.append('O')\n",
    "                        entity_xs.append('END_TAG')                        \n",
    "                    else:\n",
    "                        entity_ys.append(ys[i+1])\n",
    "                        entity_xs.append(xs[i+1])\n",
    "                    y_entity.append(entity_ys)\n",
    "                    x_entity.append(entity_xs)\n",
    "                if i == 0:                    \n",
    "                    entity_ys = ['O', ys[i]]\n",
    "                    entity_xs = ['BEGIN_TAG', xs[i]]\n",
    "                else:\n",
    "                    entity_ys = [ys[i-1],ys[i]]\n",
    "                    entity_xs = [xs[i-1],xs[i]]                    \n",
    "                is_entity = True\n",
    "            elif is_entity == True:\n",
    "                entity_ys.append(ys[i])\n",
    "                entity_xs.append(xs[i])\n",
    "        if entity_ys != False:\n",
    "            y_entity.append(entity_ys)\n",
    "            x_entity.append(entity_xs)\n",
    "    return y_bool, x_entity, y_entity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def div_xy_by_tasks(X, Y):\n",
    "    y_bool = [[0 if w=='O' else 1 for w in s] for s in Y]\n",
    "    y_entity = []\n",
    "    x_entity = []\n",
    "    for xs, ys in zip(X,Y):\n",
    "        entity_index = [n for n, v in enumerate(ys) if re.match(r\"B-\", v)]\n",
    "        is_entity, entity_xs, entity_ys = False, False, False\n",
    "        for i in range(len(ys)):\n",
    "            if ys[i] == 'O':\n",
    "                is_entity == False\n",
    "            elif i in entity_index:\n",
    "                if entity_ys:\n",
    "                    y_entity.append(entity_ys)\n",
    "                    x_entity.append(entity_xs)\n",
    "                entity_ys = [ys[i]]\n",
    "                entity_xs = [xs[i]]\n",
    "                is_entity = True\n",
    "            elif is_entity == True:\n",
    "                entity_ys.append(ys[i])\n",
    "                entity_xs.append(xs[i])\n",
    "        if entity_ys != False:\n",
    "            y_entity.append(entity_ys)\n",
    "            x_entity.append(entity_xs)\n",
    "    return y_bool, x_entity, y_entity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_file(X, Y, filename):\n",
    "    w_str = \"\"\n",
    "    if flat = True:\n",
    "        w_str += str(X[n]) + \" \"+ str(Y[n]) + \"\\n\"\n",
    "        for n in range(len(X)):\n",
    "    for n in range(len(X)):\n",
    "        for i in range(len(X[n])):\n",
    "            w_str += str(X[n][i]) + \" \"+ str(Y[n][i]) + \"\\n\"\n",
    "        w_str += \"\\n\"\n",
    "    with open(filename, mode='w') as f:\n",
    "        f.write(w_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 693,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_bool, x_entity, y_entity = div_xy_by_tasks(X_true, y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 723,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, x_entity_1g, y_entity_1g = div_xy_by_tasks_1gram(X_true[:5385], y_true[:5385])\n",
    "write_file(x_entity_1g, y_entity_1g, '../MBEM/booltype_data/ner-type-1gramBEtag-train.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 654,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bool2task(X, y_bool):\n",
    "    X_type = []\n",
    "    y_type = []\n",
    "    for xs, ys in zip(X, y_bool):\n",
    "        x_task = []\n",
    "        y_task = []\n",
    "        for i in range(len(xs)):\n",
    "            if ys[i]=='1':\n",
    "                x_task.append(xs[i])\n",
    "                y_task.append('B-PER')\n",
    "            else:\n",
    "                if len(x_task) != 0:\n",
    "                    X_type.append(x_task)\n",
    "                    y_type.append(y_task)\n",
    "                x_task, y_task = [], []\n",
    "    return X_type, y_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 713,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_test_truedata(X, y_true, y_bool, filename):\n",
    "    X_type = []\n",
    "    y_type = []\n",
    "    for n in range(len(X)):\n",
    "        x_task = []\n",
    "        y_task = []\n",
    "        for i in range(len(X[n])):\n",
    "            if int(y_bool[n][i])==1:\n",
    "                x_task.append(X[n][i])\n",
    "                y_task.append(y_true[n][i])\n",
    "            else:\n",
    "                if len(x_task) != 0:\n",
    "                    X_type.append(x_task)\n",
    "                    y_type.append(y_task)\n",
    "                x_task, y_task = [], []\n",
    "    write_file(X_type, y_type, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 714,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_test_truedata(X_true, y_true, y_bool, '../MBEM/booltype_data/ner-bool2type-typetrue.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 704,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_type, y_type = bool2task(X_true[:5385], est_labels[:5385])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 667,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write_file(X_true[5385:], y_bool, '../MBEM/ner-mturk/ner-bool-test.txt')\n",
    "write_file(X_true, y_type, '../MBEM/booltype_data/ner-bool2type-test.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ans_mは回答(redundancy)×タスク(単語)×ラベル数\n",
    "ans_m = ans_matrix(ans_train, redundancy, k)\n",
    "ans_m = ans_m.transpose(1, 0, 2) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mv 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Algorithm 1\n",
    "#deep-learining-modelに渡すデータの書き込み\n",
    "w_list = []\n",
    "i = 0\n",
    "simple_agg = init_posdis(redundancy, ans_m, k)\n",
    "for task in ans_train:\n",
    "    for word in task[0]:\n",
    "        w_list.append(word +\" \"+ str(class_dic_r[int(simple_agg[i])]) + \"\\n\")\n",
    "        i += 1\n",
    "    w_list.append(\"\\n\")\n",
    "w_file = path_w + \"/agg_single_K2O_3_small.txt\"\n",
    "with open(w_file, mode='w') as f:\n",
    "    f.writelines(w_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subprocess.run(['./deep-learning-models/python', 'main.py', 'dataset_reader=normal_bc5cdr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1  iteration\n",
      "\n",
      "labels_md [6.72143920e-02 2.52850768e-02 2.59225158e-02 2.04688717e-02\n",
      " 9.20745095e-04 6.37438912e-04 4.53289893e-03 5.17033784e-03\n",
      " 8.49847723e-01]\n"
     ]
    }
   ],
   "source": [
    "iter_time = 1\n",
    "print(iter_time, \" iteration\\n\")\n",
    "est_labels = get_newest_prediction()\n",
    "#if len(est_labels[0]) == 22:\n",
    "#    est_labels[0].insert(0, '3')\n",
    "est_labels, e_conf = post_prob_DS(label2num(est_labels[0:train_num5], class_dic, class_dic_r), ans_train, k, worker_num, num_words)\n",
    "write_prediction(label2num(est_labels, class_dic, class_dic_r), ans_train, iter_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "single label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Algorithm 1\n",
    "#deep-learining-modelに渡すデータの書き込み\n",
    "w_list = []\n",
    "i = 0\n",
    "simple_agg = init_posdis_single(redundancy, ans_m, k)\n",
    "for task in ans_train:\n",
    "    for word in task[0]:\n",
    "        w_list.append(word +\" \"+ str(class_dic_r[int(simple_agg[i])]) + \"\\n\")\n",
    "        i += 1\n",
    "    w_list.append(\"\\n\")\n",
    "w_file = path_w + \"/agg_mild_single_test2.txt\"\n",
    "with open(w_file, mode='w') as f:\n",
    "    f.writelines(w_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1  iteration\n",
      "\n",
      "labels_md [0.02856942 0.01611608 0.03659928 0.02496302 0.02411777 0.0101289\n",
      " 0.01381982 0.01914489 0.82654082]\n"
     ]
    }
   ],
   "source": [
    "iter_time = 1\n",
    "print(iter_time, \" iteration\\n\")\n",
    "est_labels = get_newest_prediction()\n",
    "est_labels, e_conf = post_prob_DS(label2num(est_labels[0:train_num], class_dic, class_dic_r), ans_train, k, worker_num, num_words)\n",
    "write_prediction(label2num(est_labels, class_dic, class_dic_r), ans_train, iter_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "確率でやりたい時にはこちら"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4  iteration\n",
      "\n",
      "labels_md [0.03498831 0.0160068  0.04957858 0.04780792 0.         0.\n",
      " 0.         0.         0.85161839]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jimmy/.pyenv/versions/anaconda3-5.2.0/lib/python3.6/site-packages/ipykernel_launcher.py:30: RuntimeWarning: divide by zero encountered in log\n"
     ]
    }
   ],
   "source": [
    "iter_time = 4\n",
    "print(iter_time, \" iteration\\n\")\n",
    "est_labels = get_newest_prediction()\n",
    "est_labels, e_conf = post_prob_DS(label2num(est_labels[0:train_num], class_dic, class_dic_r), ans_train, k, worker_num, num_words)\n",
    "write_prediction(label2num(est_labels, class_dic, class_dic_r), ans_train, iter_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5  iteration\n",
      "\n",
      "labels_md [0.03498831 0.0160068  0.04957858 0.04780792 0.         0.\n",
      " 0.         0.         0.85161839]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jimmy/.pyenv/versions/anaconda3-5.2.0/lib/python3.6/site-packages/ipykernel_launcher.py:30: RuntimeWarning: divide by zero encountered in log\n"
     ]
    }
   ],
   "source": [
    "iter_time = 5\n",
    "print(iter_time, \" iteration\\n\")\n",
    "est_labels = get_newest_prediction()\n",
    "est_labels, e_conf = post_prob_DS(label2num(est_labels[0:train_num], class_dic, class_dic_r), ans_train, k, worker_num, num_words)\n",
    "write_prediction(label2num(est_labels, class_dic, class_dic_r), ans_train, iter_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ワーカのタスクに対する回答の事後確率の初期化\n",
    "#Algorithm 1のInitialixe posterior distribution using weighted mv(論文p6)\n",
    "def init_posdis_p(redundancy, ans_m, k):\n",
    "    simple_agg = np.zeros((num_words,k))\n",
    "    mv_ans = np.zeros((num_words))\n",
    "    for r in range(redundancy):\n",
    "        simple_agg += (1/redundancy)*ans_m[r] #simple_aggをmvせずにそのまま使えるようにしたい\n",
    "    return simple_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Algorithm 1\n",
    "#deep-learining-modelに渡すデータの書き込み\n",
    "w_list = [str(class_dic_r)+\"\\n\\n\"]\n",
    "i = 0\n",
    "simple_agg = init_posdis_p(redundancy, ans_m, k)\n",
    "for task in ans_train:\n",
    "    for word in task[0]:\n",
    "        w_list.append(word +\" \"+ str(simple_agg[i])[1:-1] + \"\\n\")\n",
    "        i += 1\n",
    "    w_list.append(\"\\n\")\n",
    "w_file = path_w + \"/simple_agg_p.txt\"\n",
    "with open(w_file, mode='w') as f:\n",
    "    f.writelines(w_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5  iteration\n",
      "\n",
      "labels_md [0.04041827 0.01312667 0.02640166 0.03396618 0.00496885 0.00904776\n",
      " 0.0120884  0.02921982 0.83076239]\n"
     ]
    }
   ],
   "source": [
    "iter_time = 5\n",
    "print(iter_time, \" iteration\\n\")\n",
    "est_labels = get_newest_prediction()\n",
    "#if len(est_labels[0]) == 22:\n",
    "#    est_labels[0].insert(0, '3')\n",
    "est_labels, e_conf = post_prob_DS(label2num(est_labels[0:train_num5], class_dic, class_dic_r), ans_train, k, worker_num, num_words)\n",
    "write_prediction(label2num(est_labels, class_dic, class_dic_r), ans_train, iter_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'simple_pred' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-f6ae168b7ffd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mest_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0msimple_pred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msimple_pred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miteration_times\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\" iteration\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m#simple_pred(weighed mv)とans_train(回答と回答ワーカ)を使って学習\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m#simple_predを使うのは事前分布のため\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'simple_pred' is not defined"
     ]
    }
   ],
   "source": [
    "est_labels = simple_pred\n",
    "for t in range(iteration_times):\n",
    "    print(t, \" iteration\\n\")\n",
    "    #simple_pred(weighed mv)とans_train(回答と回答ワーカ)を使って学習\n",
    "    #simple_predを使うのは事前分布のため\n",
    "    #学習機のtrainと推定ラベルの更新\n",
    "    model, est_labels = train(words_dic, class_dic, ans_train, est_labels)\n",
    "    #est_labelsで混同行列の更新\n",
    "    est_labels, e_conf = post_prob_DS(est_labels, ans_train, k, worker_num)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
