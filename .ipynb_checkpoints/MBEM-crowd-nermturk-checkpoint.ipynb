{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import collections\n",
    "import glob\n",
    "import numpy as np\n",
    "import os\n",
    "import subprocess\n",
    "import torch\n",
    "import torch.autograd as autograd\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import random\n",
    "\n",
    "from itertools import groupby\n",
    "torch.manual_seed(1)\n",
    "\n",
    "ans_path = './ner-mturk/answers*'\n",
    "ans_file_list = sorted(glob.glob(ans_path))\n",
    "single_ans_list = sorted(glob.glob('ner-mturk/single_ans*'))\n",
    "truth_file = './ner-mturk/ground_truth.txt'\n",
    "path_w = './MBEM_outputs'\n",
    "train_num = 5385\n",
    "train_num5 = 1077\n",
    "test_num = 600\n",
    "k = 9\n",
    "redundancy = 5\n",
    "iteration_times = 5\n",
    "#ans_file = ans_file_list[5]\n",
    "ans_file = single_ans_list[1]\n",
    "#ans_file = '../MBEM/ner-mturk/sim_data_cw0_08.txt'\n",
    "#ans_file = '../MBEM/ner-mturk/sim_data_single_cw0_07.txt'\n",
    "#ans_file = '../MBEM/ner-mturk/mild_single_07.txt'\n",
    "#ans_file = '../MBEM/ner-mturk/testO2K_05.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ans(workers, answers):\n",
    "    ans_label = []\n",
    "    for a in workers:\n",
    "        ans_label.append(class_dic[answers[a]])\n",
    "    return ans_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_n_ans(answers, n):\n",
    "    ans = []\n",
    "    for k in range(len(answers)):\n",
    "        ans.append(answers[k][n])\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tupleには対応していないので返り値用に多重配列作り直した方がいいかもしれない\n",
    "def label2num(answers, class_dic, class_dic_r):\n",
    "    ans_return = copy.deepcopy(answers)\n",
    "    if answers[0][0] in class_dic:\n",
    "        for i in range(len(answers)):\n",
    "            for w in range(len(answers[i])):\n",
    "                ans_return[i][w] = class_dic[answers[i][w]]\n",
    "    elif answers[0][0] in class_dic_r:\n",
    "        for i in range(len(answers)):\n",
    "            for w in range(len(answers[i])):\n",
    "                ans_return[i][w] = class_dic_r[int(answers[i][w])]\n",
    "    else: print(\"error\")\n",
    "    return ans_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_output(path, class_dic_r, to_label=False):\n",
    "    f = open(path)\n",
    "    make_xypair = lambda v: list(zip(*[l.strip().split() for l in v]))\n",
    "    is_emptyline = lambda x: x.strip() != '' and not x.startswith('-DOCSTART-')\n",
    "    list_int = lambda t: list([class_dic_r[int(v)] for v in t])\n",
    "    xypairs = [make_xypair(v) for k, v in groupby(f, is_emptyline) if k]\n",
    "    if to_label == True:\n",
    "        return ([p[0] for p in xypairs], [list(list_int(p[1])) for p in xypairs])\n",
    "    if len(xypairs[0]) == 2:\n",
    "        return ([p[0] for p in xypairs], [list(p[1]) for p in xypairs])\n",
    "    else:\n",
    "        return ([p[0] for p in xypairs], [list(p[1:]) for p in xypairs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_crowd_data(ans_file, truth_file, train_num):\n",
    "    #ここからanswersの格納\n",
    "    #answers_list[task_num] = [[words, ...], [回答者], [[answers(one hot ベクトル)]...]]\n",
    "    answers_list = []\n",
    "    sentence = []\n",
    "    answers = []\n",
    "    worker = []\n",
    "    words_dic = {}\n",
    "    get_worker = lambda x: tuple([i for i, l in enumerate(x) if l !='?'])\n",
    "    for l in open(ans_file):\n",
    "        ans = l.split()\n",
    "        if len(l) < 2:\n",
    "            answers_list.append([sentence, worker, answers])\n",
    "            sentence = []\n",
    "            worker = []\n",
    "            answers = []\n",
    "        else:\n",
    "            if len(worker) < 1:\n",
    "                worker = get_worker(ans[1:])\n",
    "            if not ans[0] in words_dic:\n",
    "                words_dic[ans[0]] = len(words_dic)\n",
    "            sentence.append(ans[0])\n",
    "            answers.append(get_ans(worker, ans[1:]))            \n",
    "    #truth_list: [(task_word, answer), ....]\n",
    "    truth_list = [tuple(l.split()) for l in open(truth_file) if l != \"\\n\"]\n",
    "    ans_train = answers_list[0:train_num]\n",
    "#    ans_test = answers_list[train_num:]\n",
    "    return ans_train, words_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ans_matrix(ans_train, redundancy, k):\n",
    "    ans_m = np.zeros((num_words, redundancy,k))\n",
    "    m = 0\n",
    "    for n in range(len(ans_train)):\n",
    "        for i in range(len(ans_train[n][0])):\n",
    "            ans_m[m] = np.eye(k)[ans_train[n][2][i][:5]]\n",
    "            m += 1\n",
    "    return ans_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "#deep-learning-modelからのデータの読み込み\n",
    "def get_newest_prediction():\n",
    "    files_list = glob.glob(\"./deep-learning-model/outputs/*\")\n",
    "    latest_file = max(glob.glob(max(files_list, key=os.path.getctime)+\"/*\"), key=os.path.getctime) + \"/best_model_log/pred.txt\"\n",
    "    prediction_list = [list(l.split()) for l in open(latest_file) if l != \"\\n\"]\n",
    "    return prediction_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ワーカのタスクに対する回答の事後確率の初期化\n",
    "#Algorithm 1のInitialixe posterior distribution using weighted mv(論文p6)\n",
    "def init_posdis(redundancy, ans_m, k):\n",
    "    simple_agg = np.zeros((num_words,k))\n",
    "    mv_ans = np.zeros((num_words))\n",
    "    for r in range(redundancy):\n",
    "        simple_agg += (1/redundancy)*ans_m[r]\n",
    "    for i in range(len(simple_agg)):\n",
    "        mv_ans[i] = np.argmax(simple_agg[i])\n",
    "    return mv_ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ワーカのタスクに対する回答の事後確率の初期化\n",
    "#mvしない場合\n",
    "def init_posdis_single(redundancy, ans_m, k):\n",
    "    simple_agg = np.zeros((num_words,k))\n",
    "    mv_ans = np.zeros((num_words))\n",
    "    simple_agg += (1/redundancy)*ans_m[0]\n",
    "    for i in range(len(simple_agg)):\n",
    "        mv_ans[i] = np.argmax(simple_agg[i])\n",
    "    return mv_ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def post_prob_DS(est_labels, ans_train, k, worker_num, num_words):\n",
    "    #学習機とラベルの更新\n",
    "    n = len(ans_train)\n",
    "    m = worker_num\n",
    "    e_conf = np.zeros((m,k,k))\n",
    "    temp_conf = (1/float(k))*np.ones((m,k,k))\n",
    "    labels_md = np.zeros((k))\n",
    "    worker_acc = np.zeros((m,k)) #ワーカーの信頼度\n",
    "    task_acc = np.zeros((n, k))\n",
    "    #est_labelsを正解ラベルとして混同行列を作成 式(7)\n",
    "    for i in range(n):\n",
    "        for l in range(len(ans_train[i][2])):\n",
    "            #真のラベルの周辺分布を更新\n",
    "            labels_md[int(est_labels[i][l])] += 1\n",
    "            for a, j in enumerate(ans_train[i][1]): #各回答ワーカーについて\n",
    "                temp_conf[j,:,:] = temp_conf[j,:,:] + np.outer(np.eye(k)[int(est_labels[i][l])],np.eye(k)[ans_train[i][2][l][a]]) #外積 混同行列の作成\n",
    "    #temp_confの正規化\n",
    "    for j in range(m):  \n",
    "        for r in range(k):\n",
    "            e_conf[j,:,:] = np.divide(temp_conf[j,:,:],np.outer(np.sum(temp_conf[j,:,:],axis =1),np.ones(k)))\n",
    "    labels_md = np.divide(labels_md, np.sum(labels_md)*np.ones(k))\n",
    "    print(\"labels_md\", labels_md)\n",
    "    #混同行列を使って真のラベル推定(論文p5の(5)式)\n",
    "    for i in range(n):\n",
    "        for l in range(len(ans_train[i][2])):\n",
    "            temp_class = 0.0\n",
    "            for a, j in enumerate(ans_train[i][1]): #論文と添字違うので治せたら直す\n",
    "                temp_acc = np.log(np.dot(e_conf[j,:,:],np.transpose(np.eye(k)[ans_train[i][2][l][a]])))\n",
    "                temp_class = temp_class + temp_acc\n",
    "            temp_class = np.log(labels_md) +temp_class\n",
    "            est_labels[i][l] = np.argmax(temp_class)\n",
    "    return est_labels, e_conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def post_prob_DS_single(est_labels, ans_train, k, worker_num, num_words):\n",
    "    #学習機とラベルの更新\n",
    "    n = len(ans_train)\n",
    "    m = worker_num\n",
    "    temp_class = np.zeros((num_words,k))\n",
    "    e_conf = np.zeros((m,k,k))\n",
    "    temp_conf = (1/float(k))*np.ones((m,k,k))\n",
    "    labels_md = np.zeros((k))\n",
    "    worker_acc = np.ones((m,k)) #ワーカーの信頼度\n",
    "    task_acc = np.zeros((n, k))\n",
    "    #est_labelsを正解ラベルとして混同行列を作成 式(7)\n",
    "    for i in range(n):\n",
    "        for l in range(len(ans_train[i][2])):\n",
    "            #真のラベルの周辺分布を更新\n",
    "            labels_md[int(est_labels[i][l])] += 1\n",
    "            temp_conf[ans_train[i][1][0],:,:] = temp_conf[ans_train[i][1][0],:,:] + np.outer(np.eye(k)[int(est_labels[i][l])],np.eye(k)[ans_train[i][2][l][0]]) #外積 混同行列の作成\n",
    "    #temp_confの正規化\n",
    "    for j in range(m):  \n",
    "        for r in range(k):\n",
    "            e_conf[j,:,:] = np.divide(temp_conf[j,:,:],np.outer(np.sum(temp_conf[j,:,:],axis =1),np.ones(k)))\n",
    "    labels_md = np.divide(labels_md, np.sum(labels_md)*np.ones(k))\n",
    "    print(\"labels_md\", labels_md)\n",
    "    #混同行列を使って真のラベル推定(論文p5の(5)式)\n",
    "    for i in range(n):\n",
    "        for l in range(len(ans_train[i][2])):\n",
    "            temp_class = 0.0\n",
    "            temp_acc = np.log(np.dot(e_conf[ans_train[i][1][0],:,:],np.transpose(np.eye(k)[ans_train[i][2][l][0]])))\n",
    "            temp_class = temp_class + temp_acc\n",
    "            worker_acc[ans_train[i][1][0]] =+ temp_acc\n",
    "            temp_class = np.log(labels_md) + temp_class\n",
    "            est_labels[i][l] = np.argmax(temp_class)\n",
    "    return est_labels, e_conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#deep-learining-modelに渡すデータの書き込み\n",
    "def write_prediction(est_labels, ans_train, iter_num):\n",
    "    w_list = []\n",
    "    for n in range(len(ans_train)):\n",
    "        for i in range(len(ans_train[n][0])):\n",
    "            w_list.append(ans_train[n][0][i] +\" \"+ str(est_labels[n][i]) + \"\\n\")\n",
    "        w_list.append(\"\\n\")\n",
    "    w_file = path_w + \"/prediction.txt\"\n",
    "    with open(w_file, mode='w') as f:\n",
    "        f.writelines(w_list)\n",
    "    with open(\"./MBEM_outputs/prediction\"+str(iter_num)+\".txt\", mode='w') as f:\n",
    "        f.writelines(w_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "#deep-learining-modelに渡すデータの書き込み\n",
    "def write_prediction_weighted(est_labels_worker,est_labels_deep, ans_train, e_conf, class_dic, class_dic_r, iter_num):\n",
    "    w_write = \"\"\n",
    "    est_labels = label2num(est_labels_worker, class_dic, class_dic_r)\n",
    "    if len(ans_train[0][1]) > 1:\n",
    "        print(\"Error:This program is only for single labeled data\")\n",
    "    for n in range(len(ans_train)):\n",
    "        for i in range(len(ans_train[n][0])):\n",
    "            print([est_labels_deep[n][i]][est_labels_worker[n][i]])\n",
    "            w_write += ans_train[n][0][i] +\" \"+ str(est_labels[n][i]) + \" \" + str(e_conf[ans_train[n][1][0]][est_labels_deep[n][i]][est_labels_worker[n][i]]) + \"\\n\"\n",
    "        w_write += \"\\n\"\n",
    "    w_file = path_w + \"/prediction.txt\"\n",
    "    with open(w_file, mode='w') as f:\n",
    "        f.write(w_write)\n",
    "    with open(\"./MBEM_outputs/prediction\"+str(iter_num)+\".txt\", mode='w') as f:\n",
    "        f.write(w_write)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1  iteration\n",
      "\n",
      "labels_md [0.04047334 0.00777629 0.01907445 0.02627316 0.00543777 0.00540959\n",
      " 0.01489047 0.02287807 0.85778686]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-269-6d9620fb8ab7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mest_labels_worker\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me_conf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpost_prob_DS\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel2num\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mest_labels_deep\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtrain_num\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_dic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_dic_r\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mans_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mworker_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_words\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mest_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabel2num\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mest_labels_worker\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_dic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_dic_r\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mwrite_prediction_weighted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mest_labels_worker\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mest_labels_deep\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtrain_num\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mans_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me_conf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_dic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_dic_r\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miter_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-268-79af0786df5b>\u001b[0m in \u001b[0;36mwrite_prediction_weighted\u001b[0;34m(est_labels_worker, est_labels_deep, ans_train, e_conf, class_dic, class_dic_r, iter_num)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mans_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mans_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m             \u001b[0mw_write\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mans_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mest_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me_conf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mans_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mest_labels_deep\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mest_labels_worker\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mw_write\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mw_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpath_w\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/prediction.txt\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices"
     ]
    }
   ],
   "source": [
    "iter_time = 1\n",
    "print(iter_time, \" iteration\\n\")\n",
    "est_labels_deep = get_newest_prediction()\n",
    "#if len(est_labels[0]) == 22:\n",
    "#    est_labels[0].insert(0, '3')\n",
    "est_labels_worker, e_conf = post_prob_DS(label2num(est_labels_deep[0:train_num], class_dic, class_dic_r), ans_train, k, worker_num, num_words)\n",
    "est_labels = label2num(est_labels_worker, class_dic, class_dic_r)\n",
    "write_prediction_weighted(est_labels_worker, est_labels_deep[0:train_num], ans_train, e_conf, class_dic, class_dic_r, iter_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#引数:タスク,混同行列,書き込みファイル\n",
    "#出力:ワーカーの回答(ファイルに書き込む)\n",
    "#ワーカーはランダムにとる\n",
    "def generate_ans(X_true, y_true, labelnum_dic, class_dic_r, conf, repeat):\n",
    "    m, k = conf.shape[0], conf.shape[1]\n",
    "    n = len(X_true)\n",
    "    workers_this_example = np.zeros((n,repeat),dtype=np.int)\n",
    "    ans_list = []\n",
    "    for i in range(n):        #m人のワーカーからrepeat人重複なしで選ぶ\n",
    "        workers_this_example[i] = np.sort(np.random.choice(m,repeat,replace=False))\n",
    "        answers = []\n",
    "        for j in workers_this_example[i]:\n",
    "            answers.append(worker_ans(y_true[i], labelnum_dic, class_dic_r, conf[j]))        \n",
    "        ans_list.append([X_true[i], list(workers_this_example[i]),answers])\n",
    "    return ans_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#正解ラベルと混同行列が与えられた時のワーカーの回答ラベル作成\n",
    "def worker_ans(true_labels, labelnum_dic, class_dic_r, conf):\n",
    "    ans_true = [labelnum_dic[y] for y in true_labels]\n",
    "    res_ans = []\n",
    "    a = 0.0\n",
    "    res_pre = -1\n",
    "    for i in range(len(ans_true)):\n",
    "        if sum(conf[ans_true[i],:][:-1]) > 1.0:\n",
    "            print(ans_true[i], conf)\n",
    "        res = np.argmax(np.random.multinomial(1,conf[ans_true[i],:]))\n",
    "        if res == 4:\n",
    "            res_ans.append(class_dic_r[8])\n",
    "        else:\n",
    "            if res_pre == res:\n",
    "                res_ans.append(class_dic_r[res+4])\n",
    "            else:\n",
    "                res_ans.append(class_dic_r[res])\n",
    "        res_pre = res\n",
    "    return res_ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_ans_list(ans_list, worker_num, w_path):\n",
    "    w_str = \"\"\n",
    "    for n in range(len(ans_list)):\n",
    "        for i in range(len(ans_list[n][0])):\n",
    "            w_str += ans_list[n][0][i] + fillin_ans(ans_list[n][1], ans_list[n][2], i, worker_num) + \"\\n\"\n",
    "        w_str += \"\\n\"\n",
    "    with open(w_path, mode='w') as f:\n",
    "        f.write(w_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fillin_ans(workers, answers, i, worker_num):\n",
    "    w_str = \"\"\n",
    "    for w in range(worker_num):\n",
    "        if w in workers:\n",
    "            ans_index = workers.index(w)\n",
    "            w_str += \" \" + answers[ans_index][i]\n",
    "        else:\n",
    "            w_str += \" ?\"\n",
    "    return w_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#シミュレーションデータのワーカ生成\n",
    "#混同行列の作成\n",
    "#引数:ラベル,ワーカーの人数,ワーカーの正解率\n",
    "#返り値:混同行列\n",
    "def generate_conf(class_label, m, gamma, class_wise=1):\n",
    "    k = len(class_label)\n",
    "    conf = (1/float(k))*np.ones((m,k,k))\n",
    "    if class_wise==1:\n",
    "        for i in range(m):\n",
    "            for j in range(k):\n",
    "            # gammaの確率でそのクラスは正解する\n",
    "                if(np.random.uniform(0,1) < gamma):\n",
    "                    conf[i,j,:] = 0\n",
    "                    conf[i,j,j] = 1 \n",
    "                else:\n",
    "                    conf[i,j,:] = 1\n",
    "                    conf[i,j,j] = 1 + np.random.uniform(0.1,0.11)\n",
    "                    conf[i,j,:] = conf[i,j,:]/np.sum(conf[i,j,:])\n",
    "    if class_wise==0:\n",
    "        for i in range(m):\n",
    "        # gammaの確率でワーカーは正解する\n",
    "            if(np.random.uniform(0,1) < gamma):\n",
    "                for j in range(k):\n",
    "                    conf[i,j,:] = 0\n",
    "                    conf[i,j,j] = 1 \n",
    "            else:\n",
    "                for j in range(k):\n",
    "                    conf[i,j,:] = 1\n",
    "                    conf[i,j,j] = 1 + np.random.uniform(0.1,0.11)\n",
    "                    conf[i,j,:] = conf[i,j,:]/np.sum(conf[i,j,:])\n",
    "    return conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_ner(y_true, b_tag):\n",
    "    loc_num, misc_num, org_num, per_num = 0, 0, 0, 0\n",
    "    for ans in y_true:\n",
    "        loc_num += ans.count('B-LOC')\n",
    "        misc_num += ans.count('B-MISC')\n",
    "        org_num += ans.count('B-ORG')\n",
    "        per_num += ans.count('B-PER')\n",
    "    return loc_num, misc_num, org_num, per_num\n",
    "    P = loc_num + misc_num + org_num + per_num\n",
    "    TP = int(recall*P) #NER正解データ数\n",
    "    FP = int(TP*((1/precision)-1)) #NERミス\n",
    "    FN = int(P - TP) #NER見逃し\n",
    "    print(\"P\", P, \"TP\", TP, \"FP\", FP, \"FN\", FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#学習機に渡すシミュレーションデータの作成\n",
    "def makefile_ans(X_true, y_true, class_shuffle, precision, recall, w_path):\n",
    "    loc_num, misc_num, org_num, per_num = 0, 0, 0, 0\n",
    "    w_str = \"\"\n",
    "    b_tag = ['B-LOC', 'B-MISC', 'B-ORG', 'B-PER']\n",
    "    for ans in y_true:\n",
    "        loc_num += ans.count('B-LOC')\n",
    "        misc_num += ans.count('B-MISC')\n",
    "        org_num += ans.count('B-ORG')\n",
    "        per_num += ans.count('B-PER')\n",
    "    P = loc_num + misc_num + org_num + per_num\n",
    "    s = np.random.dirichlet((5,5,1), 1)\n",
    "    print(s)\n",
    "    if precision > recall:\n",
    "        miss_pr = int(P * (1-precision)*(s[0][0]+s[0][1])) #タグ位置ミスとK2s\n",
    "        miss_len = int(miss_pr*(s[0][0]/(s[0][0]+s[0][1])))\n",
    "        miss_k2s = int(miss_pr*(s[0][1]/(s[0][0]+s[0][1])))\n",
    "        miss_O2k = int(miss_pr*(s[0][2]/(s[0][0]+s[0][1])))\n",
    "        miss_k2O = int(P * (recall - (s[0][0]+s[0][1]))) #K2Oの数\n",
    "    else:\n",
    "        miss_pr = int(P * (1-recall)*(s[0][0]+s[0][1])) #タグ位置ミスとk2sとk2O\n",
    "        miss_len = int(miss_pr*(s[0][0]/(s[0][0]+s[0][1])))\n",
    "        miss_k2s = int(miss_pr*(s[0][1]/(s[0][0]+s[0][1])))\n",
    "        miss_k2O = int(miss_pr*((s[0][2])/(s[0][0]+s[0][1])))\n",
    "        miss_O2k = int(P*(precision-((1-recall)*(s[0][0]+s[0][1]))))\n",
    "    print(\"www\", s[0][0]+s[0][1])\n",
    "    print(\"re\", (precision-1+(recall*(s[0][0]+s[0][1]))))\n",
    "    print(\"sum\", sum(s[0]))\n",
    "#    print(1-(s[0][0]+s[0][1])-recall)\n",
    "    print(\"pr\", miss_pr/P, \"len\", miss_len/P, \"k2s\", miss_k2s/P, \"pr\", (miss_len/P)+(miss_k2s/P),\"\\nO2k\", miss_O2k/P,\"k2O\", miss_k2O/P)\n",
    "    z = 0\n",
    "    for n in range(len(X_true)):\n",
    "        ans_new = []\n",
    "        if z < miss_len:\n",
    "            for i in range(len(X_true[n])-1):\n",
    "                w_str += X_true[n][i] + \" \" + y_true[n][i+1] + \"\\n\"\n",
    "            w_str += X_true[n][-1] + \" \" + y_true[n][0] + \"\\n\\n\"\n",
    "            z += y_true[n].count('B-LOC') + y_true[n].count('B-MISC') + y_true[n].count('B-ORG') + y_true[n].count('B-PER')\n",
    "        elif z < miss_len + miss_k2s:\n",
    "            a = random.randint(0,1)\n",
    "            new_y = [class_shuffle[a][w] for w in y_true[n]]\n",
    "            for i in range(len(X_true[n])):\n",
    "                w_str += X_true[n][i] + \" \" + new_y[i] + \"\\n\"\n",
    "            w_str += \"\\n\"\n",
    "            z += y_true[n].count('B-LOC') + y_true[n].count('B-MISC') + y_true[n].count('B-ORG') + y_true[n].count('B-PER')\n",
    "        elif z < miss_len + miss_k2s + miss_k2O:\n",
    "            for i in range(len(X_true[n])):\n",
    "                w_str += X_true[n][i] + \" \" + \"O\\n\"\n",
    "            w_str += \"\\n\"\n",
    "            z += y_true[n].count('B-LOC') + y_true[n].count('B-MISC') + y_true[n].count('B-ORG') + y_true[n].count('B-PER')\n",
    "        else:\n",
    "            for i in range(len(X_true[n])):\n",
    "                if random.randint(0,1) == 0 and miss_O2k > 0 and y_true[n][i] == 'O':\n",
    "                    w_str += X_true[n][i] + \" \" + b_tag[random.randint(0,3)] + \"\\n\"\n",
    "                    miss_O2k -= 1\n",
    "                else:\n",
    "                    w_str += X_true[n][i] + \" \" + y_true[n][i] + \"\\n\"\n",
    "            w_str += \"\\n\"\n",
    "    print(\"miss_O2k\", miss_O2k)\n",
    "    with open(w_path, mode='w') as f:\n",
    "        f.write(w_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#シミュレーションデータのワーカ生成\n",
    "#混同行列の作成\n",
    "#引数:ラベル,ワーカーの人数,ワーカーの正解率\n",
    "#返り値:混同行列\n",
    "def generate_conf_test(class_label, m, a_r, K2O=False):\n",
    "    k = len(class_label)\n",
    "    conf = (1/float(k))*np.ones((m,k,k))\n",
    "    for i in range(m): #ワーカー\n",
    "        #ベータ分布でサンプリングされた値r\n",
    "        eta_r = np.random.beta(a_r, 1.0, size=k)\n",
    "        for j in range(k):\n",
    "            conf[i,j,:] = (1 - eta_r[j])/(k)\n",
    "            conf[i,j,j] += eta_r[j]\n",
    "        if K2O == True:\n",
    "            conf[i,4,:] += eta_r.transpose()\n",
    "        else:\n",
    "            conf[i,:,4] += eta_r.transpose()\n",
    "        for j in range(k):\n",
    "            conf[i,j,:] = conf[i,j,:]/sum(conf[i,j,:])\n",
    "    return conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "conf1 = generate_conf_test(class_label, 47, 10)\n",
    "ans_list_temp = generate_ans(X_true[:5385], y_true[:5385], labelnum_dic, class_dic_r, conf1, 1)\n",
    "write_ans_list(ans_list_temp, 47, '../MBEM/ner-mturk/mild_single_test1.txt')\n",
    "conf2 = generate_conf_test(class_label, 47, 10, True)\n",
    "ans_list_temp = generate_ans(X_true[:5385], y_true[:5385], labelnum_dic, class_dic_r, conf2, 1)\n",
    "write_ans_list(ans_list_temp, 47, '../MBEM/ner-mturk/mild_single_test2.txt')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.48035011 0.01309993 0.01309993 0.01309993 0.48035011]\n",
      " [0.00684483 0.48973276 0.00684483 0.00684483 0.48973276]\n",
      " [0.01034039 0.01034039 0.48448942 0.01034039 0.48448942]\n",
      " [0.00226689 0.00226689 0.00226689 0.49659967 0.49659967]\n",
      " [0.01237615 0.01237615 0.01237615 0.01237615 0.95049541]] \n",
      "\n",
      "[[0.96211532 0.00947117 0.00947117 0.00947117 0.00947117]\n",
      " [0.00398497 0.98406012 0.00398497 0.00398497 0.00398497]\n",
      " [0.0466155  0.0466155  0.81353799 0.0466155  0.0466155 ]\n",
      " [0.02136069 0.02136069 0.02136069 0.91455724 0.02136069]\n",
      " [0.17229267 0.17722329 0.13890988 0.16160718 0.34996698]]\n"
     ]
    }
   ],
   "source": [
    "print(conf1[0], \"\\n\")\n",
    "print(conf2[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_conf_test(class_label, m, a=0.1, O2K=False, Kmiss=False):\n",
    "    k = len(class_label)\n",
    "    conf = (1/float(k))*np.zeros((m,k,k))\n",
    "    for i in range(m): #ワーカー\n",
    "        for j in range(k):\n",
    "            conf[i,j,:] = 0\n",
    "            conf[i,j,j] += 1-a\n",
    "        if O2K == True:\n",
    "            conf[i,4,:] += a\n",
    "        elif Kmiss == True:\n",
    "            conf[i,:4, :4] += a/(k-2)\n",
    "            for j in range(k-1):\n",
    "                conf[i,j,j] -= a/(k-2)\n",
    "            conf[i,4,4] = 1\n",
    "        else:\n",
    "            conf[i,:,4] += a\n",
    "    return conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.9 0.  0.  0.  0.1]\n",
      " [0.  0.9 0.  0.  0.1]\n",
      " [0.  0.  0.9 0.  0.1]\n",
      " [0.  0.  0.  0.9 0.1]\n",
      " [0.  0.  0.  0.  1. ]] \n",
      " [[0.9 0.  0.  0.  0. ]\n",
      " [0.  0.9 0.  0.  0. ]\n",
      " [0.  0.  0.9 0.  0. ]\n",
      " [0.  0.  0.  0.9 0. ]\n",
      " [0.1 0.1 0.1 0.1 1. ]]\n"
     ]
    }
   ],
   "source": [
    "conf1 = generate_conf_test(class_label, 47)\n",
    "ans_list_temp = generate_ans(X_true[:5385], y_true[:5385], labelnum_dic, class_dic_r, conf1, 1)\n",
    "write_ans_list(ans_list_temp, 47, '../MBEM/ner-mturk/testK2O.txt')\n",
    "conf2 = generate_conf_test(class_label, 47, O2K=True)\n",
    "ans_list_temp = generate_ans(X_true[:5385], y_true[:5385], labelnum_dic, class_dic_r, conf2, 1)\n",
    "write_ans_list(ans_list_temp, 47, '../MBEM/ner-mturk/testO2K.txt')\n",
    "print(conf1[0],\"\\n\", conf2[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.8        0.06666667 0.06666667 0.06666667 0.        ]\n",
      " [0.06666667 0.8        0.06666667 0.06666667 0.        ]\n",
      " [0.06666667 0.06666667 0.8        0.06666667 0.        ]\n",
      " [0.06666667 0.06666667 0.06666667 0.8        0.        ]\n",
      " [0.         0.         0.         0.         1.        ]]\n"
     ]
    }
   ],
   "source": [
    "conf3 = generate_conf_test(class_label, 47, a=0.2, O2K=False, Kmiss=True)\n",
    "ans_list_temp = generate_ans(X_true[:5385], y_true[:5385], labelnum_dic, class_dic_r, conf3, 1)\n",
    "write_ans_list(ans_list_temp, 47, '../MBEM/ner-mturk/test_Kmiss_2.txt')\n",
    "print(conf3[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "#シミュレーションデータのワーカ生成\n",
    "#混同行列の作成\n",
    "#引数:ラベル,ワーカーの人数,ワーカーの正解率\n",
    "#返り値:混同行列\n",
    "def generate_mild_conf(class_label, m, a_p, a_r):\n",
    "    k = len(class_label)\n",
    "    conf = (1/float(k))*np.ones((m,k,k))\n",
    "    for i in range(m): #ワーカー\n",
    "        #ベータ分布でサンプリングされた値r\n",
    "        eta_p = np.random.beta(a_p, 1.0, size=k) #ベータ分布で出すb=1で固定a=としてクラス数ぶんr_r,r_pサンプリング\n",
    "        eta_r = np.random.beta(a_r, 1.0, size=k)\n",
    "        tempconf = np.zeros((k,k))\n",
    "        for j in range(k):\n",
    "            conf[i,j,:] = (1 - eta_r[j])/(k)\n",
    "            conf[i,j,j] += eta_r[j]\n",
    "            tempconf[:,j] = (1 - eta_p[j])/(k)\n",
    "            tempconf[j,j] += eta_p[j]\n",
    "        conf[i] = conf[i]/2 + tempconf/2\n",
    "        conf[i,:,4] += eta_r.transpose()\n",
    "        tempconf[:,4] += eta_p.transpose()\n",
    "        for j in range(k):\n",
    "            conf[i,j,:] = conf[i,j,:]/sum(conf[i,j,:])\n",
    "    return conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "worker_num 47\n",
      "クラス： {'B-LOC': 0, 'B-MISC': 1, 'B-ORG': 2, 'B-PER': 3, 'I-LOC': 4, 'I-MISC': 5, 'I-ORG': 6, 'I-PER': 7, 'O': 8}\n",
      "タスク数 5385\n",
      "タスク数(単語): 70985\n",
      "語彙数 12378\n"
     ]
    }
   ],
   "source": [
    "class_list = list(set(l.split()[1] for l in open(truth_file) if l != \"\\n\"))\n",
    "class_dic = {k:i for i, k in enumerate(sorted(class_list))}\n",
    "class_dic_r = {class_dic[c]:c for c in class_dic}\n",
    "class_label = {'LOC': 0, 'MISC': 1, 'ORG': 2, 'PER': 3, 'O': 4}\n",
    "labelnum_dic = {'B-LOC': 0, 'B-MISC': 1, 'B-ORG': 2, 'B-PER': 3, 'I-LOC': 0, 'I-MISC': 1, 'I-ORG': 2, 'I-PER': 3, 'O': 4}\n",
    "s1 = {'B-LOC': 'B-MISC', 'B-MISC': 'B-ORG', 'B-ORG': 'B-PER', 'B-PER': 'B-LOC', 'I-LOC': 'I-MISC', 'I-MISC': 'I-ORG', 'I-ORG': 'I-PER', 'I-PER': 'I-LOC', 'O':'O'}\n",
    "s2 = {'B-LOC': 'B-ORG', 'B-MISC': 'B-PER', 'B-ORG': 'B-LOC', 'B-PER':'B-MISC' , 'I-LOC': 'I-ORG', 'I-MISC': 'I-PER', 'I-ORG':  'I-LOC', 'I-PER':'I-MISC', 'O':'O'}\n",
    "class_shuffle = [s1, s2]\n",
    "b_tag = ['B-LOC', 'B-MISC', 'B-ORG', 'B-PER']\n",
    "#データの読み込み\n",
    "ans_train, words_dic = load_crowd_data(ans_file, truth_file, train_num)\n",
    "X_true, y_true = read_output('../MBEM/ner-mturk/ground_truth.txt', class_dic_r)\n",
    "X_true5, y_true5 = read_output('../MBEM/ner-mturk/testset5.txt', class_dic_r)\n",
    "workers_count = []\n",
    "for i in range(len(ans_train)):\n",
    "    for w in ans_train[i][1]:\n",
    "        workers_count.append(w)\n",
    "worker_num = len(set(workers_count))\n",
    "\n",
    "#多分データを変えるごとにクラス確認したくなるので残しておく\n",
    "num_words = 0\n",
    "for l in ans_train:\n",
    "    num_words += len(l[0])\n",
    "print(\"worker_num\", worker_num)\n",
    "print(\"クラス：\",class_dic)\n",
    "print(\"タスク数\",len(ans_train))\n",
    "print(\"タスク数(単語):\", num_words)\n",
    "print(\"語彙数\", len(words_dic))\n",
    "worker_num = 47"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ans_mは回答(redundancy)×タスク(単語)×ラベル数\n",
    "ans_m = ans_matrix(ans_train, redundancy, k)\n",
    "ans_m = ans_m.transpose(1, 0, 2) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mv 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Algorithm 1\n",
    "#deep-learining-modelに渡すデータの書き込み\n",
    "w_list = []\n",
    "i = 0\n",
    "simple_agg = init_posdis(redundancy, ans_m, k)\n",
    "for task in ans_train:\n",
    "    for word in task[0]:\n",
    "        w_list.append(word +\" \"+ str(class_dic_r[int(simple_agg[i])]) + \"\\n\")\n",
    "        i += 1\n",
    "    w_list.append(\"\\n\")\n",
    "w_file = path_w + \"/agg_single_test_delthis.txt\"\n",
    "with open(w_file, mode='w') as f:\n",
    "    f.writelines(w_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subprocess.run(['./deep-learning-models/python', 'main.py', 'dataset_reader=normal_bc5cdr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1  iteration\n",
      "\n",
      "labels_md [6.72143920e-02 2.52850768e-02 2.59225158e-02 2.04688717e-02\n",
      " 9.20745095e-04 6.37438912e-04 4.53289893e-03 5.17033784e-03\n",
      " 8.49847723e-01]\n"
     ]
    }
   ],
   "source": [
    "iter_time = 1\n",
    "print(iter_time, \" iteration\\n\")\n",
    "est_labels = get_newest_prediction()\n",
    "#if len(est_labels[0]) == 22:\n",
    "#    est_labels[0].insert(0, '3')\n",
    "est_labels, e_conf = post_prob_DS(label2num(est_labels[0:train_num5], class_dic, class_dic_r), ans_train, k, worker_num, num_words)\n",
    "write_prediction(label2num(est_labels, class_dic, class_dic_r), ans_train, iter_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "single label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Algorithm 1\n",
    "#deep-learining-modelに渡すデータの書き込み\n",
    "w_list = []\n",
    "i = 0\n",
    "simple_agg = init_posdis_single(redundancy, ans_m, k)\n",
    "for task in ans_train:\n",
    "    for word in task[0]:\n",
    "        w_list.append(word +\" \"+ str(class_dic_r[int(simple_agg[i])]) + \"\\n\")\n",
    "        i += 1\n",
    "    w_list.append(\"\\n\")\n",
    "w_file = path_w + \"/agg_mild_single_test2.txt\"\n",
    "with open(w_file, mode='w') as f:\n",
    "    f.writelines(w_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1  iteration\n",
      "\n",
      "labels_md [0.02856942 0.01611608 0.03659928 0.02496302 0.02411777 0.0101289\n",
      " 0.01381982 0.01914489 0.82654082]\n"
     ]
    }
   ],
   "source": [
    "iter_time = 1\n",
    "print(iter_time, \" iteration\\n\")\n",
    "est_labels = get_newest_prediction()\n",
    "est_labels, e_conf = post_prob_DS(label2num(est_labels[0:train_num], class_dic, class_dic_r), ans_train, k, worker_num, num_words)\n",
    "write_prediction(label2num(est_labels, class_dic, class_dic_r), ans_train, iter_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "確率でやりたい時にはこちら"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4  iteration\n",
      "\n",
      "labels_md [0.03498831 0.0160068  0.04957858 0.04780792 0.         0.\n",
      " 0.         0.         0.85161839]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jimmy/.pyenv/versions/anaconda3-5.2.0/lib/python3.6/site-packages/ipykernel_launcher.py:30: RuntimeWarning: divide by zero encountered in log\n"
     ]
    }
   ],
   "source": [
    "iter_time = 4\n",
    "print(iter_time, \" iteration\\n\")\n",
    "est_labels = get_newest_prediction()\n",
    "est_labels, e_conf = post_prob_DS(label2num(est_labels[0:train_num], class_dic, class_dic_r), ans_train, k, worker_num, num_words)\n",
    "write_prediction(label2num(est_labels, class_dic, class_dic_r), ans_train, iter_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5  iteration\n",
      "\n",
      "labels_md [0.03498831 0.0160068  0.04957858 0.04780792 0.         0.\n",
      " 0.         0.         0.85161839]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jimmy/.pyenv/versions/anaconda3-5.2.0/lib/python3.6/site-packages/ipykernel_launcher.py:30: RuntimeWarning: divide by zero encountered in log\n"
     ]
    }
   ],
   "source": [
    "iter_time = 5\n",
    "print(iter_time, \" iteration\\n\")\n",
    "est_labels = get_newest_prediction()\n",
    "est_labels, e_conf = post_prob_DS(label2num(est_labels[0:train_num], class_dic, class_dic_r), ans_train, k, worker_num, num_words)\n",
    "write_prediction(label2num(est_labels, class_dic, class_dic_r), ans_train, iter_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ワーカのタスクに対する回答の事後確率の初期化\n",
    "#Algorithm 1のInitialixe posterior distribution using weighted mv(論文p6)\n",
    "def init_posdis_p(redundancy, ans_m, k):\n",
    "    simple_agg = np.zeros((num_words,k))\n",
    "    mv_ans = np.zeros((num_words))\n",
    "    for r in range(redundancy):\n",
    "        simple_agg += (1/redundancy)*ans_m[r] #simple_aggをmvせずにそのまま使えるようにしたい\n",
    "    return simple_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Algorithm 1\n",
    "#deep-learining-modelに渡すデータの書き込み\n",
    "w_list = [str(class_dic_r)+\"\\n\\n\"]\n",
    "i = 0\n",
    "simple_agg = init_posdis_p(redundancy, ans_m, k)\n",
    "for task in ans_train:\n",
    "    for word in task[0]:\n",
    "        w_list.append(word +\" \"+ str(simple_agg[i])[1:-1] + \"\\n\")\n",
    "        i += 1\n",
    "    w_list.append(\"\\n\")\n",
    "w_file = path_w + \"/simple_agg_p.txt\"\n",
    "with open(w_file, mode='w') as f:\n",
    "    f.writelines(w_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5  iteration\n",
      "\n",
      "labels_md [0.04041827 0.01312667 0.02640166 0.03396618 0.00496885 0.00904776\n",
      " 0.0120884  0.02921982 0.83076239]\n"
     ]
    }
   ],
   "source": [
    "iter_time = 5\n",
    "print(iter_time, \" iteration\\n\")\n",
    "est_labels = get_newest_prediction()\n",
    "#if len(est_labels[0]) == 22:\n",
    "#    est_labels[0].insert(0, '3')\n",
    "est_labels, e_conf = post_prob_DS(label2num(est_labels[0:train_num5], class_dic, class_dic_r), ans_train, k, worker_num, num_words)\n",
    "write_prediction(label2num(est_labels, class_dic, class_dic_r), ans_train, iter_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'simple_pred' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-f6ae168b7ffd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mest_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0msimple_pred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msimple_pred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miteration_times\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\" iteration\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m#simple_pred(weighed mv)とans_train(回答と回答ワーカ)を使って学習\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m#simple_predを使うのは事前分布のため\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'simple_pred' is not defined"
     ]
    }
   ],
   "source": [
    "est_labels = simple_pred\n",
    "for t in range(iteration_times):\n",
    "    print(t, \" iteration\\n\")\n",
    "    #simple_pred(weighed mv)とans_train(回答と回答ワーカ)を使って学習\n",
    "    #simple_predを使うのは事前分布のため\n",
    "    #学習機のtrainと推定ラベルの更新\n",
    "    model, est_labels = train(words_dic, class_dic, ans_train, est_labels)\n",
    "    #est_labelsで混同行列の更新\n",
    "    est_labels, e_conf = post_prob_DS(est_labels, ans_train, k, worker_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ニューラルネットワーク"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29\n"
     ]
    }
   ],
   "source": [
    "print(len(get_newest_prediction()[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ワーカーの回答ラベルでtrainしてmodelとpredicted_labels(タスク数*各文書単語数list)を返す\n",
    "def train(words_dic, class_dic, ans_train, ans_labels):\n",
    "    EMBEDDING_DIM = 5\n",
    "    HIDDEN_DIM = 4\n",
    "    predicted_labels = []\n",
    "    model = BiLSTM_CRF(len(words_dic), class_dic, EMBEDDING_DIM, HIDDEN_DIM)\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.01, weight_decay=1e-4)\n",
    "    # Modelトレーニング\n",
    "    for epoch in range(2):\n",
    "        m = 0\n",
    "        for sentence, worker, classes in ans_train:\n",
    "            # 勾配の初期化\n",
    "            model.zero_grad()\n",
    "            tags = ans_labels[m:m+len(sentence)]\n",
    "            sentence_in = prepare_sequence(sentence, words_dic)\n",
    "            targets = torch.tensor(tags, dtype=torch.long)\n",
    "            loss = model.neg_log_likelihood(sentence_in, targets)\n",
    "            # 損失関数と勾配の計算をしてパラメータ更新\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    #ラベル予測\n",
    "    for i in range(len(ans_train)):\n",
    "        with torch.no_grad():\n",
    "            check_sent = prepare_sequence(ans_train[i][0], words_dic)\n",
    "            predicted_labels.append(model(check_sent))\n",
    "    return model, predicted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A', 'newborn', 'with', 'massive', 'tricuspid', 'regurgitation', '&#44;', 'atrial', 'flutter', '&#44;', 'congestive', 'heart', 'failure', '&#44;', 'and', 'a', 'high', 'serum', 'lithium', 'level', 'is', 'described', '.']\n",
      "(tensor(83.0933), [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    precheck_sent = prepare_sequence(ans_train[6][0], words_dic)\n",
    "    print(ans_train[0][0])\n",
    "    print(model(precheck_sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
