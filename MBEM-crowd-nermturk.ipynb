{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import collections\n",
    "import glob\n",
    "import numpy as np\n",
    "import os\n",
    "import subprocess\n",
    "import torch\n",
    "import torch.autograd as autograd\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import random\n",
    "\n",
    "from itertools import groupby\n",
    "torch.manual_seed(1)\n",
    "\n",
    "ans_path = './ner-mturk/answers*'\n",
    "ans_file_list = sorted(glob.glob(ans_path))\n",
    "single_ans_list = sorted(glob.glob('ner-mturk/single_ans*'))\n",
    "truth_file = './ner-mturk/ground_truth.txt'\n",
    "path_w = './MBEM_outputs'\n",
    "train_num = 5385\n",
    "train_num5 = 1077\n",
    "test_num = 600\n",
    "k = 9\n",
    "redundancy = 5\n",
    "iteration_times = 5\n",
    "#ans_file = ans_file_list[6]\n",
    "#ans_file = single_ans_list[1]\n",
    "#ans_file = '../MBEM/ner-mturk/sim_data_cw0_08.txt'\n",
    "#ans_file = '../MBEM/ner-mturk/sim_data_single_cw0_07.txt'\n",
    "ans_file = '../MBEM/ner-mturk/mild_single_07.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ans(workers, answers):\n",
    "    ans_label = []\n",
    "    for a in workers:\n",
    "        ans_label.append(class_dic[answers[a]])\n",
    "    return ans_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_n_ans(answers, n):\n",
    "    ans = []\n",
    "    for k in range(len(answers)):\n",
    "        ans.append(answers[k][n])\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tupleには対応していないので返り値用に多重配列作り直した方がいいかもしれない\n",
    "def label2num(answers, class_dic, class_dic_r):\n",
    "    if answers[0][0] in class_dic:\n",
    "        for i in range(len(answers)):\n",
    "            for w in range(len(answers[i])):\n",
    "                answers[i][w] = class_dic[answers[i][w]]\n",
    "    elif answers[0][0] in class_dic_r:\n",
    "        for i in range(len(answers)):\n",
    "            for w in range(len(answers[i])):\n",
    "                answers[i][w] = class_dic_r[int(answers[i][w])]\n",
    "    else: print(\"error\")\n",
    "    return answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_output(path, class_dic_r, to_label=False):\n",
    "    f = open(path)\n",
    "    make_xypair = lambda v: list(zip(*[l.strip().split() for l in v]))\n",
    "    is_emptyline = lambda x: x.strip() != '' and not x.startswith('-DOCSTART-')\n",
    "    list_int = lambda t: list([class_dic_r[int(v)] for v in t])\n",
    "    xypairs = [make_xypair(v) for k, v in groupby(f, is_emptyline) if k]\n",
    "    if to_label == True:\n",
    "        return ([p[0] for p in xypairs], [list(list_int(p[1])) for p in xypairs])\n",
    "    if len(xypairs[0]) == 2:\n",
    "        return ([p[0] for p in xypairs], [list(p[1]) for p in xypairs])\n",
    "    else:\n",
    "        return ([p[0] for p in xypairs], [list(p[1:]) for p in xypairs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#データをダウンロード trainとvalに分けて戻す\n",
    "def load_crowd_data(ans_file, truth_file, train_num):\n",
    "    #ここからanswersの格納\n",
    "    #answers_list[task_num] = [[words, ...], [回答者], [[answers(one hot ベクトル)]...]]\n",
    "    answers_list = []\n",
    "    sentence = []\n",
    "    answers = []\n",
    "    worker = []\n",
    "    words_dic = {}\n",
    "    get_worker = lambda x: tuple([i for i, l in enumerate(x) if l !='?'])\n",
    "    for l in open(ans_file):\n",
    "        ans = l.split()\n",
    "        if len(l) < 2:\n",
    "            answers_list.append([sentence, worker, answers])\n",
    "            sentence = []\n",
    "            worker = []\n",
    "            answers = []\n",
    "        else:\n",
    "            if len(worker) < 1:\n",
    "                worker = get_worker(ans[1:])\n",
    "            if not ans[0] in words_dic:\n",
    "                words_dic[ans[0]] = len(words_dic)\n",
    "            sentence.append(ans[0])\n",
    "            answers.append(get_ans(worker, ans[1:]))            \n",
    "    #truth_list: [(task_word, answer), ....]\n",
    "    truth_list = [tuple(l.split()) for l in open(truth_file) if l != \"\\n\"]\n",
    "    ans_train = answers_list[0:train_num]\n",
    "#    ans_test = answers_list[train_num:]\n",
    "    return ans_train, words_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ans_matrix(ans_train, redundancy, k):\n",
    "    ans_m = np.zeros((num_words, redundancy,k))\n",
    "    m = 0\n",
    "    for n in range(len(ans_train)):\n",
    "        for i in range(len(ans_train[n][0])):\n",
    "            ans_m[m] = np.eye(k)[ans_train[n][2][i][:5]]\n",
    "            m += 1\n",
    "    return ans_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#deep-learning-modelからのデータの読み込み\n",
    "def get_newest_prediction():\n",
    "    files_list = glob.glob(\"./deep-learning-model/outputs/*\")\n",
    "    latest_file = max(glob.glob(max(files_list, key=os.path.getctime)+\"/*\"), key=os.path.getctime) + \"/best_model_log/pred.txt\"\n",
    "    prediction_list = [list(l.split()) for l in open(latest_file) if l != \"\\n\"]\n",
    "    return prediction_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ワーカのタスクに対する回答の事後確率の初期化\n",
    "#Algorithm 1のInitialixe posterior distribution using weighted mv(論文p6)\n",
    "def init_posdis(redundancy, ans_m, k):\n",
    "    simple_agg = np.zeros((num_words,k))\n",
    "    mv_ans = np.zeros((num_words))\n",
    "    for r in range(redundancy):\n",
    "        simple_agg += (1/redundancy)*ans_m[r]\n",
    "    for i in range(len(simple_agg)):\n",
    "        mv_ans[i] = np.argmax(simple_agg[i])\n",
    "    return mv_ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ワーカのタスクに対する回答の事後確率の初期化\n",
    "#mvしない場合\n",
    "def init_posdis_single(redundancy, ans_m, k):\n",
    "    simple_agg = np.zeros((num_words,k))\n",
    "    mv_ans = np.zeros((num_words))\n",
    "    simple_agg += (1/redundancy)*ans_m[0]\n",
    "    for i in range(len(simple_agg)):\n",
    "        mv_ans[i] = np.argmax(simple_agg[i])\n",
    "    return mv_ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def post_prob_DS(est_labels, ans_train, k, worker_num, num_words):\n",
    "    #学習機とラベルの更新\n",
    "    n = len(ans_train)\n",
    "    m = worker_num\n",
    "    e_conf = np.zeros((m,k,k))\n",
    "    temp_conf = (1/float(k))*np.ones((m,k,k))\n",
    "    labels_md = np.zeros((k))\n",
    "    worker_acc = np.zeros((m,k)) #ワーカーの信頼度\n",
    "    task_acc = np.zeros((n, k))\n",
    "    #est_labelsを正解ラベルとして混同行列を作成 式(7)\n",
    "    for i in range(n):\n",
    "        for l in range(len(ans_train[i][2])):\n",
    "            #真のラベルの周辺分布を更新\n",
    "            labels_md[int(est_labels[i][l])] += 1\n",
    "            for a, j in enumerate(ans_train[i][1]): #各回答ワーカーについて\n",
    "                temp_conf[j,:,:] = temp_conf[j,:,:] + np.outer(np.eye(k)[int(est_labels[i][l])],np.eye(k)[ans_train[i][2][l][a]]) #外積 混同行列の作成\n",
    "    #temp_confの正規化\n",
    "    for j in range(m):  \n",
    "        for r in range(k):\n",
    "            e_conf[j,:,:] = np.divide(temp_conf[j,:,:],np.outer(np.sum(temp_conf[j,:,:],axis =1),np.ones(k)))\n",
    "    labels_md = np.divide(labels_md, np.sum(labels_md)*np.ones(k))\n",
    "    print(\"labels_md\", labels_md)\n",
    "    #混同行列を使って真のラベル推定(論文p5の(5)式)\n",
    "    for i in range(n):\n",
    "        for l in range(len(ans_train[i][2])):\n",
    "            temp_class = 0.0\n",
    "            for a, j in enumerate(ans_train[i][1]): #論文と添字違うので治せたら直す\n",
    "                temp_acc = np.log(np.dot(e_conf[j,:,:],np.transpose(np.eye(k)[ans_train[i][2][l][a]])))\n",
    "                temp_class = temp_class + temp_acc\n",
    "            temp_class = np.log(labels_md) +temp_class\n",
    "            est_labels[i][l] = np.argmax(temp_class)\n",
    "    return est_labels, e_conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def post_prob_DS_single(est_labels, ans_train, k, worker_num, num_words):\n",
    "    #学習機とラベルの更新\n",
    "    n = len(ans_train)\n",
    "    m = worker_num\n",
    "    temp_class = np.zeros((num_words,k))\n",
    "    e_conf = np.zeros((m,k,k))\n",
    "    temp_conf = (1/float(k))*np.ones((m,k,k))\n",
    "    labels_md = np.zeros((k))\n",
    "    worker_acc = np.ones((m,k)) #ワーカーの信頼度\n",
    "    task_acc = np.zeros((n, k))\n",
    "    #est_labelsを正解ラベルとして混同行列を作成 式(7)\n",
    "    for i in range(n):\n",
    "        for l in range(len(ans_train[i][2])):\n",
    "            #真のラベルの周辺分布を更新\n",
    "            labels_md[int(est_labels[i][l])] += 1\n",
    "            temp_conf[ans_train[i][1][0],:,:] = temp_conf[ans_train[i][1][0],:,:] + np.outer(np.eye(k)[int(est_labels[i][l])],np.eye(k)[ans_train[i][2][l][0]]) #外積 混同行列の作成\n",
    "    #temp_confの正規化\n",
    "    for j in range(m):  \n",
    "        for r in range(k):\n",
    "            e_conf[j,:,:] = np.divide(temp_conf[j,:,:],np.outer(np.sum(temp_conf[j,:,:],axis =1),np.ones(k)))\n",
    "    labels_md = np.divide(labels_md, np.sum(labels_md)*np.ones(k))\n",
    "    print(\"labels_md\", labels_md)\n",
    "    #混同行列を使って真のラベル推定(論文p5の(5)式)\n",
    "    for i in range(n):\n",
    "        for l in range(len(ans_train[i][2])):\n",
    "            temp_class = 0.0\n",
    "            temp_acc = np.log(np.dot(e_conf[ans_train[i][1][0],:,:],np.transpose(np.eye(k)[ans_train[i][2][l][0]])))\n",
    "            temp_class = temp_class + temp_acc\n",
    "            worker_acc[ans_train[i][1][0]] =+ temp_acc\n",
    "            temp_class = np.log(labels_md) + temp_class\n",
    "            est_labels[i][l] = np.argmax(temp_class)\n",
    "    return est_labels, e_conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#deep-learining-modelに渡すデータの書き込み\n",
    "def write_prediction(est_labels, ans_train, iter_num):\n",
    "    w_list = []\n",
    "    for n in range(len(ans_train)):\n",
    "        for i in range(len(ans_train[n][0])):\n",
    "            w_list.append(ans_train[n][0][i] +\" \"+ str(est_labels[n][i]) + \"\\n\")\n",
    "        w_list.append(\"\\n\")\n",
    "    w_file = path_w + \"/prediction.txt\"\n",
    "    with open(w_file, mode='w') as f:\n",
    "        f.writelines(w_list)\n",
    "    with open(\"./MBEM_outputs/prediction\"+str(iter_num)+\".txt\", mode='w') as f:\n",
    "        f.writelines(w_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#正解ラベルと混同行列が与えられた時のワーカーの回答ラベル作成\n",
    "def worker_ans(true_labels, labelnum_dic, class_dic_r, conf):\n",
    "    ans_true = [labelnum_dic[y] for y in true_labels]\n",
    "    res_ans = []\n",
    "    a = 0.0\n",
    "    res_pre = -1\n",
    "    for i in range(len(ans_true)):\n",
    "        res = np.argmax(np.random.multinomial(1,conf[ans_true[i],:]))\n",
    "        if res == 4:\n",
    "            res_ans.append(class_dic_r[8])\n",
    "        else:\n",
    "            if res_pre == res:\n",
    "                res_ans.append(class_dic_r[res+4])\n",
    "            else:\n",
    "                res_ans.append(class_dic_r[res])\n",
    "        res_pre = res\n",
    "    return res_ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#引数:タスク,混同行列,書き込みファイル\n",
    "#出力:ワーカーの回答(ファイルに書き込む)\n",
    "#ワーカーはランダムにとる\n",
    "def generate_ans(X_true, y_true, labelnum_dic, class_dic_r, conf, repeat):\n",
    "    m, k = conf.shape[0], conf.shape[1]\n",
    "    n = len(X_true)\n",
    "    workers_this_example = np.zeros((n,repeat),dtype=np.int)\n",
    "    ans_list = []\n",
    "    for i in range(n):        #m人のワーカーからrepeat人重複なしで選ぶ\n",
    "        workers_this_example[i] = np.sort(np.random.choice(m,repeat,replace=False))\n",
    "        answers = []\n",
    "        for j in workers_this_example[i]:\n",
    "            answers.append(worker_ans(y_true[i], labelnum_dic, class_dic_r, conf[j]))        \n",
    "        ans_list.append([X_true[i], list(workers_this_example[i]),answers])\n",
    "    return ans_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gammma=0.7\n",
    "\"\"\"\n",
    "conf = generate_conf(class_label, 47, 0.7)\n",
    "ans_list_temp = generate_ans(X_true5[:1077], y_true5[:1077], labelnum_dic, class_dic_r, conf, 5)\n",
    "write_ans_list(ans_list_temp, 47, '../MBEM/ner-mturk/sim_data07.txt')\n",
    "ans_list_temp = generate_ans(X_true[:5385], y_true[:5385], labelnum_dic, class_dic_r, conf, 1)\n",
    "write_ans_list(ans_list_temp, 47, '../MBEM/ner-mturk/sim_data_single07.txt')\n",
    "\n",
    "#gamma=0.8\n",
    "conf = generate_conf(class_label, 47, 0.8)\n",
    "ans_list_temp = generate_ans(X_true5[:1077], y_true5[:1077], labelnum_dic, class_dic_r, conf, 5)\n",
    "write_ans_list(ans_list_temp, 47, '../MBEM/ner-mturk/sim_data08.txt')\n",
    "#ans_list_temp = generate_ans(X_true[:5385], y_true[:5385], labelnum_dic, class_dic_r, conf, 1)\n",
    "#write_ans_list(ans_list_temp, 47, '../MBEM/ner-mturk/sim_data_single08.txt')\n",
    "\n",
    "#gamma=0.8\n",
    "\n",
    "conf = generate_conf(class_label, 47, 0.8, class_wise=0)\n",
    "ans_list_temp = generate_ans(X_true5[:1077], y_true5[:1077], labelnum_dic, class_dic_r, conf, 5)\n",
    "write_ans_list(ans_list_temp, 47, '../MBEM/ner-mturk/sim_data_cw0_08.txt')\n",
    "#ans_list_temp = generate_ans(X_true[:5385], y_true[:5385], labelnum_dic, class_dic_r, conf, 1)\n",
    "#write_ans_list(ans_list_temp, 47, '../MBEM/ner-mturk/sim_data_single_cw0_08.txt')\n",
    "\n",
    "#gamma=0.7\n",
    "conf = generate_conf(class_label, 47, 0.7, class_wise=0)\n",
    "ans_list_temp = generate_ans(X_true5[:1077], y_true5[:1077], labelnum_dic, class_dic_r, conf, 5)\n",
    "write_ans_list(ans_list_temp, 47, '../MBEM/ner-mturk/sim_data_cw0_07.txt')\n",
    "#ans_list_temp = generate_ans(X_true[:5385], y_true[:5385], labelnum_dic, class_dic_r, conf, 1)\n",
    "#write_ans_list(ans_list_temp, 47, '../MBEM/ner-mturk/sim_data_single_cw0_07.txt')\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_ans_list(ans_list, worker_num, w_path):\n",
    "    w_str = \"\"\n",
    "    for n in range(len(ans_list)):\n",
    "        for i in range(len(ans_list[n][0])):\n",
    "            w_str += ans_list[n][0][i] + fillin_ans(ans_list[n][1], ans_list[n][2], i, worker_num) + \"\\n\"\n",
    "        w_str += \"\\n\"\n",
    "    with open(w_path, mode='w') as f:\n",
    "        f.write(w_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fillin_ans(workers, answers, i, worker_num):\n",
    "    w_str = \"\"\n",
    "    for w in range(worker_num):\n",
    "        if w in workers:\n",
    "            ans_index = workers.index(w)\n",
    "            w_str += \" \" + answers[ans_index][i]\n",
    "        else:\n",
    "            w_str += \" ?\"\n",
    "    return w_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#シミュレーションデータのワーカ生成\n",
    "#混同行列の作成\n",
    "#引数:ラベル,ワーカーの人数,ワーカーの正解率\n",
    "#返り値:混同行列\n",
    "def generate_conf(class_label, m, gamma, class_wise=1):\n",
    "    k = len(class_label)\n",
    "    conf = (1/float(k))*np.ones((m,k,k))\n",
    "    if class_wise==1:\n",
    "        for i in range(m):\n",
    "            for j in range(k):\n",
    "            # gammaの確率でそのクラスは正解する\n",
    "                if(np.random.uniform(0,1) < gamma):\n",
    "                    conf[i,j,:] = 0\n",
    "                    conf[i,j,j] = 1 \n",
    "                else:\n",
    "                    conf[i,j,:] = 1\n",
    "                    conf[i,j,j] = 1 + np.random.uniform(0.1,0.11)\n",
    "                    conf[i,j,:] = conf[i,j,:]/np.sum(conf[i,j,:])\n",
    "    if class_wise==0:\n",
    "        for i in range(m):\n",
    "        # gammaの確率でワーカーは正解する\n",
    "            if(np.random.uniform(0,1) < gamma):\n",
    "                for j in range(k):\n",
    "                    conf[i,j,:] = 0\n",
    "                    conf[i,j,j] = 1 \n",
    "            else:\n",
    "                for j in range(k):\n",
    "                    conf[i,j,:] = 1\n",
    "                    conf[i,j,j] = 1 + np.random.uniform(0.1,0.11)\n",
    "                    conf[i,j,:] = conf[i,j,:]/np.sum(conf[i,j,:])\n",
    "    return conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#学習機に渡すシミュレーションデータの作成\n",
    "def makefile_ans(X_true, y_true, class_shuffle, precision, recall, w_path):\n",
    "    loc_num, misc_num, org_num, per_num = 0, 0, 0, 0\n",
    "    w_str = \"\"\n",
    "    b_tag = ['B-LOC', 'B-MISC', 'B-ORG', 'B-PER']\n",
    "    for ans in y_true:\n",
    "        loc_num += ans.count('B-LOC')\n",
    "        misc_num += ans.count('B-MISC')\n",
    "        org_num += ans.count('B-ORG')\n",
    "        per_num += ans.count('B-PER')\n",
    "    print(loc_num, misc_num, org_num, per_num)\n",
    "    P = loc_num + misc_num + org_num + per_num\n",
    "    TP = int(recall*P) #NER正解データ数\n",
    "    FP = int(TP*((1/precision)-1)) #NERミス\n",
    "    FN = int(P - TP) #NER見逃し\n",
    "    print(\"P\", P, \"TP\", TP, \"FP\", FP, \"FN\", FN)\n",
    "    z = 0\n",
    "    for n in range(len(X_true)):\n",
    "        if z < TP:\n",
    "            for i in range(len(X_true[n])):\n",
    "                w_str += X_true[n][i] + \" \" + y_true[n][i] + \"\\n\"\n",
    "            w_str += \"\\n\"\n",
    "            z += ans.count('B-LOC') + ans.count('B-MISC') + ans.count('B-ORG') + ans.count('B-PER')\n",
    "        elif z < TP + FN:\n",
    "            #完全に見逃す\n",
    "            for i in range(len(X_true[n])):\n",
    "                w_str += X_true[n][i] + \" \" + \"O\\n\"\n",
    "            w_str += \"\\n\"\n",
    "            z += ans.count('B-LOC') + ans.count('B-MISC') + ans.count('B-ORG') + ans.count('B-PER')\n",
    "        else:\n",
    "            #タグの付け方ミス(位置ミス、種類ミス) !位置ミスはタグのがしになりかねない(Bタグだけの時)!\n",
    "            #if random.randint(0,1)==0: #位置ミス\n",
    "            #    for i in range(len(X_true)):\n",
    "            #        w_str += X_true[n][i] + \" \" + y_true[n][i]\n",
    "            #    w_str += \"\\n\" \n",
    "            #else #種類ミス\n",
    "            a = random.randint(0,1)\n",
    "            new_y = [class_shuffle[a][w] for w in y_true[n]]\n",
    "            for i in range(len(X_true[n])):\n",
    "                w_str += X_true[n][i] + \" \" + new_y[i] + \"\\n\"\n",
    "            w_str += \"\\n\"\n",
    "    with open(w_path, mode='w') as f:\n",
    "        f.write(w_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2929 1343 2779 2808\n",
      "P 9859 TP 7887 FP 7887 FN 1972\n"
     ]
    }
   ],
   "source": [
    "#makefile_ans(X_true, y_true, class_shuffle, precision=0.5, recall=0.8, w_path='../MBEM/ner-mturk/sim_p05_r08.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2929 1343 2779 2808\n",
      "P 9859 TP 4929 FP 1232 FN 4930\n"
     ]
    }
   ],
   "source": [
    "#makefile_ans(X_true, y_true, class_shuffle, precision=0.8, recall=0.5, w_path='../MBEM/ner-mturk/sim_p08_r05.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2567 1183 2547 2476\n",
      "P 8773 TP 6141 FP 2631 FN 2632\n",
      "2567 1183 2547 2476\n",
      "P 8773 TP 5263 FP 1315 FN 3510\n",
      "2567 1183 2547 2476\n",
      "P 8773 TP 7018 FP 4678 FN 1755\n"
     ]
    }
   ],
   "source": [
    "#makefile_ans(X_true[:5385], y_true[:5385], class_shuffle, precision=0.7, recall=0.7, w_path='../MBEM/ner-mturk/sim_p07_r07.txt')\n",
    "#makefile_ans(X_true[:5385], y_true[:5385], class_shuffle, precision=0.8, recall=0.6, w_path='../MBEM/ner-mturk/sim_p08_r06.txt')\n",
    "#makefile_ans(X_true[:5385], y_true[:5385], class_shuffle, precision=0.6, recall=0.8, w_path='../MBEM/ner-mturk/sim_p06_r08.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2567 1183 2547 2476\n",
      "P 8773 TP 4386 FP 4386 FN 4387\n",
      "2567 1183 2547 2476\n",
      "P 8773 TP 5263 FP 3508 FN 3510\n"
     ]
    }
   ],
   "source": [
    "makefile_ans(X_true[:5385], y_true[:5385], class_shuffle, precision=0.5, recall=0.5, w_path='../MBEM/ner-mturk/sim_p05_r05.txt')\n",
    "makefile_ans(X_true[:5385], y_true[:5385], class_shuffle, precision=0.6, recall=0.6, w_path='../MBEM/ner-mturk/sim_p06_r06.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "#シミュレーションデータのワーカ生成\n",
    "#混同行列の作成\n",
    "#引数:ラベル,ワーカーの人数,ワーカーの正解率\n",
    "#返り値:混同行列\n",
    "def generate_mild_conf(class_label, m, eta_p, eta_r):#gamma,a をまとめてeta\n",
    "    k = len(class_label)\n",
    "    conf = (1/float(k))*np.ones((m,k,k))\n",
    "    for i in range(m): #ワーカー\n",
    "        #ベータ分布でサンプリングされた値r\n",
    "        eta = np.random.uniform(a, 1.0, k) #ベータ分布で出すb=1で固定a=としてクラス数ぶんr_r,r_pサンプリング\n",
    "                #Oタグの時にはeta_O,それ以外eta_b\n",
    "                #r_r,r_pをサンプリング\n",
    "                #r_rが高い->j,j＝r_r\n",
    "                #r_pが高い->Oタグとjjが高い, kj(kはj以外)が低い\n",
    "                #各クラスにr_r, r_p\n",
    "                conf[i,j,:] = (1 - r)/(k)\n",
    "                conf[i,j,j] += r\n",
    "                #recallとprecisionの値\n",
    "    return conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_ner(y_true, b_tag):\n",
    "    loc_num, misc_num, org_num, per_num = 0, 0, 0, 0\n",
    "    for ans in y_true:\n",
    "        loc_num += ans.count('B-LOC')\n",
    "        misc_num += ans.count('B-MISC')\n",
    "        org_num += ans.count('B-ORG')\n",
    "        per_num += ans.count('B-PER')\n",
    "    return loc_num, misc_num, org_num, per_num\n",
    "    P = loc_num + misc_num + org_num + per_num\n",
    "    TP = int(recall*P) #NER正解データ数\n",
    "    FP = int(TP*((1/precision)-1)) #NERミス\n",
    "    FN = int(P - TP) #NER見逃し\n",
    "    print(\"P\", P, \"TP\", TP, \"FP\", FP, \"FN\", FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2929 1343 2779 2808\n"
     ]
    }
   ],
   "source": [
    "count_ner(y_true, b_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#シミュレーションデータのワーカ生成\n",
    "#混同行列の作成\n",
    "#引数:ラベル,ワーカーの人数,ワーカーの正解率\n",
    "#返り値:混同行列\n",
    "def generate_mild_conf(class_label, m, eta_p, eta_r):#gamma,a をまとめてeta\n",
    "    k = len(class_label)\n",
    "    conf = (1/float(k))*np.ones((m,k,k))\n",
    "    for i in range(m): #ワーカー\n",
    "        #ベータ分布でサンプリングされた値r\n",
    "        eta = np.random.uniform(a, 1.0, k) #ベータ分布で出すb=1で固定a=としてクラス数ぶんr_r,r_pサンプリング\n",
    "                #Oタグの時にはeta_O,それ以外eta_b\n",
    "                #r_r,r_pをサンプリング\n",
    "                #r_rが高い->j,j＝r_r\n",
    "                #r_pが高い->Oタグとjjが高い, kj(kはj以外)が低い\n",
    "                #各クラスにr_r, r_p\n",
    "                conf[i,j,:] = (1 - r)/(k)\n",
    "                conf[i,j,j] += r\n",
    "                #recallとprecisionの値\n",
    "    return conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gammma=0.0\n",
    "#a = 0.0\n",
    "conf = generate_mild_conf(class_label, 47, 0, 0.0)\n",
    "ans_list_temp = generate_ans(X_true5[:1077], y_true5[:1077], labelnum_dic, class_dic_r, conf, 5)\n",
    "write_ans_list(ans_list_temp, 47, '../MBEM/ner-mturk/mild_mv_00.txt')\n",
    "ans_list_temp = generate_ans(X_true[:5385], y_true[:5385], labelnum_dic, class_dic_r, conf, 1)\n",
    "write_ans_list(ans_list_temp, 47, '../MBEM/ner-mturk/mild_single_00.txt')\n",
    "\n",
    "#a = 0.3\n",
    "conf = generate_mild_conf(class_label, 47, 0, 0.3)\n",
    "ans_list_temp = generate_ans(X_true5[:1077], y_true5[:1077], labelnum_dic, class_dic_r, conf, 5)\n",
    "write_ans_list(ans_list_temp, 47, '../MBEM/ner-mturk/mild_mv_03.txt')\n",
    "ans_list_temp = generate_ans(X_true[:5385], y_true[:5385], labelnum_dic, class_dic_r, conf, 1)\n",
    "write_ans_list(ans_list_temp, 47, '../MBEM/ner-mturk/mild_single_03.txt')\n",
    "\n",
    "#a = 0.5\n",
    "conf = generate_mild_conf(class_label, 47, 0, 0.5)\n",
    "ans_list_temp = generate_ans(X_true5[:1077], y_true5[:1077], labelnum_dic, class_dic_r, conf, 5)\n",
    "write_ans_list(ans_list_temp, 47, '../MBEM/ner-mturk/mild_mv_05.txt')\n",
    "ans_list_temp = generate_ans(X_true[:5385], y_true[:5385], labelnum_dic, class_dic_r, conf, 1)\n",
    "write_ans_list(ans_list_temp, 47, '../MBEM/ner-mturk/mild_single_05.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a = 0.7\n",
    "conf = generate_mild_conf(class_label, 47, 0, 0.5)\n",
    "ans_list_temp = generate_ans(X_true5[:1077], y_true5[:1077], labelnum_dic, class_dic_r, conf, 5)\n",
    "write_ans_list(ans_list_temp, 47, '../MBEM/ner-mturk/mild_mv_07.txt')\n",
    "ans_list_temp = generate_ans(X_true[:5385], y_true[:5385], labelnum_dic, class_dic_r, conf, 1)\n",
    "write_ans_list(ans_list_temp, 47, '../MBEM/ner-mturk/mild_single_07.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "worker_num 47\n",
      "クラス： {'B-LOC': 0, 'B-MISC': 1, 'B-ORG': 2, 'B-PER': 3, 'I-LOC': 4, 'I-MISC': 5, 'I-ORG': 6, 'I-PER': 7, 'O': 8}\n",
      "タスク数 5385\n",
      "タスク数(単語): 70985\n",
      "語彙数 12378\n"
     ]
    }
   ],
   "source": [
    "class_list = list(set(l.split()[1] for l in open(truth_file) if l != \"\\n\"))\n",
    "class_dic = {k:i for i, k in enumerate(sorted(class_list))}\n",
    "class_dic_r = {class_dic[c]:c for c in class_dic}\n",
    "class_label = {'LOC': 0, 'MISC': 1, 'ORG': 2, 'PER': 3, 'O': 4}\n",
    "labelnum_dic = {'B-LOC': 0, 'B-MISC': 1, 'B-ORG': 2, 'B-PER': 3, 'I-LOC': 0, 'I-MISC': 1, 'I-ORG': 2, 'I-PER': 3, 'O': 4}\n",
    "s1 = {'B-LOC': 'B-MISC', 'B-MISC': 'B-ORG', 'B-ORG': 'B-PER', 'B-PER': 'B-LOC', 'I-LOC': 'I-MISC', 'I-MISC': 'I-ORG', 'I-ORG': 'I-PER', 'I-PER': 'I-LOC', 'O':'O'}\n",
    "s2 = {'B-LOC': 'B-ORG', 'B-MISC': 'B-PER', 'B-ORG': 'B-LOC', 'B-PER':'B-MISC' , 'I-LOC': 'I-ORG', 'I-MISC': 'I-PER', 'I-ORG':  'I-LOC', 'I-PER':'I-MISC', 'O':'O'}\n",
    "class_shuffle = [s1, s2]\n",
    "b_tag = ['B-LOC', 'B-MISC', 'B-ORG', 'B-PER']\n",
    "#データの読み込み\n",
    "ans_train, words_dic = load_crowd_data(ans_file, truth_file, train_num)\n",
    "X_true, y_true = read_output('../MBEM/ner-mturk/ground_truth.txt', class_dic_r)\n",
    "X_true5, y_true5 = read_output('../MBEM/ner-mturk/testset5.txt', class_dic_r)\n",
    "workers_count = []\n",
    "for i in range(len(ans_train)):\n",
    "    for w in ans_train[i][1]:\n",
    "        workers_count.append(w)\n",
    "worker_num = len(set(workers_count))\n",
    "\n",
    "#多分データを変えるごとにクラス確認したくなるので残しておく\n",
    "num_words = 0\n",
    "for l in ans_train:\n",
    "    num_words += len(l[0])\n",
    "print(\"worker_num\", worker_num)\n",
    "print(\"クラス：\",class_dic)\n",
    "print(\"タスク数\",len(ans_train))\n",
    "print(\"タスク数(単語):\", num_words)\n",
    "print(\"語彙数\", len(words_dic))\n",
    "worker_num = 47"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ans_mは回答(redundancy)×タスク(単語)×ラベル数\n",
    "ans_m = ans_matrix(ans_train, redundancy, k)\n",
    "ans_m = ans_m.transpose(1, 0, 2) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mv 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Algorithm 1\n",
    "#deep-learining-modelに渡すデータの書き込み\n",
    "w_list = []\n",
    "i = 0\n",
    "simple_agg = init_posdis(redundancy, ans_m, k)\n",
    "for task in ans_train:\n",
    "    for word in task[0]:\n",
    "        w_list.append(word +\" \"+ str(class_dic_r[int(simple_agg[i])]) + \"\\n\")\n",
    "        i += 1\n",
    "    w_list.append(\"\\n\")\n",
    "w_file = path_w + \"/agg_mild_mv_03.txt\"\n",
    "with open(w_file, mode='w') as f:\n",
    "    f.writelines(w_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subprocess.run(['./deep-learning-models/python', 'main.py', 'dataset_reader=normal_bc5cdr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1  iteration\n",
      "\n",
      "labels_md [6.72143920e-02 2.52850768e-02 2.59225158e-02 2.04688717e-02\n",
      " 9.20745095e-04 6.37438912e-04 4.53289893e-03 5.17033784e-03\n",
      " 8.49847723e-01]\n"
     ]
    }
   ],
   "source": [
    "iter_time = 1\n",
    "print(iter_time, \" iteration\\n\")\n",
    "est_labels = get_newest_prediction()\n",
    "#if len(est_labels[0]) == 22:\n",
    "#    est_labels[0].insert(0, '3')\n",
    "est_labels, e_conf = post_prob_DS(label2num(est_labels[0:train_num5], class_dic, class_dic_r), ans_train, k, worker_num, num_words)\n",
    "write_prediction(label2num(est_labels, class_dic, class_dic_r), ans_train, iter_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2  iteration\n",
      "\n",
      "labels_md [0.03208443 0.01643176 0.04369998 0.04681635 0.         0.\n",
      " 0.         0.         0.86096749]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jimmy/.pyenv/versions/anaconda3-5.2.0/lib/python3.6/site-packages/ipykernel_launcher.py:30: RuntimeWarning: divide by zero encountered in log\n"
     ]
    }
   ],
   "source": [
    "iter_time = 2\n",
    "print(iter_time, \" iteration\\n\")\n",
    "est_labels = get_newest_prediction()\n",
    "est_labels, e_conf = post_prob_DS(label2num(est_labels[0:train_num], class_dic, class_dic_r), ans_train, k, worker_num, num_words)\n",
    "write_prediction(label2num(est_labels, class_dic, class_dic_r), ans_train, iter_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3  iteration\n",
      "\n",
      "labels_md [0.0389546  0.01643176 0.0434875  0.04207097 0.         0.\n",
      " 0.         0.         0.85905517]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jimmy/.pyenv/versions/anaconda3-5.2.0/lib/python3.6/site-packages/ipykernel_launcher.py:30: RuntimeWarning: divide by zero encountered in log\n"
     ]
    }
   ],
   "source": [
    "iter_time = 3\n",
    "print(iter_time, \" iteration\\n\")\n",
    "est_labels = get_newest_prediction()\n",
    "est_labels, e_conf = post_prob_DS(label2num(est_labels[0:train_num], class_dic, class_dic_r), ans_train, k, worker_num, num_words)\n",
    "write_prediction(label2num(est_labels, class_dic, class_dic_r), ans_train, iter_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4  iteration\n",
      "\n",
      "labels_md [0.03498831 0.0160068  0.04957858 0.04780792 0.         0.\n",
      " 0.         0.         0.85161839]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jimmy/.pyenv/versions/anaconda3-5.2.0/lib/python3.6/site-packages/ipykernel_launcher.py:30: RuntimeWarning: divide by zero encountered in log\n"
     ]
    }
   ],
   "source": [
    "iter_time = 4\n",
    "print(iter_time, \" iteration\\n\")\n",
    "est_labels = get_newest_prediction()\n",
    "est_labels, e_conf = post_prob_DS(label2num(est_labels[0:train_num], class_dic, class_dic_r), ans_train, k, worker_num, num_words)\n",
    "write_prediction(label2num(est_labels, class_dic, class_dic_r), ans_train, iter_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5  iteration\n",
      "\n",
      "labels_md [0.03498831 0.0160068  0.04957858 0.04780792 0.         0.\n",
      " 0.         0.         0.85161839]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jimmy/.pyenv/versions/anaconda3-5.2.0/lib/python3.6/site-packages/ipykernel_launcher.py:30: RuntimeWarning: divide by zero encountered in log\n"
     ]
    }
   ],
   "source": [
    "iter_time = 5\n",
    "print(iter_time, \" iteration\\n\")\n",
    "est_labels = get_newest_prediction()\n",
    "est_labels, e_conf = post_prob_DS(label2num(est_labels[0:train_num], class_dic, class_dic_r), ans_train, k, worker_num, num_words)\n",
    "write_prediction(label2num(est_labels, class_dic, class_dic_r), ans_train, iter_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "single label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Algorithm 1\n",
    "#deep-learining-modelに渡すデータの書き込み\n",
    "w_list = []\n",
    "i = 0\n",
    "simple_agg = init_posdis_single(redundancy, ans_m, k)\n",
    "for task in ans_train:\n",
    "    for word in task[0]:\n",
    "        w_list.append(word +\" \"+ str(class_dic_r[int(simple_agg[i])]) + \"\\n\")\n",
    "        i += 1\n",
    "    w_list.append(\"\\n\")\n",
    "w_file = path_w + \"/agg_mild_single_07.txt\"\n",
    "with open(w_file, mode='w') as f:\n",
    "    f.writelines(w_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1  iteration\n",
      "\n",
      "labels_md [0.02856942 0.01611608 0.03659928 0.02496302 0.02411777 0.0101289\n",
      " 0.01381982 0.01914489 0.82654082]\n"
     ]
    }
   ],
   "source": [
    "iter_time = 1\n",
    "print(iter_time, \" iteration\\n\")\n",
    "est_labels = get_newest_prediction()\n",
    "est_labels, e_conf = post_prob_DS(label2num(est_labels[0:train_num], class_dic, class_dic_r), ans_train, k, worker_num, num_words)\n",
    "write_prediction(label2num(est_labels, class_dic, class_dic_r), ans_train, iter_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2  iteration\n",
      "\n",
      "labels_md [0.03588082 0.01949708 0.04646052 0.05171515 0.         0.\n",
      " 0.         0.         0.84644643]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jimmy/.pyenv/versions/anaconda3-5.2.0/lib/python3.6/site-packages/ipykernel_launcher.py:30: RuntimeWarning: divide by zero encountered in log\n"
     ]
    }
   ],
   "source": [
    "iter_time = 2\n",
    "print(iter_time, \" iteration\\n\")\n",
    "est_labels = get_newest_prediction()\n",
    "est_labels, e_conf = post_prob_DS(label2num(est_labels[0:train_num], class_dic, class_dic_r), ans_train, k, worker_num, num_words)\n",
    "write_prediction(label2num(est_labels, class_dic, class_dic_r), ans_train, iter_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3  iteration\n",
      "\n",
      "labels_md [0.04268507 0.02275129 0.05595548 0.05718109 0.         0.\n",
      " 0.         0.         0.82142706]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jimmy/.pyenv/versions/anaconda3-5.2.0/lib/python3.6/site-packages/ipykernel_launcher.py:30: RuntimeWarning: divide by zero encountered in log\n"
     ]
    }
   ],
   "source": [
    "iter_time = 3\n",
    "print(iter_time, \" iteration\\n\")\n",
    "est_labels = get_newest_prediction()\n",
    "est_labels, e_conf = post_prob_DS(label2num(est_labels[0:train_num], class_dic, class_dic_r), ans_train, k, worker_num, num_words)\n",
    "write_prediction(label2num(est_labels, class_dic, class_dic_r), ans_train, iter_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4  iteration\n",
      "\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-b40b0d6e6e5a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter_time\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\" iteration\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mest_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_newest_prediction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mest_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me_conf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpost_prob_DS\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel2num\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mest_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1077\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_dic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_dic_r\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mans_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mworker_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_words\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mwrite_prediction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel2num\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mest_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_dic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_dic_r\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mans_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miter_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-74f8863635e1>\u001b[0m in \u001b[0;36mpost_prob_DS\u001b[0;34m(est_labels, ans_train, k, worker_num, num_words)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mans_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0;31m#真のラベルの周辺分布を更新\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m             \u001b[0mlabels_md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mest_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mans_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m#各回答ワーカーについて\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m                 \u001b[0mtemp_conf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtemp_conf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mouter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meye\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mest_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meye\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mans_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#外積 混同行列の作成\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "iter_time = 4\n",
    "print(iter_time, \" iteration\\n\")\n",
    "est_labels = get_newest_prediction()\n",
    "est_labels, e_conf = post_prob_DS(label2num(est_labels[0:train_num], class_dic, class_dic_r), ans_train, k, worker_num, num_words)\n",
    "write_prediction(label2num(est_labels, class_dic, class_dic_r), ans_train, iter_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5  iteration\n",
      "\n",
      "labels_md [0.04055786 0.         0.01790519 0.02676622 0.00571952 0.\n",
      " 0.01300275 0.02435726 0.8716912 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jimmy/.pyenv/versions/anaconda3-5.2.0/lib/python3.6/site-packages/ipykernel_launcher.py:30: RuntimeWarning: divide by zero encountered in log\n"
     ]
    }
   ],
   "source": [
    "iter_time = 5\n",
    "print(iter_time, \" iteration\\n\")\n",
    "est_labels = get_newest_prediction()\n",
    "est_labels, e_conf = post_prob_DS(label2num(est_labels[0:train_num], class_dic, class_dic_r), ans_train, k, worker_num, num_words)\n",
    "write_prediction(label2num(est_labels, class_dic, class_dic_r), ans_train, iter_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1  iteration\n",
      "\n",
      "2  iteration\n",
      "\n",
      "3  iteration\n",
      "\n",
      "4  iteration\n",
      "\n",
      "5  iteration\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for t in range(iteration_times):\n",
    "    print(t+1, \" iteration\\n\")\n",
    "    est_labels = get_newest_prediction()\n",
    "    if len(est_labels[0]) == 22:\n",
    "        est_labels[0].insert(0, '3')\n",
    "    est_labels, e_conf = post_prob_DS(est_labels[0:train_num], ans_train, k, worker_num, num_words)\n",
    "    write_prediction(est_labels, ans_train, t+1)\n",
    "    subprocess.run(['python', './deep-learning-models/main.py', 'dataset_reader=normal_bc5cdr2']) #ここがうまく行かない"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "確率でやりたい時にはこちら(probの方がうまく動かせないので後で直す)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ワーカのタスクに対する回答の事後確率の初期化\n",
    "#Algorithm 1のInitialixe posterior distribution using weighted mv(論文p6)\n",
    "def init_posdis_p(redundancy, ans_m, k):\n",
    "    simple_agg = np.zeros((num_words,k))\n",
    "    mv_ans = np.zeros((num_words))\n",
    "    for r in range(redundancy):\n",
    "        simple_agg += (1/redundancy)*ans_m[r] #simple_aggをmvせずにそのまま使えるようにしたい\n",
    "    return simple_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Algorithm 1\n",
    "#deep-learining-modelに渡すデータの書き込み\n",
    "w_list = [str(class_dic_r)+\"\\n\\n\"]\n",
    "i = 0\n",
    "simple_agg = init_posdis_p(redundancy, ans_m, k)\n",
    "for task in ans_train:\n",
    "    for word in task[0]:\n",
    "        w_list.append(word +\" \"+ str(simple_agg[i])[1:-1] + \"\\n\")\n",
    "        i += 1\n",
    "    w_list.append(\"\\n\")\n",
    "w_file = path_w + \"/simple_agg_p.txt\"\n",
    "with open(w_file, mode='w') as f:\n",
    "    f.writelines(w_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5  iteration\n",
      "\n",
      "labels_md [0.04041827 0.01312667 0.02640166 0.03396618 0.00496885 0.00904776\n",
      " 0.0120884  0.02921982 0.83076239]\n"
     ]
    }
   ],
   "source": [
    "iter_time = 5\n",
    "print(iter_time, \" iteration\\n\")\n",
    "est_labels = get_newest_prediction()\n",
    "#if len(est_labels[0]) == 22:\n",
    "#    est_labels[0].insert(0, '3')\n",
    "est_labels, e_conf = post_prob_DS(label2num(est_labels[0:train_num5], class_dic, class_dic_r), ans_train, k, worker_num, num_words)\n",
    "write_prediction(label2num(est_labels, class_dic, class_dic_r), ans_train, iter_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'simple_pred' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-f6ae168b7ffd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mest_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0msimple_pred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msimple_pred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miteration_times\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\" iteration\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m#simple_pred(weighed mv)とans_train(回答と回答ワーカ)を使って学習\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m#simple_predを使うのは事前分布のため\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'simple_pred' is not defined"
     ]
    }
   ],
   "source": [
    "est_labels = simple_pred\n",
    "for t in range(iteration_times):\n",
    "    print(t, \" iteration\\n\")\n",
    "    #simple_pred(weighed mv)とans_train(回答と回答ワーカ)を使って学習\n",
    "    #simple_predを使うのは事前分布のため\n",
    "    #学習機のtrainと推定ラベルの更新\n",
    "    model, est_labels = train(words_dic, class_dic, ans_train, est_labels)\n",
    "    #est_labelsで混同行列の更新\n",
    "    est_labels, e_conf = post_prob_DS(est_labels, ans_train, k, worker_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ニューラルネットワーク"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29\n"
     ]
    }
   ],
   "source": [
    "print(len(get_newest_prediction()[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ワーカーの回答ラベルでtrainしてmodelとpredicted_labels(タスク数*各文書単語数list)を返す\n",
    "def train(words_dic, class_dic, ans_train, ans_labels):\n",
    "    EMBEDDING_DIM = 5\n",
    "    HIDDEN_DIM = 4\n",
    "    predicted_labels = []\n",
    "    model = BiLSTM_CRF(len(words_dic), class_dic, EMBEDDING_DIM, HIDDEN_DIM)\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.01, weight_decay=1e-4)\n",
    "    # Modelトレーニング\n",
    "    for epoch in range(2):\n",
    "        m = 0\n",
    "        for sentence, worker, classes in ans_train:\n",
    "            # 勾配の初期化\n",
    "            model.zero_grad()\n",
    "            tags = ans_labels[m:m+len(sentence)]\n",
    "            sentence_in = prepare_sequence(sentence, words_dic)\n",
    "            targets = torch.tensor(tags, dtype=torch.long)\n",
    "            loss = model.neg_log_likelihood(sentence_in, targets)\n",
    "            # 損失関数と勾配の計算をしてパラメータ更新\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    #ラベル予測\n",
    "    for i in range(len(ans_train)):\n",
    "        with torch.no_grad():\n",
    "            check_sent = prepare_sequence(ans_train[i][0], words_dic)\n",
    "            predicted_labels.append(model(check_sent))\n",
    "    return model, predicted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A', 'newborn', 'with', 'massive', 'tricuspid', 'regurgitation', '&#44;', 'atrial', 'flutter', '&#44;', 'congestive', 'heart', 'failure', '&#44;', 'and', 'a', 'high', 'serum', 'lithium', 'level', 'is', 'described', '.']\n",
      "(tensor(83.0933), [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    precheck_sent = prepare_sequence(ans_train[6][0], words_dic)\n",
    "    print(ans_train[0][0])\n",
    "    print(model(precheck_sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
