{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import glob\n",
    "import numpy as np\n",
    "import os\n",
    "import scipy.special as special\n",
    "\n",
    "from itertools import groupby\n",
    "\n",
    "ans_path = './ner-mturk/answers*'\n",
    "ans_file_list = sorted(glob.glob(ans_path))\n",
    "single_ans_list = sorted(glob.glob('ner-mturk/single_ans*'))\n",
    "truth_file = './ner-mturk/ground_truth.txt'\n",
    "path_w = './MBEM_outputs'\n",
    "alltask_num = 5985\n",
    "train_num = 5385\n",
    "train_num5 = 1077\n",
    "test_num = 600\n",
    "redundancy = 5\n",
    "iteration_times = 5\n",
    "ans_file = single_ans_list[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_output(path, class_dic_r, to_label=False):\n",
    "    f = open(path)\n",
    "    make_xypair = lambda v: list(zip(*[l.strip().split() for l in v]))\n",
    "    is_emptyline = lambda x: x.strip() != '' and not x.startswith('-DOCSTART-')\n",
    "    list_int = lambda t: list([class_dic_r[int(v)] for v in t])\n",
    "    xypairs = [make_xypair(v) for k, v in groupby(f, is_emptyline) if k]\n",
    "    if to_label == True:\n",
    "        return ([p[0] for p in xypairs], [list(list_int(p[1])) for p in xypairs])\n",
    "    if len(xypairs[0]) == 2:\n",
    "        return ([p[0] for p in xypairs], [list(p[1]) for p in xypairs])\n",
    "    else:\n",
    "        return ([p[0] for p in xypairs], [list(p[1:]) for p in xypairs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_crowd_data(ans_file, truth_file, train_num):\n",
    "    #answers_list[task_num] = [[words, ...], [worker], [[answers]...]]\n",
    "    answers_list = []\n",
    "    sentence = []\n",
    "    answers = []\n",
    "    worker = []\n",
    "    words_dic = {}\n",
    "    get_worker = lambda x: tuple([i for i, l in enumerate(x) if l !='?'])\n",
    "    for l in open(ans_file):\n",
    "        ans = l.split()\n",
    "        if len(l) < 2:\n",
    "            answers_list.append([sentence, worker, answers])\n",
    "            sentence = []\n",
    "            worker = []\n",
    "            answers = []\n",
    "        else:\n",
    "            if len(worker) < 1:\n",
    "                worker = get_worker(ans[1:])\n",
    "            if not ans[0] in words_dic:\n",
    "                words_dic[ans[0]] = len(words_dic)\n",
    "            sentence.append(ans[0])\n",
    "            answers.append(get_ans(worker, ans[1:]))            \n",
    "    #truth_list: [(task_word, answer), ....]\n",
    "    truth_list = [tuple(l.split()) for l in open(truth_file) if l != \"\\n\"]\n",
    "    ans_train = answers_list[0:train_num]\n",
    "#    ans_test = answers_list[train_num:]\n",
    "    return ans_train, words_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ans(workers, answers):\n",
    "    ans_label = []\n",
    "    for a in workers:\n",
    "        ans_label.append(class_dic[answers[a]])\n",
    "    return ans_label\n",
    "def label2num(answers, class_dic, class_dic_r):\n",
    "    ans_return = copy.deepcopy(answers)\n",
    "    if answers[0][0] in class_dic:\n",
    "        for i in range(len(answers)):\n",
    "            for w in range(len(answers[i])):\n",
    "                ans_return[i][w] = class_dic[answers[i][w]]\n",
    "    elif answers[0][0] in class_dic_r:\n",
    "        for i in range(len(answers)):\n",
    "            for w in range(len(answers[i])):\n",
    "                ans_return[i][w] = class_dic_r[int(answers[i][w])]\n",
    "    else: print(\"error\")\n",
    "    return ans_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ワーカのタスクに対する回答の事後確率の初期化\n",
    "#Algorithm 1のInitialixe posterior distribution using weighted mv(論文p6)\n",
    "def init_posdis(redundancy, ans_m, k):\n",
    "    simple_agg = np.zeros((num_words,k))\n",
    "    mv_ans = np.zeros((num_words))\n",
    "    for r in range(redundancy):\n",
    "        simple_agg += (1/redundancy)*ans_m[r]\n",
    "    for i in range(len(simple_agg)):\n",
    "        mv_ans[i] = np.argmax(simple_agg[i])\n",
    "    return mv_ans\n",
    "def ans_matrix(ans_train, redundancy, k):\n",
    "    ans_m = np.zeros((num_words, redundancy,k))\n",
    "    m = 0\n",
    "    for n in range(len(ans_train)):\n",
    "        for i in range(len(ans_train[n][0])):\n",
    "            ans_m[m] = np.eye(k)[ans_train[n][2][i][:5]]\n",
    "            m += 1\n",
    "    return ans_m\n",
    "#deep-learining-modelに渡すデータの書き込み\n",
    "def write_prediction(est_labels, ans_train, iter_num):\n",
    "    w_list = []\n",
    "    for n in range(len(ans_train)):\n",
    "        for i in range(len(ans_train[n][0])):\n",
    "            w_list.append(ans_train[n][0][i] +\" \"+ str(est_labels[n][i]) + \"\\n\")\n",
    "        w_list.append(\"\\n\")\n",
    "    w_file = path_w + \"/prediction.txt\"\n",
    "    with open(w_file, mode='w') as f:\n",
    "        f.writelines(w_list)\n",
    "    with open(\"./MBEM_outputs/prediction\"+str(iter_num)+\".txt\", mode='w') as f:\n",
    "        f.writelines(w_list)\n",
    "#deep-learning-modelからのデータの読み込み\n",
    "def get_newest_prediction():\n",
    "    files_list = glob.glob(\"./deep-learning-model/outputs/*\")\n",
    "    latest_file = max(glob.glob(max(files_list, key=os.path.getctime)+\"/*\"), key=os.path.getctime) + \"/best_model_log/pred.txt\"\n",
    "    prediction_list = [list(l.split()) for l in open(latest_file) if l != \"\\n\"]\n",
    "    return prediction_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "worker_num 47\n",
      "クラス： {'B-LOC': 0, 'B-MISC': 1, 'B-ORG': 2, 'B-PER': 3, 'I-LOC': 4, 'I-MISC': 5, 'I-ORG': 6, 'I-PER': 7, 'O': 8}\n",
      "クラス数： 9\n",
      "タスク数 5385\n",
      "タスク数(単語): 70985\n",
      "語彙数 12378\n"
     ]
    }
   ],
   "source": [
    "class_list = list(set(l.split()[1] for l in open(truth_file) if l != \"\\n\"))\n",
    "class_dic = {k:i for i, k in enumerate(sorted(class_list))}\n",
    "class_dic_r = {class_dic[c]:c for c in class_dic}\n",
    "class_label = {'LOC': 0, 'MISC': 1, 'ORG': 2, 'PER': 3, 'O': 4}\n",
    "labelnum_dic = {'B-LOC': 0, 'B-MISC': 1, 'B-ORG': 2, 'B-PER': 3, 'I-LOC': 0, 'I-MISC': 1, 'I-ORG': 2, 'I-PER': 3, 'O': 4}\n",
    "#データの読み込み\n",
    "ans_train, words_dic = load_crowd_data(ans_file, truth_file, train_num)\n",
    "X_true, y_true = read_output('../MBEM/ner-mturk/ground_truth.txt', class_dic_r)\n",
    "X_true5, y_true5 = read_output('../MBEM/ner-mturk/testset5.txt', class_dic_r)\n",
    "workers_count = []\n",
    "for i in range(len(ans_train)):\n",
    "    for w in ans_train[i][1]:\n",
    "        workers_count.append(w)\n",
    "worker_num = len(set(workers_count))\n",
    "class_num = len(class_dic)\n",
    "#多分データを変えるごとにクラス確認したくなるので残しておく\n",
    "num_words = 0\n",
    "for l in ans_train:\n",
    "    num_words += len(l[0])\n",
    "print(\"worker_num\", worker_num)\n",
    "print(\"クラス：\",class_dic)\n",
    "print(\"クラス数：\", class_num)\n",
    "print(\"タスク数\",len(ans_train))\n",
    "print(\"タスク数(単語):\", num_words)\n",
    "print(\"語彙数\", len(words_dic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ans_mは回答(redundancy)×タスク(単語)×ラベル数\n",
    "ans_m = ans_matrix(ans_train, redundancy, k)\n",
    "ans_m = ans_m.transpose(1, 0, 2) \n",
    "#deep-learining-modelに渡すデータの書き込み\n",
    "w_list = []\n",
    "i = 0\n",
    "simple_agg = init_posdis(redundancy, ans_m, k)\n",
    "for task in ans_train:\n",
    "    for word in task[0]:\n",
    "        w_list.append(word +\" \"+ str(class_dic_r[int(simple_agg[i])]) + \"\\n\")\n",
    "        i += 1\n",
    "    w_list.append(\"\\n\")\n",
    "w_file = path_w + \"/agg_test.txt\"\n",
    "with open(w_file, mode='w') as f:\n",
    "    f.writelines(w_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_agg, y_agg = read_output('./MBEM_outputs/agg_test.txt', class_dic_r, to_label=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "est_labels = get_newest_prediction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_occurence(est_labels, ans_train, words_dic):\n",
    "    occurence = np.zeros((J,len(words_dic)))\n",
    "    for n in range(len(ans_train)):\n",
    "        for t in range(len(ans_train[n][0])):\n",
    "            occurence[class_dic[est_labels[n][t]],words_dic[ans_train[n][0][t]]] += 1\n",
    "    return occurence\n",
    "def cal_exp_log_rho(kappa, occurence):\n",
    "    exp_log_rho = np.zeros((J,len(words_dic)))\n",
    "    for j in range(J):\n",
    "        exp_log_rho[j] = special.digamma(occurence[j]+kappa[j]) - special.digamma(np.sum(occurence+kappa,axis=0))\n",
    "    return exp_log_rho\n",
    "def cal_exp_log_conf(N, K, J):\n",
    "    exp_log_conf = np.zeros((K,J,J,J)) \n",
    "    for k in range(K):\n",
    "        for j in range(J):\n",
    "            for l in range(J):\n",
    "                for m in range(J):\n",
    "                    exp_log_conf[k,j,l,m] = special.digamma(N[k,j,l,m]) - special.digamma(np.sum(N[k,j,l]))\n",
    "    return exp_log_conf\n",
    "def cal_exp_log_transe(N_s, gamma):\n",
    "    exp_log_transe = np.zeros((J,J))\n",
    "    exp_log_transe = special.digamma(N_s+gamma) - np.matrix(np.ones((J,J)))*special.digamma(np.sum(N_s[j]+gamma[j]))\n",
    "    return exp_log_transe\n",
    "def cal_ll(exp_log_conf, exp_log_rho, J, x): \n",
    "    ll = np.zeros((J))\n",
    "    temp_sum = np.sum(exp_log_conf[:,:,ans_train[n]]) * rho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#未完成\n",
    "def cal_N(alpha, ans_train, label_post):\n",
    "    temp_sum = np.zeros((K,J,J,J))\n",
    "    N = np.zeros((K,J,J,J))\n",
    "    ans = label2num(answers, class_dic, class_dic_r)\n",
    "    for n in range(len(ans_train)):\n",
    "        for t in range(len(ans_train[n][0])):\n",
    "            #ここはワーカーの人数拡張に伴って変更する必要あり\n",
    "            if t == 0:\n",
    "                temp_sum += label_post[n,t]\n",
    "            temp_sum += label_post[n,t] \\\n",
    "            *(np.matrix(np.identity(class_num)[ans_train[n][2][t][0]]).T*np.matrix(np.identity(class_num)[ans_train[n][2][t][0]])[:, :, np.newaxis] \\\n",
    "            *np.matrix(np.identity(class_num)[ans_train[n][2][t-1][0]]).T *np.matrix(np.identity(class_num)[ans_train[n][2][t-1][0]]))\n",
    "    N = alpha + temp_sum\n",
    "    return N\n",
    "def cal_N_s(post_transe):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input \n",
    "#ラベル :y\n",
    "#単語: x\n",
    "\n",
    "K = worker_num\n",
    "J = class_num\n",
    "#初期値を設定する\n",
    "conf = np.zeros((K,J,J,J)) #worker,true_label,woker_ans(n-1),worker_ans(n)\n",
    "trans_prob = np.zeros((J,J))\n",
    "\n",
    "#0.1くらいで\n",
    "alpha = 0.1 * np.ones((K,J,J,J))\n",
    "kappa = 10 * np.ones((J, len(words_dic)))\n",
    "gamma = 10 * np.ones((J,J))\n",
    "\n",
    "occurence = cal_occurence(est_labels, ans_train, words_dic)\n",
    "exp_log_rho = cal_exp_log_rho(kappa, occurence)\n",
    "\n",
    "conf = np.random.dirichlet(alpha, size=(K,J,J,J)) #worker,true_label,woker_ans(n-1),worker_ans(n)\n",
    "trans_prob = np.random.dirichlet(gamma, size=(J,J)) #遷移確率\n",
    "\n",
    "label_trans_num = np.zeros((K,J,J,J))\n",
    "\n",
    "\n",
    "        \n",
    "def forward(exp_log_rho, exp_log_trans, x, y, J):\n",
    "    n = len(y) # タスク数\n",
    "    # 前向きアルゴリズム\n",
    "    log_r_m = np.zeros((n, J))\n",
    "\n",
    "    for t in range(n):\n",
    "        if t == 0:\n",
    "            ll[y[t]] = exp_log_rho\n",
    "            log_r_m[t] = ll[y[t]]\n",
    "            continue\n",
    "        ll = cal_ll(exp_log_conf, exp_log_rho, J, x[t])\n",
    "        temp_sum = 0\n",
    "        for l in range(J):\n",
    "            temp_sum += log_r_m[t-1,l] + exp_log_trans[l,j]\n",
    "        log_r_m[t] = temp_sum + ll\n",
    "\n",
    "        return log_r_m\n",
    "\n",
    "def backward(exp_log_rho, exp_log_trans, x, y, J):\n",
    "    n = len(y) \n",
    "    # 後ろ向きアルゴリズム\n",
    "    log_lambda = np.zeros((n,J))\n",
    "    back_lambda = np.zeros((n,J))\n",
    "    ll = np.zeros((n,J))\n",
    "    ll[t] = cal_ll(exp_log_conf, exp_log_rho, J, x[t])\n",
    "    for a in range(n):\n",
    "        t = n-1-a\n",
    "        ll[t] = cal_ll(exp_log_conf, exp_log_rho, J, x[t+1])\n",
    "        for l in range(J):\n",
    "            log_lambda[t] += log_lambda[t+1,l] + exp_log_trans[j,l] + ll[t+1,l]\n",
    "    back_lambda = np.exp(log_lambda) \n",
    "\n",
    "#ビタビアルゴリズム\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_log_trans = cal_exp_log_trans(N_s, gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input \n",
    "#ラベル :y\n",
    "#単語: x\n",
    "\n",
    "K = worker_num\n",
    "J = class_num\n",
    "#初期値を設定する\n",
    "conf = np.zeros((K,J,J,J)) #worker,true_label,woker_ans(n-1),worker_ans(n)\n",
    "rho = np.zeros((J)) #出力確率\n",
    "trans_prob = np.zeros((J,J))\n",
    "\n",
    "class VB:\n",
    "    def __init__(self, K, J, alpha, kappa, gamma ):\n",
    "        self.conf = np.random.dirichlet(alpha, size=(K,J,J,J)) #worker,true_label,woker_ans(n-1),worker_ans(n)\n",
    "        self.rho = np.random.dirichlet(kappa, size=(J)) #出力確率\n",
    "        self.trans_prob = np.random.dirichlet(gamma, size=(J,J)) #遷移確率\n",
    "        \n",
    "    def forward(self, y, J):\n",
    "        n = len(y) # タスク数\n",
    "\n",
    "        # 前向きアルゴリズム\n",
    "        r = np.zeros((n, J))\n",
    "        ll\n",
    "        \n",
    "\n",
    "        # Step2\n",
    "        for t in range(1, n):\n",
    "            alpha[t, :] = np.dot(alpha[t-1, :], A) * B[:, x[t]]\n",
    "\n",
    "        # Step3\n",
    "        return round(np.sum(alpha[-1]), 3)\n",
    "\n",
    "    def backward(self, x, c):\n",
    "        n = len(x) # 観測回数\n",
    "\n",
    "        # 後ろ向きアルゴリズム\n",
    "        # Step1\n",
    "        beta = np.zeros((n, c))\n",
    "        beta[-1, :] = 1\n",
    "\n",
    "        # Step2\n",
    "        for t in range((n-1), 0, -1):\n",
    "            beta[t-1, :] = np.dot(self.A, (self.B[:, x[t]] * beta[t, :]))\n",
    "\n",
    "        # Step3\n",
    "        return round(sum(p[:] * self.B[:, x[0]] * beta[0, :]), 3)\n",
    "    \n",
    "    def exp_log_conf(\n",
    "\n",
    "\n",
    "        \n",
    "#前向き後ろ向きアルゴリズム\n",
    "#論文の7式\n",
    "\n",
    "#ビタビアルゴリズム\n",
    "\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.VB at 0x7f5bc031ed90>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha = 10 * np.ones((K))\n",
    "kappa = 10 * np.ones((J))\n",
    "gamma = 10 * np.ones((J,J))\n",
    "VB(K,J,alpha,kappa,gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "type object 'VB' has no attribute 'conf'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-3fc33e1ecf75>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mVB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: type object 'VB' has no attribute 'conf'"
     ]
    }
   ],
   "source": [
    "VB.conf[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_symbol = [ \"w1\", \"w2\", \"w3\" ] # 状態\n",
    "c = len(s_symbol)               # 状態数\n",
    "v_symbol = [ \"v1\", \"v2\" ]       # 出力記号\n",
    "m = len(v_symbol)               # 出力数\n",
    "\n",
    "# 遷移確率行列\n",
    "A = np.array([[0.1, 0.7, 0.2], [0.2, 0.1, 0.7], [0.7, 0.2, 0.1]])\n",
    "# 出力確率行列\n",
    "B = np.array([[0.9, 0.1], [0.6, 0.4], [0.1, 0.9]])\n",
    "# 初期確率行列\n",
    "p = np.array([1/3, 1/3, 1/3])\n",
    "\n",
    "class HMM:\n",
    "\n",
    "    def __init__(self, p, A, B): \n",
    "        self.p = p\n",
    "        self.A = A\n",
    "        self.B = B\n",
    "\n",
    "    def forward(self, x, c):\n",
    "        n = len(x) # 観測回数\n",
    "\n",
    "        # 前向きアルゴリズム\n",
    "        alpha = np.zeros((n, c))\n",
    "\n",
    "        # Step1\n",
    "        alpha[0, :] = p[:] * B[:, x[0]]\n",
    "\n",
    "        # Step2\n",
    "        for t in range(1, n):\n",
    "            alpha[t, :] = np.dot(alpha[t-1, :], A) * B[:, x[t]]\n",
    "\n",
    "        # Step3\n",
    "        return round(np.sum(alpha[-1]), 3)\n",
    "\n",
    "    def backward(self, x, c):\n",
    "        n = len(x) # 観測回数\n",
    "\n",
    "        # 後ろ向きアルゴリズム\n",
    "        # Step1\n",
    "        beta = np.zeros((n, c))\n",
    "        beta[-1, :] = 1\n",
    "\n",
    "        # Step2\n",
    "        for t in range((n-1), 0, -1):\n",
    "            beta[t-1, :] = np.dot(self.A, (self.B[:, x[t]] * beta[t, :]))\n",
    "\n",
    "        # Step3\n",
    "        return round(sum(p[:] * self.B[:, x[0]] * beta[0, :]), 3)\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    # 観測結果\n",
    "    x = [ 0, 1, 0 ] # v1, v2, v1という結果\n",
    "\n",
    "    hmm = HMM(p, A, B)\n",
    "    print(hmm.forward(x, c))\n",
    "    print(hmm.backward(x, c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def post_prob_DS(est_labels, ans_train, k, worker_num, num_words):\n",
    "    #学習機とラベルの更新\n",
    "    n = len(ans_train)\n",
    "    m = worker_num\n",
    "    e_conf = np.zeros((m,k,k,k))\n",
    "    temp_conf = (1/float(k))*np.ones((m,k,k,k))\n",
    "    labels_md = 0.000001 * np.ones((k,k)) #正規化の時に困りそうなので0にしないでおく\n",
    "    task_acc = np.zeros((n, k, k))\n",
    "    #est_labelsを正解ラベルとして混同行列を作成 式(7)\n",
    "    for i in range(n):\n",
    "        pre_ans = ans_train[i][2][0]\n",
    "        for l in range(len(ans_train[i][2])-1):\n",
    "            l += 1\n",
    "            #真のラベルの周辺分布を更新\n",
    "            labels_md[int(est_labels[i][l-1]),int(est_labels[i][l])] += 1\n",
    "            for a, j in enumerate(ans_train[i][1]): #各回答ワーカーについて\n",
    "                temp_conf[j,int(est_labels[i][l]),:,:] = temp_conf[j,int(est_labels[i][l]),:,:] + np.outer(np.eye(k)[ans_train[i][2][l-1][a]],np.eye(k)[ans_train[i][2][l][a]]) #外積 混同行列の作成\n",
    "    #temp_confの正規化\n",
    "    for j in range(m):  \n",
    "        for p in range(k):\n",
    "            e_conf[j,p,:,:] = np.divide(temp_conf[j,p,:,:],np.outer(np.sum(temp_conf[j,p,:,:],axis =1),np.ones(k)))\n",
    "    labels_md = np.divide(labels_md, np.sum(labels_md)*np.ones(k))\n",
    "    #混同行列を使って真のラベル推定(論文p5の(5)式)\n",
    "    for i in range(n):\n",
    "        for l in range(len(ans_train[i][2])):\n",
    "            temp_class = 0.0\n",
    "            for r, a in enumerate(ans_train[i][1]):\n",
    "                if l == 0:\n",
    "                    w_conf = np.sum(e_conf[a,:,:,:], axis=1)\n",
    "                else:\n",
    "                    w_conf = e_conf[a,:,ans_train[i][2][l-1][r],:]\n",
    "                #混同行列の該当列をとる\n",
    "                temp_acc = np.log(np.dot(w_conf,np.transpose(np.eye(k)[ans_train[i][2][l][r]])))\n",
    "                temp_class = temp_class + temp_acc\n",
    "            temp_class = np.log(labels_md) +temp_class\n",
    "            est_labels[i][l] = np.argmax(temp_class)%9\n",
    "    return est_labels, e_conf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
