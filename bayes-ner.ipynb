{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import glob\n",
    "import numpy as np\n",
    "import os\n",
    "import scipy.special as special\n",
    "import time\n",
    "\n",
    "from itertools import groupby\n",
    "\n",
    "ans_path = './ner-mturk/answers*'\n",
    "ans_file_list = sorted(glob.glob(ans_path))\n",
    "single_ans_list = sorted(glob.glob('ner-mturk/single_ans*'))\n",
    "truth_file = './ner-mturk/ground_truth.txt'\n",
    "path_w = './MBEM_outputs'\n",
    "alltask_num = 5985\n",
    "train_num = 5385\n",
    "train_num5 = 1077\n",
    "test_num = 600\n",
    "redundancy = 5\n",
    "iteration_times = 5\n",
    "ans_file = single_ans_list[1]\n",
    "ans_file5 = ans_file_list[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_output(path, class_dic_r, to_label=False):\n",
    "    f = open(path)\n",
    "    make_xypair = lambda v: list(zip(*[l.strip().split() for l in v]))\n",
    "    is_emptyline = lambda x: x.strip() != '' and not x.startswith('-DOCSTART-')\n",
    "    list_int = lambda t: list([class_dic_r[int(v)] for v in t])\n",
    "    xypairs = [make_xypair(v) for k, v in groupby(f, is_emptyline) if k]\n",
    "    if to_label == True:\n",
    "        return ([p[0] for p in xypairs], [list(list_int(p[1])) for p in xypairs])\n",
    "    if len(xypairs[0]) == 2:\n",
    "        return ([p[0] for p in xypairs], [list(p[1]) for p in xypairs])\n",
    "    else:\n",
    "        return ([p[0] for p in xypairs], [list(p[1:]) for p in xypairs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_crowd_data(ans_file, truth_file, train_num):\n",
    "    #answers_list[task_num] = [[words, ...], [worker], [[answers]...]]\n",
    "    answers_list = []\n",
    "    sentence = []\n",
    "    answers = []\n",
    "    worker = []\n",
    "    words_dic = {}\n",
    "    get_worker = lambda x: tuple([i for i, l in enumerate(x) if l !='?'])\n",
    "    for l in open(ans_file):\n",
    "        ans = l.split()\n",
    "        if len(l) < 2:\n",
    "            answers_list.append([sentence, worker, answers])\n",
    "            sentence = []\n",
    "            worker = []\n",
    "            answers = []\n",
    "        else:\n",
    "            if len(worker) < 1:\n",
    "                worker = get_worker(ans[1:])\n",
    "            if not ans[0] in words_dic:\n",
    "                words_dic[ans[0]] = len(words_dic)\n",
    "            sentence.append(ans[0])\n",
    "            answers.append(get_ans(worker, ans[1:]))            \n",
    "    #truth_list: [(task_word, answer), ....]\n",
    "    truth_list = [tuple(l.split()) for l in open(truth_file) if l != \"\\n\"]\n",
    "    ans_train = answers_list[0:train_num]\n",
    "#    ans_test = answers_list[train_num:]\n",
    "    return ans_train, words_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logsumexp(arr, axis=0):\n",
    "    arr = np.rollaxis(arr, axis)\n",
    "    # Use the max to normalize, as with the log this is what accumulates\n",
    "    # the less errors\n",
    "    vmax = arr.max(axis=0)\n",
    "    out = np.log(np.sum(np.exp(arr - vmax), axis=0))\n",
    "    out += vmax\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ans(workers, answers):\n",
    "    ans_label = []\n",
    "    for a in workers:\n",
    "        ans_label.append(class_dic[answers[a]])\n",
    "    return ans_label\n",
    "def label2num(answers, class_dic, class_dic_r):\n",
    "    ans_return = copy.deepcopy(answers)\n",
    "    if answers[0][0] in class_dic:\n",
    "        for i in range(len(answers)):\n",
    "            for w in range(len(answers[i])):\n",
    "                ans_return[i][w] = class_dic[answers[i][w]]\n",
    "    elif answers[0][0] in class_dic_r:\n",
    "        for i in range(len(answers)):\n",
    "            for w in range(len(answers[i])):\n",
    "                ans_return[i][w] = class_dic_r[int(answers[i][w])]\n",
    "    else: print(\"error\")\n",
    "    return ans_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ワーカのタスクに対する回答の事後確率の初期化\n",
    "#Algorithm 1のInitialixe posterior distribution using weighted mv(論文p6)\n",
    "def init_posdis(redundancy, ans_m, k):\n",
    "    simple_agg = np.zeros((num_words,k))\n",
    "    mv_ans = np.zeros((num_words))\n",
    "    for r in range(redundancy):\n",
    "        simple_agg += (1/redundancy)*ans_m[r]\n",
    "    for i in range(len(simple_agg)):\n",
    "        mv_ans[i] = np.argmax(simple_agg[i])\n",
    "    return mv_ans\n",
    "def ans_matrix(ans_train, redundancy, k):\n",
    "    ans_m = np.zeros((num_words, redundancy,k))\n",
    "    m = 0\n",
    "    for n in range(len(ans_train)):\n",
    "        for i in range(len(ans_train[n][0])):\n",
    "            ans_m[m] = np.eye(k)[ans_train[n][2][i][:5]]\n",
    "            m += 1\n",
    "    return ans_m\n",
    "#deep-learining-modelに渡すデータの書き込み\n",
    "def write_prediction(est_labels, ans_train, iter_num):\n",
    "    w_list = []\n",
    "    for n in range(len(ans_train)):\n",
    "        for i in range(len(ans_train[n][0])):\n",
    "            w_list.append(ans_train[n][0][i] +\" \"+ str(est_labels[n][i]) + \"\\n\")\n",
    "        w_list.append(\"\\n\")\n",
    "    w_file = path_w + \"/prediction.txt\"\n",
    "    with open(w_file, mode='w') as f:\n",
    "        f.writelines(w_list)\n",
    "    with open(\"./MBEM_outputs/prediction\"+str(iter_num)+\".txt\", mode='w') as f:\n",
    "        f.writelines(w_list)\n",
    "#deep-learning-modelからのデータの読み込み\n",
    "def get_newest_prediction():\n",
    "    files_list = glob.glob(\"./deep-learning-model/outputs/*\")\n",
    "    latest_file = max(glob.glob(max(files_list, key=os.path.getctime)+\"/*\"), key=os.path.getctime) + \"/best_model_log/pred.txt\"\n",
    "    prediction_list = [list(l.split()) for l in open(latest_file) if l != \"\\n\"]\n",
    "    return prediction_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "worker_num 47\n",
      "クラス： {'B-LOC': 0, 'B-MISC': 1, 'B-ORG': 2, 'B-PER': 3, 'I-LOC': 4, 'I-MISC': 5, 'I-ORG': 6, 'I-PER': 7, 'O': 8}\n",
      "クラス数： 9\n",
      "タスク数 5385\n",
      "タスク数(単語): 70985\n",
      "語彙数 12378\n"
     ]
    }
   ],
   "source": [
    "class_list = list(set(l.split()[1] for l in open(truth_file) if l != \"\\n\"))\n",
    "class_dic = {k:i for i, k in enumerate(sorted(class_list))}\n",
    "class_dic_r = {class_dic[c]:c for c in class_dic}\n",
    "class_label = {'LOC': 0, 'MISC': 1, 'ORG': 2, 'PER': 3, 'O': 4}\n",
    "labelnum_dic = {'B-LOC': 0, 'B-MISC': 1, 'B-ORG': 2, 'B-PER': 3, 'I-LOC': 0, 'I-MISC': 1, 'I-ORG': 2, 'I-PER': 3, 'O': 4}\n",
    "#データの読み込み\n",
    "ans_train, words_dic = load_crowd_data(ans_file, truth_file, train_num)\n",
    "ans_train5, words_dic5 = load_crowd_data(ans_file5, truth_file, train_num5)\n",
    "X_true, y_true = read_output('../MBEM/ner-mturk/ground_truth.txt', class_dic_r)\n",
    "X_true5, y_true5 = read_output('../MBEM/ner-mturk/testset5.txt', class_dic_r)\n",
    "workers_count = []\n",
    "for i in range(len(ans_train)):\n",
    "    for w in ans_train[i][1]:\n",
    "        workers_count.append(w)\n",
    "worker_num = len(set(workers_count))\n",
    "class_num = len(class_dic)\n",
    "#多分データを変えるごとにクラス確認したくなるので残しておく\n",
    "num_words = 0\n",
    "for l in ans_train:\n",
    "    num_words += len(l[0])\n",
    "print(\"worker_num\", worker_num)\n",
    "print(\"クラス：\",class_dic)\n",
    "print(\"クラス数：\", class_num)\n",
    "print(\"タスク数\",len(ans_train))\n",
    "print(\"タスク数(単語):\", num_words)\n",
    "print(\"語彙数\", len(words_dic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ans_mは回答(redundancy)×タスク(単語)×ラベル数\n",
    "ans_m = ans_matrix(ans_train, redundancy, k)\n",
    "ans_m = ans_m.transpose(1, 0, 2) \n",
    "#deep-learining-modelに渡すデータの書き込み\n",
    "w_list = []\n",
    "i = 0\n",
    "simple_agg = init_posdis(redundancy, ans_m, k)\n",
    "for task in ans_train:\n",
    "    for word in task[0]:\n",
    "        w_list.append(word +\" \"+ str(class_dic_r[int(simple_agg[i])]) + \"\\n\")\n",
    "        i += 1\n",
    "    w_list.append(\"\\n\")\n",
    "w_file = path_w + \"/agg_test.txt\"\n",
    "with open(w_file, mode='w') as f:\n",
    "    f.writelines(w_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_agg, y_agg = read_output('./MBEM_outputs/agg_test.txt', class_dic_r, to_label=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#データの読み込み\n",
    "est_labels = get_newest_prediction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "#in ans_train[n] out: np.array(t*J)\n",
    "def ans2matrix(ans_n, J):\n",
    "    ans_matrix = np.array([])\n",
    "    for t in ans_n[2]:\n",
    "        temp_t = np.zeros((J))\n",
    "        for ans in t:\n",
    "            temp_t += np.eye(J)[ans]\n",
    "        temp_t = temp_t / len(ans_n[2][0])\n",
    "        ans_matrix = np.append(ans_matrix, temp_t)\n",
    "    ans_matrix = ans_matrix.reshape(-1, J)\n",
    "    return ans_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_occurence(r, ans_train, words_dic):\n",
    "    occurence = np.zeros((J,len(words_dic)))\n",
    "    for n in range(len(ans_train)):\n",
    "        for t in range(len(ans_train[n][0])):\n",
    "            occurence[:,words_dic[ans_train[n][0][t]]] += r[n][t]\n",
    "    return occurence\n",
    "def cal_exp_log_rho(kappa, occurence):\n",
    "    exp_log_rho = np.zeros((J,len(words_dic)))\n",
    "    for j in range(J):\n",
    "        exp_log_rho[j] = special.digamma(occurence[j]+kappa[j]) - special.digamma(np.sum(occurence+kappa,axis=0))\n",
    "    return exp_log_rho\n",
    "def cal_exp_log_conf(N, K, J):\n",
    "    exp_log_conf = np.zeros((K,J,J,J)) \n",
    "    for k in range(K):\n",
    "        for j in range(J):\n",
    "            for l in range(J):\n",
    "                for m in range(J):\n",
    "                    exp_log_conf[k,j,l,m] = special.digamma(N[k,j,l,m]) - special.digamma(np.sum(N[k,j,l]))\n",
    "    return exp_log_conf\n",
    "def cal_exp_log_transe(N_s, gamma):\n",
    "    exp_log_transe = np.zeros((J,J))\n",
    "    exp_log_transe = special.digamma(N_s+gamma) - np.matrix(np.ones((J,J)))*special.digamma(np.sum(N_s[j]+gamma[j]))\n",
    "    return exp_log_transe\n",
    "def cal_ll(exp_log_conf, exp_log_rho, J, x, ans, t, words_dic): \n",
    "    ll = np.zeros((J))\n",
    "    temp_sum = np.zeros((J))\n",
    "    for k in range(len(ans[0])):\n",
    "        temp_sum += exp_log_conf[k,:,ans[t-1][k], ans[t][k]]\n",
    "    ll = temp_sum + exp_log_rho[:,words_dic[x[t]]] #要確認\n",
    "    return ll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(exp_log_rho, exp_log_trans, x, y, J, words_dic):\n",
    "    n = len(y) # 単語数\n",
    "    # 前向きアルゴリズム\n",
    "    log_r_m = np.zeros((n, J))\n",
    "    new_r_m = np.zeros((n, J))\n",
    "    ll = np.zeros((n,J))\n",
    "    for t in range(n):\n",
    "        if t == 0:\n",
    "            ll[t] = exp_log_rho[:,words_dic[x[t]]]\n",
    "            log_r_m[t] = ll[t]\n",
    "            continue\n",
    "        ll[t] = cal_ll(exp_log_conf, exp_log_rho, J, x, y, t, words_dic)\n",
    "        temp_sum = np.zeros((J))\n",
    "        for j in range(J):\n",
    "            for l in range(J):\n",
    "                temp_sum[j] += log_r_m[t-1,l] + exp_log_trans[l,j]\n",
    "        log_r_m[t] = temp_sum + ll[t]\n",
    "        new_r_m = np.exp(log_r_m)\n",
    "    return ll, new_r_m\n",
    "\n",
    "def backward(exp_log_rho, exp_log_t, J, y, words_dic, ll):\n",
    "    n = len(y) \n",
    "    # 後ろ向きアルゴリズム\n",
    "    log_lambda = np.zeros((n,J))\n",
    "    for a in range(n):\n",
    "        t = n-1-a\n",
    "        if t == n-1:\n",
    "            log_lambda[t,:] = 1\n",
    "            continue\n",
    "        for j in range(J):\n",
    "            for l in range(J):\n",
    "                log_lambda[t,j] += log_lambda[t+1,l] + exp_log_t[j,l] + ll[t+1,l]\n",
    "    back_lambda = np.exp(log_lambda)\n",
    "    return back_lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(exp_log_rho, exp_log_trans, x, y, J, words_dic):\n",
    "    n = len(y) # 単語数\n",
    "    # 前向きアルゴリズム\n",
    "    log_r_m = np.zeros((n, J))\n",
    "    new_r_m = np.zeros((n, J))\n",
    "    ll = np.zeros((n,J))\n",
    "    for t in range(n):\n",
    "        if t == 0:\n",
    "            ll[t] = exp_log_rho[:,words_dic[x[t]]]\n",
    "            log_r_m[t] = ll[t]\n",
    "            continue\n",
    "        ll[t] = cal_ll(exp_log_conf, exp_log_rho, J, x, y, t, words_dic)\n",
    "        temp_sum = np.zeros((J))\n",
    "        for j in range(J):\n",
    "            for l in range(J):\n",
    "                temp_sum[j] += log_r_m[t-1,l] + exp_log_trans[l,j]\n",
    "        log_r_m[t] = temp_sum + ll[t]\n",
    "        new_r_m = np.exp(log_r_m)\n",
    "    return ll, new_r_m\n",
    "\n",
    "def backward(exp_log_rho, exp_log_t, J, y, words_dic, ll):\n",
    "    n = len(y) \n",
    "    # 後ろ向きアルゴリズム\n",
    "    log_lambda = np.zeros((n,J))\n",
    "    for a in range(n):\n",
    "        t = n-1-a\n",
    "        if t == n-1:\n",
    "            log_lambda[t,:] = 1\n",
    "            continue\n",
    "        for j in range(J):\n",
    "            for l in range(J):\n",
    "                log_lambda[t,j] += log_lambda[t+1,l] + exp_log_t[j,l] + ll[t+1,l]\n",
    "    back_lambda = np.exp(log_lambda)\n",
    "    return back_lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'log_r_m' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-556-26fa9fca0adf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_r_m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m#logsumexp(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'log_r_m' is not defined"
     ]
    }
   ],
   "source": [
    "np.shape(log_r_m)\n",
    "#logsumexp("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-8.93773589e+00 -2.92585218e+01 -8.82650134e+00 -7.86940779e+00\n",
      "  -2.59780428e+01 -3.85072541e+00 -2.61576165e+00 -1.13163717e+01\n",
      "  -9.98744235e-02]\n",
      " [-1.95583050e+01 -1.28823269e+00 -2.55284993e+01 -4.65616561e+00\n",
      "  -1.75640640e+01 -4.13128513e+00 -3.17925448e+00 -7.99900147e-01\n",
      "  -1.57172451e+00]\n",
      " [-5.66416368e+00 -2.51910182e+01 -1.48500360e+00 -7.61226721e+00\n",
      "  -5.86548015e+00 -5.52448133e+00 -3.25081340e-01 -5.01658258e+00\n",
      "  -3.39273057e+00]\n",
      " [-8.64886851e+00 -6.03145615e+00 -8.29532064e+00 -2.88481730e+01\n",
      "  -5.22466378e+01 -4.29597254e+01 -2.10359241e+00 -1.36077195e-01\n",
      "  -6.04047038e+00]\n",
      " [-6.72808688e+00 -6.18910765e+00 -4.58437002e+00 -9.76287009e+00\n",
      "  -2.07986496e+01 -5.06392313e-01 -9.59290353e-01 -7.40650083e+00\n",
      "  -9.98887137e+00]\n",
      " [-4.70133508e+00 -1.24628257e+01 -4.92233578e+00 -1.72965844e-02\n",
      "  -3.59581623e+01 -1.67880414e+01 -7.19803662e+00 -1.14960601e+01\n",
      "  -1.07964911e+01]\n",
      " [-3.89850698e+00 -2.20262048e+00 -8.90913896e+00 -9.76735355e+00\n",
      "  -1.49139769e+01 -1.69670125e+01 -1.41880633e-01 -8.76917316e+00\n",
      "  -6.77535297e+00]\n",
      " [-1.19369107e+00 -1.26739929e+01 -9.07847964e-01 -5.09313339e+00\n",
      "  -2.72831110e+01 -1.24700637e+00 -1.67002874e+01 -2.23574940e+01\n",
      "  -1.29188575e+01]\n",
      " [-4.21588784e-01 -1.44709687e+01 -2.72401712e+00 -1.97254617e+00\n",
      "  -4.39532227e+00 -7.68806297e+00 -9.80173667e+00 -2.27302714e+00\n",
      "  -3.75354960e+00]]\n"
     ]
    }
   ],
   "source": [
    "trans_prob = np.random.dirichlet(gamma,size=(J)) #遷移確率 論文のT\n",
    "rho = np.random.dirichlet(kappa, size=(J)) #出力確率\n",
    "\n",
    "exp_log_conf = np.log(conf)\n",
    "exp_log_t = np.log(trans_prob)\n",
    "\n",
    "print(exp_log_t)\n",
    "#print(np.sum(np.exp(exp_log_t[:,3])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-10.32329768 -31.11950803  -8.35303177  -8.03531699  -9.39301296\n",
      "  -26.64233653 -13.66652596  -9.02959725 -13.70513135]\n",
      " [-20.23108746 -41.20861072 -19.6511657  -46.79241883 -20.46813027\n",
      "  -41.57962947 -19.5778015  -18.31781148 -40.02518713]\n",
      " [-18.48653175 -36.00507726 -23.52639606 -21.03841021 -55.74171648\n",
      "  -19.91237317 -27.49079687 -35.63295483 -28.13253169]\n",
      " [-38.96367782 -33.56909238 -21.75281697 -17.28157515 -25.61981901\n",
      "  -26.53510132 -20.02894357 -20.10155646 -23.14962091]\n",
      " [-19.15184594 -26.79612021 -23.39186713 -24.92917234 -43.26644218\n",
      "  -22.3773645  -28.60340244 -29.51280578 -32.21123447]\n",
      " [-22.64986017 -49.4713363  -21.17250209 -52.04497928 -31.78960614\n",
      "  -27.88967881 -24.50888018 -29.78628111 -20.6891785 ]\n",
      " [-30.1455014  -40.87129314 -23.43498435 -20.99385227 -25.25364458\n",
      "  -30.85570458 -28.48304486 -19.8891366  -33.2527461 ]\n",
      " [-44.55883677 -22.544412   -25.94658681 -26.840758   -23.15659953\n",
      "  -36.03285331 -30.89127625 -24.59107015 -30.55007463]]\n"
     ]
    }
   ],
   "source": [
    "n = 0\n",
    "ll, r_m = forward(exp_log_rho, exp_log_t, ans_train[n][0], ans_train[n][2], J, words_dic)\n",
    "print(ll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_N(alpha, ans_train, r):\n",
    "    temp_sum = np.zeros((K,J,J,J))\n",
    "    N = np.zeros((K,J,J,J))\n",
    "    for n in range(len(ans_train)):\n",
    "        for t in range(len(ans_train[n][0])):\n",
    "            for k in range(len(ans_train[n][1])):\n",
    "                one_hot_matrix = np.zeros((J,J,J))\n",
    "                one_hot_matrix[:,[ans_train[n][2][t-1][k]],[ans_train[n][2][t][k]]]\n",
    "                temp_sum[ans_train[n][1][k]] += r[n][t] * one_hot_matrix\n",
    "    N = alpha.transpose(3,2,1,0) + temp_sum\n",
    "    return N\n",
    "def cal_N_s(s, J):\n",
    "    N_s = np.zeros((J,J))\n",
    "    for n in range(len(s)):\n",
    "        for t in range(len(s[n])):\n",
    "            N_s = s[n][t]\n",
    "    return N_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed_time:2.9802322387695312e-05[sec]\n",
      "elapsed_time:1841.8553094863892[sec]\n"
     ]
    }
   ],
   "source": [
    "#input \n",
    "#ラベル :y\n",
    "#単語: x\n",
    "\n",
    "K = worker_num\n",
    "J = class_num\n",
    "\n",
    "max_iter = 50\n",
    "\n",
    "#ハイパーパラメータの設定\n",
    "alpha = 0.1 * np.ones((J,J,J,K))\n",
    "kappa = 0.1 * np.ones((len(words_dic),J))\n",
    "gamma = 0.1 * np.ones((J,J))\n",
    "\n",
    "conf = np.random.dirichlet(alpha,size=(K,J,J)) #worker,true_label,woker_ans(n-1),worker_ans(n)　論文のA\n",
    "trans_prob = np.random.dirichlet(gamma,size=(J)) #遷移確率 論文のT\n",
    "rho = np.random.dirichlet(kappa, size=(J)) #出力確率\n",
    "\n",
    "exp_log_conf = np.log(conf)\n",
    "exp_log_t = np.log(trans_prob)\n",
    "exp_log_rho = np.log(rho)\n",
    "\n",
    "start = time.time()\n",
    "elapsed_time = time.time() - start\n",
    "print (\"elapsed_time:{0}\".format(elapsed_time) + \"[sec]\")\n",
    "\n",
    "iter_times = 0\n",
    "while iter_times < max_iter:\n",
    "    r = []\n",
    "    s = []\n",
    "    #r,sの更新\n",
    "    for n in range(len(ans_train)):\n",
    "        ll, r_m = forward(exp_log_rho, exp_log_t, ans_train[n][0], ans_train[n][2], J, words_dic)\n",
    "        back_lambda = backward(exp_log_rho, exp_log_t, J, ans_train[n][2], words_dic, ll)\n",
    "        r.append(r_m*back_lambda)\n",
    "        temp_s = np.zeros((len(ans_train[n][0]), J,J))\n",
    "        for t in range(len(ans_train[n][0])):\n",
    "            if t == 0:\n",
    "                continue\n",
    "            for j in range(J):\n",
    "                for l in range(J):\n",
    "                    temp_s[t,j,l] = r_m[t-1,j] * back_lambda[t,l] * np.exp(exp_log_t[j,l] + ll[t,l])\n",
    "        s.append(temp_s)\n",
    "    #confの更新\n",
    "    N = cal_N(alpha, ans_train, r)\n",
    "    exp_log_conf = cal_exp_log_conf(N, K, J)\n",
    "    #Tの更新\n",
    "    N_s = cal_N_s(s, J)\n",
    "    exp_log_t = cal_exp_log_transe(N_s, gamma)\n",
    "    #rhoの更新\n",
    "    occurence = cal_occurence(r, ans_train, words_dic)\n",
    "    exp_log_rho = cal_exp_log_rho(kappa.transpose(1,0), occurence)\n",
    "    data_numpy = np.array([ll, r_m, r, s, N, N_s, occurence, np.exp(exp_log_conf), np.exp(exp_log_t), np.exp(exp_log_rho)])\n",
    "    np.save(path_w + '/bayes_param_data' + str(iter_times) + '.npy', data_numpy)\n",
    "    iter_times += 1\n",
    "elapsed_time = time.time() - start\n",
    "print (\"elapsed_time:{0}\".format(elapsed_time) + \"[sec]\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0051211367873734565\n"
     ]
    }
   ],
   "source": [
    "print(np.sum(np.exp(exp_log_conf[0][0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 以下，dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input \n",
    "#ラベル :y\n",
    "#単語: x\n",
    "\n",
    "K = worker_num\n",
    "J = class_num\n",
    "#初期値を設定する\n",
    "conf = np.zeros((K,J,J,J)) #worker,true_label,woker_ans(n-1),worker_ans(n)\n",
    "rho = np.zeros((J)) #出力確率\n",
    "trans_prob = np.zeros((J,J))\n",
    "\n",
    "class VB:\n",
    "    def __init__(self, K, J, alpha, kappa, gamma ):\n",
    "        self.conf = np.random.dirichlet(alpha, size=(K,J,J,J)) #worker,true_label,woker_ans(n-1),worker_ans(n)\n",
    "        self.rho = np.random.dirichlet(kappa, size=(J)) #出力確率\n",
    "        self.trans_prob = np.random.dirichlet(gamma, size=(J,J)) #遷移確率\n",
    "        \n",
    "    def forward(self, y, J):\n",
    "        n = len(y) # タスク数\n",
    "\n",
    "        # 前向きアルゴリズム\n",
    "        r = np.zeros((n, J))\n",
    "        ll\n",
    "        \n",
    "\n",
    "        # Step2\n",
    "        for t in range(1, n):\n",
    "            alpha[t, :] = np.dot(alpha[t-1, :], A) * B[:, x[t]]\n",
    "\n",
    "        # Step3\n",
    "        return round(np.sum(alpha[-1]), 3)\n",
    "\n",
    "    def backward(self, x, c):\n",
    "        n = len(x) # 観測回数\n",
    "\n",
    "        # 後ろ向きアルゴリズム\n",
    "        # Step1\n",
    "        beta = np.zeros((n, c))\n",
    "        beta[-1, :] = 1\n",
    "\n",
    "        # Step2\n",
    "        for t in range((n-1), 0, -1):\n",
    "            beta[t-1, :] = np.dot(self.A, (self.B[:, x[t]] * beta[t, :]))\n",
    "\n",
    "        # Step3\n",
    "        return round(sum(p[:] * self.B[:, x[0]] * beta[0, :]), 3)\n",
    "    \n",
    "    def exp_log_conf(\n",
    "\n",
    "\n",
    "        \n",
    "#前向き後ろ向きアルゴリズム\n",
    "#論文の7式\n",
    "\n",
    "#ビタビアルゴリズム\n",
    "\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.VB at 0x7f5bc031ed90>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha = 10 * np.ones((K))\n",
    "kappa = 10 * np.ones((J))\n",
    "gamma = 10 * np.ones((J,J))\n",
    "VB(K,J,alpha,kappa,gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "#init_r(label_post) n*t*J 論文のr\n",
    "label_post = []\n",
    "for n in range(len(ans_train)):\n",
    "    label_post.append(ans2matrix(ans_train[n], J))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_symbol = [ \"w1\", \"w2\", \"w3\" ] # 状態\n",
    "c = len(s_symbol)               # 状態数\n",
    "v_symbol = [ \"v1\", \"v2\" ]       # 出力記号\n",
    "m = len(v_symbol)               # 出力数\n",
    "\n",
    "# 遷移確率行列\n",
    "A = np.array([[0.1, 0.7, 0.2], [0.2, 0.1, 0.7], [0.7, 0.2, 0.1]])\n",
    "# 出力確率行列\n",
    "B = np.array([[0.9, 0.1], [0.6, 0.4], [0.1, 0.9]])\n",
    "# 初期確率行列\n",
    "p = np.array([1/3, 1/3, 1/3])\n",
    "\n",
    "class HMM:\n",
    "\n",
    "    def __init__(self, p, A, B): \n",
    "        self.p = p\n",
    "        self.A = A\n",
    "        self.B = B\n",
    "\n",
    "    def forward(self, x, c):\n",
    "        n = len(x) # 観測回数\n",
    "\n",
    "        # 前向きアルゴリズム\n",
    "        alpha = np.zeros((n, c))\n",
    "\n",
    "        # Step1\n",
    "        alpha[0, :] = p[:] * B[:, x[0]]\n",
    "\n",
    "        # Step2\n",
    "        for t in range(1, n):\n",
    "            alpha[t, :] = np.dot(alpha[t-1, :], A) * B[:, x[t]]\n",
    "\n",
    "        # Step3\n",
    "        return round(np.sum(alpha[-1]), 3)\n",
    "\n",
    "    def backward(self, x, c):\n",
    "        n = len(x) # 観測回数\n",
    "\n",
    "        # 後ろ向きアルゴリズム\n",
    "        # Step1\n",
    "        beta = np.zeros((n, c))\n",
    "        beta[-1, :] = 1\n",
    "\n",
    "        # Step2\n",
    "        for t in range((n-1), 0, -1):\n",
    "            beta[t-1, :] = np.dot(self.A, (self.B[:, x[t]] * beta[t, :]))\n",
    "\n",
    "        # Step3\n",
    "        return round(sum(p[:] * self.B[:, x[0]] * beta[0, :]), 3)\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    # 観測結果\n",
    "    x = [ 0, 1, 0 ] # v1, v2, v1という結果\n",
    "\n",
    "    hmm = HMM(p, A, B)\n",
    "    print(hmm.forward(x, c))\n",
    "    print(hmm.backward(x, c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def post_prob_DS(est_labels, ans_train, k, worker_num, num_words):\n",
    "    #学習機とラベルの更新\n",
    "    n = len(ans_train)\n",
    "    m = worker_num\n",
    "    e_conf = np.zeros((m,k,k,k))\n",
    "    temp_conf = (1/float(k))*np.ones((m,k,k,k))\n",
    "    labels_md = 0.000001 * np.ones((k,k)) #正規化の時に困りそうなので0にしないでおく\n",
    "    task_acc = np.zeros((n, k, k))\n",
    "    #est_labelsを正解ラベルとして混同行列を作成 式(7)\n",
    "    for i in range(n):\n",
    "        pre_ans = ans_train[i][2][0]\n",
    "        for l in range(len(ans_train[i][2])-1):\n",
    "            l += 1\n",
    "            #真のラベルの周辺分布を更新\n",
    "            labels_md[int(est_labels[i][l-1]),int(est_labels[i][l])] += 1\n",
    "            for a, j in enumerate(ans_train[i][1]): #各回答ワーカーについて\n",
    "                temp_conf[j,int(est_labels[i][l]),:,:] = temp_conf[j,int(est_labels[i][l]),:,:] + np.outer(np.eye(k)[ans_train[i][2][l-1][a]],np.eye(k)[ans_train[i][2][l][a]]) #外積 混同行列の作成\n",
    "    #temp_confの正規化\n",
    "    for j in range(m):  \n",
    "        for p in range(k):\n",
    "            e_conf[j,p,:,:] = np.divide(temp_conf[j,p,:,:],np.outer(np.sum(temp_conf[j,p,:,:],axis =1),np.ones(k)))\n",
    "    labels_md = np.divide(labels_md, np.sum(labels_md)*np.ones(k))\n",
    "    #混同行列を使って真のラベル推定(論文p5の(5)式)\n",
    "    for i in range(n):\n",
    "        for l in range(len(ans_train[i][2])):\n",
    "            temp_class = 0.0\n",
    "            for r, a in enumerate(ans_train[i][1]):\n",
    "                if l == 0:\n",
    "                    w_conf = np.sum(e_conf[a,:,:,:], axis=1)\n",
    "                else:\n",
    "                    w_conf = e_conf[a,:,ans_train[i][2][l-1][r],:]\n",
    "                #混同行列の該当列をとる\n",
    "                temp_acc = np.log(np.dot(w_conf,np.transpose(np.eye(k)[ans_train[i][2][l][r]])))\n",
    "                temp_class = temp_class + temp_acc\n",
    "            temp_class = np.log(labels_md) +temp_class\n",
    "            est_labels[i][l] = np.argmax(temp_class)%9\n",
    "    return est_labels, e_conf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
